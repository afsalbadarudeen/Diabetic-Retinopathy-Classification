{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c68ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d503d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:\\\\Users\\\\Govind S\\\\Downloads\\\\ds\\\\project\\\\pronostico_dataset.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f989b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='ID',axis=1,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c69dc7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.196340</td>\n",
       "      <td>85.288742</td>\n",
       "      <td>80.021878</td>\n",
       "      <td>79.957109</td>\n",
       "      <td>retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.529850</td>\n",
       "      <td>99.379736</td>\n",
       "      <td>84.852361</td>\n",
       "      <td>110.382411</td>\n",
       "      <td>retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.003986</td>\n",
       "      <td>111.349455</td>\n",
       "      <td>109.850616</td>\n",
       "      <td>100.828246</td>\n",
       "      <td>retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.638210</td>\n",
       "      <td>95.056128</td>\n",
       "      <td>79.666851</td>\n",
       "      <td>87.066303</td>\n",
       "      <td>retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.346286</td>\n",
       "      <td>109.154591</td>\n",
       "      <td>90.713220</td>\n",
       "      <td>92.511770</td>\n",
       "      <td>retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>49.611850</td>\n",
       "      <td>94.857639</td>\n",
       "      <td>86.615671</td>\n",
       "      <td>107.643986</td>\n",
       "      <td>no_retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>63.099686</td>\n",
       "      <td>100.039527</td>\n",
       "      <td>93.515186</td>\n",
       "      <td>104.971404</td>\n",
       "      <td>retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>55.562243</td>\n",
       "      <td>98.421446</td>\n",
       "      <td>102.697875</td>\n",
       "      <td>120.875951</td>\n",
       "      <td>retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>63.468956</td>\n",
       "      <td>106.809289</td>\n",
       "      <td>88.060631</td>\n",
       "      <td>106.052213</td>\n",
       "      <td>retinopathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>62.506825</td>\n",
       "      <td>96.900784</td>\n",
       "      <td>86.878033</td>\n",
       "      <td>108.625436</td>\n",
       "      <td>no_retinopathy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  systolic_bp  diastolic_bp  cholesterol       prognosis\n",
       "0     77.196340    85.288742     80.021878    79.957109     retinopathy\n",
       "1     63.529850    99.379736     84.852361   110.382411     retinopathy\n",
       "2     69.003986   111.349455    109.850616   100.828246     retinopathy\n",
       "3     82.638210    95.056128     79.666851    87.066303     retinopathy\n",
       "4     78.346286   109.154591     90.713220    92.511770     retinopathy\n",
       "...         ...          ...           ...          ...             ...\n",
       "5995  49.611850    94.857639     86.615671   107.643986  no_retinopathy\n",
       "5996  63.099686   100.039527     93.515186   104.971404     retinopathy\n",
       "5997  55.562243    98.421446    102.697875   120.875951     retinopathy\n",
       "5998  63.468956   106.809289     88.060631   106.052213     retinopathy\n",
       "5999  62.506825    96.900784     86.878033   108.625436  no_retinopathy\n",
       "\n",
       "[6000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4775e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.prognosis=='retinopathy','prognosis']=1\n",
    "df.loc[df.prognosis=='no_retinopathy','prognosis']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06dad6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1]\n",
    "ss=preprocessing.StandardScaler()\n",
    "x=ss.fit_transform(x)\n",
    "y=df.iloc[:,-1]\n",
    "y=y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3fc708",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ca22dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy={}\n",
    "recall={}\n",
    "precision={}\n",
    "f1={}\n",
    "models={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f04b1",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b6829b",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d0ee1ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7608333333333334\n",
      "0.7805280528052805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       594\n",
      "           1       0.75      0.78      0.77       606\n",
      "\n",
      "    accuracy                           0.76      1200\n",
      "   macro avg       0.76      0.76      0.76      1200\n",
      "weighted avg       0.76      0.76      0.76      1200\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[440 154]\n",
      " [133 473]]\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=10)\n",
    "model=LogisticRegression()\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "print(metrics.accuracy_score(y_test,lr.predict(x_test)))\n",
    "print(metrics.recall_score(y_test,lr.predict(x_test)))\n",
    "print(metrics.classification_report(y_test,lr.predict(x_test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,lr.predict(x_test)))\n",
    "accuracy['lr']=metrics.accuracy_score(y_test,lr.predict(x_test))\n",
    "recall['lr']=metrics.recall_score(y_test,lr.predict(x_test))\n",
    "f1['lr']=metrics.f1_score(y_test,lr.predict(x_test))\n",
    "precision['lr']=metrics.precision_score(y_test,lr.predict(x_test))\n",
    "models['lr']=lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b700e85a",
   "metadata": {},
   "source": [
    "#### roc-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "121a246a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc=metrics.roc_auc_score(y_test,.predict(x_test))\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,.predict_proba(x_test)[:,1])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr,tpr,color=\"blue\",label=\"logit model(area= %0.2f)\"%auc)\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate (1-true negative rate)\",size=12)\n",
    "plt.ylabel(\"True Positive Rate\",size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23db5d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ecf98",
   "metadata": {},
   "source": [
    "### decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fe9cfe",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "910b6fa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(),\n",
       "             param_grid=[{'max_depth': [1, 2, 3, 4, 5]}], scoring='recall')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_grid = [{'max_depth':[1,2,3,4,5]}]\n",
    "dt=DecisionTreeClassifier(criterion='gini')\n",
    "gsdt = GridSearchCV(dt,param_grid,scoring='recall',cv=kfold)\n",
    "gsdt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eda58501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 2}, 0.7874816729310963)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdt.best_params_ , gsdt.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67763b30",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35c677e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7175\n",
      "0.7937293729372937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       594\n",
      "           1       0.69      0.79      0.74       606\n",
      "\n",
      "    accuracy                           0.72      1200\n",
      "   macro avg       0.72      0.72      0.72      1200\n",
      "weighted avg       0.72      0.72      0.72      1200\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[380 214]\n",
      " [125 481]]\n"
     ]
    }
   ],
   "source": [
    "models['Decision Tree']=DecisionTreeClassifier(max_depth=2,criterion='gini')\n",
    "dt=DecisionTreeClassifier(max_depth=2,criterion='gini')\n",
    "dt.fit(x_train,y_train)\n",
    "print(metrics.accuracy_score(y_test,dt.predict(x_test)))\n",
    "print(metrics.recall_score(y_test,dt.predict(x_test)))\n",
    "print(metrics.classification_report(y_test,dt.predict(x_test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,dt.predict(x_test)))\n",
    "accuracy['dt']=metrics.accuracy_score(y_test,dt.predict(x_test))\n",
    "recall['dt']=metrics.recall_score(y_test,dt.predict(x_test))\n",
    "precision['dt']=metrics.precision_score(y_test,dt.predict(x_test))\n",
    "f1['dt']=metrics.f1_score(y_test,dt.predict(x_test))\n",
    "models['dt']=dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e954a0c2",
   "metadata": {},
   "source": [
    "#### roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b16d1fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc=metrics.roc_auc_score(y_test,dt.predict(x_test))\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,dt.predict_proba(x_test)[:,1])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr,tpr,color=\"blue\",label=\"logit model(area= %0.2f)\"%auc)\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate (1-true negative rate)\",size=12)\n",
    "plt.ylabel(\"True Positive Rate\",size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae94e6",
   "metadata": {},
   "source": [
    "### KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42d7e3",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93fe3f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid=[{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                          22, 23, 24, 25, 26, 27, 28, 29, 30, ...],\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_range=range(1,100)\n",
    "param_grid = [{'weights':['uniform','distance'],'n_neighbors':list(k_range)}]\n",
    "knn=KNeighborsClassifier()\n",
    "gsknn = GridSearchCV(knn,param_grid,scoring='recall',n_jobs=-1,cv=kfold)\n",
    "gsknn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abb2c2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_neighbors': 34, 'weights': 'distance'}, 0.768337860286967)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsknn.best_params_ , gsknn.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb99d3",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52763d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7483333333333333\n",
      "0.7937293729372937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73       594\n",
      "           1       0.73      0.79      0.76       606\n",
      "\n",
      "    accuracy                           0.75      1200\n",
      "   macro avg       0.75      0.75      0.75      1200\n",
      "weighted avg       0.75      0.75      0.75      1200\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[417 177]\n",
      " [125 481]]\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=34,weights='distance')\n",
    "knn.fit(x_train,y_train)\n",
    "print(metrics.accuracy_score(y_test,knn.predict(x_test)))\n",
    "print(metrics.recall_score(y_test,knn.predict(x_test)))\n",
    "print(metrics.classification_report(y_test,knn.predict(x_test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,knn.predict(x_test)))\n",
    "accuracy['knn']=metrics.accuracy_score(y_test,knn.predict(x_test))\n",
    "recall['knn']=metrics.recall_score(y_test,knn.predict(x_test))\n",
    "precision['knn']=metrics.precision_score(y_test,knn.predict(x_test))\n",
    "f1['knn']=metrics.f1_score(y_test,knn.predict(x_test))\n",
    "models['knn']=knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b1c77",
   "metadata": {},
   "source": [
    "#### roc-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32f4d4f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc=metrics.roc_auc_score(y_test,knn.predict(x_test))\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,knn.predict_proba(x_test)[:,1])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr,tpr,color=\"blue\",label=\"logit model(area= %0.2f)\"%auc)\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate (1-true negative rate)\",size=12)\n",
    "plt.ylabel(\"True Positive Rate\",size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64503676",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cc755",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47c52941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7533333333333333\n",
      "0.7442244224422442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       594\n",
      "           1       0.76      0.74      0.75       606\n",
      "\n",
      "    accuracy                           0.75      1200\n",
      "   macro avg       0.75      0.75      0.75      1200\n",
      "weighted avg       0.75      0.75      0.75      1200\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[453 141]\n",
      " [155 451]]\n"
     ]
    }
   ],
   "source": [
    "nb=GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(metrics.accuracy_score(y_test,nb.predict(x_test)))\n",
    "print(metrics.recall_score(y_test,nb.predict(x_test)))\n",
    "print(metrics.classification_report(y_test,nb.predict(x_test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,nb.predict(x_test)))\n",
    "accuracy['nb']=metrics.accuracy_score(y_test,nb.predict(x_test))\n",
    "recall['nb']=metrics.recall_score(y_test,nb.predict(x_test))\n",
    "precision['nb']=metrics.precision_score(y_test,nb.predict(x_test))\n",
    "f1['nb']=metrics.f1_score(y_test,nb.predict(x_test))\n",
    "models['nb']=nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d6969",
   "metadata": {},
   "source": [
    "#### roc-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6dc5cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc=metrics.roc_auc_score(y_test,nb.predict(x_test))\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,nb.predict_proba(x_test)[:,1])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr,tpr,color=\"blue\",label=\"logit model(area= %0.2f)\"%auc)\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate (1-true negative rate)\",size=12)\n",
    "plt.ylabel(\"True Positive Rate\",size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f0807d",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35ef45",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "923c00e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=SVC(), n_jobs=-1,\n",
       "             param_grid=[{'C': [15, 14, 13, 12, 11, 10, 0.1, 0.001, 0.0001],\n",
       "                          'gamma': [100, 50, 0.5, 0.1, 0.01, 0.001, 0.0001],\n",
       "                          'kernel': ['rbf']}],\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "param_grid = [{'kernel':['rbf'],'gamma':[100,50,0.5,0.1,0.01,0.001,0.0001],\n",
    "               'C':[15,14,13,12,11,10,0.1,0.001,0.0001]}]\n",
    "gsv = GridSearchCV(svm,param_grid,scoring='f1',n_jobs=-1,cv=kfold)\n",
    "gsv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08c74a17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 11, 'gamma': 0.01, 'kernel': 'rbf'}, 0.7613616025309737)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsv.best_params_ , gsv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18badffd",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52441bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745\n",
      "0.8102310231023102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.72       594\n",
      "           1       0.72      0.81      0.76       606\n",
      "\n",
      "    accuracy                           0.74      1200\n",
      "   macro avg       0.75      0.74      0.74      1200\n",
      "weighted avg       0.75      0.74      0.74      1200\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[403 191]\n",
      " [115 491]]\n"
     ]
    }
   ],
   "source": [
    "model_SVM=SVC(kernel='rbf',gamma=0.01,C=0.01,probability=True)\n",
    "model_SVM.fit(x_train,y_train)\n",
    "print(metrics.accuracy_score(y_test,model_SVM.predict(x_test)))\n",
    "print(metrics.recall_score(y_test,model_SVM.predict(x_test)))\n",
    "print(metrics.classification_report(y_test,model_SVM.predict(x_test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,model_SVM.predict(x_test)))\n",
    "accuracy['SVM']=metrics.accuracy_score(y_test,model_SVM.predict(x_test))\n",
    "recall['SVM']=metrics.recall_score(y_test,model_SVM.predict(x_test))\n",
    "precision['SVM']=metrics.precision_score(y_test,model_SVM.predict(x_test))\n",
    "f1['SVM']=metrics.f1_score(y_test,model_SVM.predict(x_test))\n",
    "models['SVM']=model_SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf548025",
   "metadata": {},
   "source": [
    "#### roc-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c06d5b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc=metrics.roc_auc_score(y_test,model_SVM.predict(x_test))\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,model_SVM.predict_proba(x_test)[:,1])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr,tpr,color=\"blue\",label=\"logit model(area= %0.2f)\"%auc)\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate (1-true negative rate)\",size=12)\n",
    "plt.ylabel(\"True Positive Rate\",size=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17318f3",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0b859ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61703d3",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0931aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid=[{'n_estimators':[200,400,600,800,1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f13ef74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 400}, 0.7304981433703521)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1,criterion='gini'),random_state=7)\n",
    "gsada=GridSearchCV(ada,param_grid,n_jobs=-1,scoring='recall',cv=kfold)\n",
    "gsada.fit(x_train,y_train)\n",
    "gsada.best_params_ , gsada.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0233f63",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90c128b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7433333333333333\n",
      "0.7623762376237624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74       594\n",
      "           1       0.74      0.76      0.75       606\n",
      "\n",
      "    accuracy                           0.74      1200\n",
      "   macro avg       0.74      0.74      0.74      1200\n",
      "weighted avg       0.74      0.74      0.74      1200\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[430 164]\n",
      " [144 462]]\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1,criterion='gini'),random_state=7,n_estimators=400)\n",
    "ada.fit(x_train,y_train)\n",
    "print(metrics.accuracy_score(y_test,ada.predict(x_test)))\n",
    "print(metrics.recall_score(y_test,ada.predict(x_test)))\n",
    "print(metrics.classification_report(y_test,ada.predict(x_test)))\n",
    "print(metrics.confusion_matrix(y_test,ada.predict(x_test)))\n",
    "accuracy['ada']=metrics.accuracy_score(y_test,ada.predict(x_test))\n",
    "recall['ada']=metrics.recall_score(y_test,ada.predict(x_test))\n",
    "precision['ada']=metrics.precision_score(y_test,ada.predict(x_test))\n",
    "f1['ada']=metrics.f1_score(y_test,ada.predict(x_test))\n",
    "models['ada']=ada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989366fb",
   "metadata": {},
   "source": [
    "#### roc-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "450ea026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc=metrics.roc_auc_score(y_test,ada.predict(x_test))\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,ada.predict_proba(x_test)[:,1])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr,tpr,color=\"blue\",label=\"logit model(area= %0.2f)\"%auc)\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate (1-true negative rate)\",size=12)\n",
    "plt.ylabel(\"True Positive Rate\",size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef35f06",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cddb47",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4938ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',\n",
       "                                                                               max_depth=3),\n",
       "                                         random_state=7),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'max_samples': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
       "                          'n_estimators': range(1, 101)}],\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid=[{'n_estimators':range(1,101),'max_samples':[0.2,0.4,0.6,0.8,1.0]}]\n",
    "bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,criterion='entropy'),random_state=7)\n",
    "gsb = GridSearchCV(bagging,param_grid,scoring='f1',n_jobs=-1,cv=kfold)\n",
    "gsb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dec08566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_samples': 0.2, 'n_estimators': 17}, 0.7475700503216283)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsb.best_params_ , gsb.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0deecb5",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcaf9dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7516666666666667\n",
      "0.7722772277227723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74       594\n",
      "           1       0.75      0.77      0.76       606\n",
      "\n",
      "    accuracy                           0.75      1200\n",
      "   macro avg       0.75      0.75      0.75      1200\n",
      "weighted avg       0.75      0.75      0.75      1200\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[434 160]\n",
      " [138 468]]\n"
     ]
    }
   ],
   "source": [
    "bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,criterion='entropy'),n_estimators=17,max_samples=0.2,random_state=7)\n",
    "bagging.fit(x_train,y_train)\n",
    "print(metrics.accuracy_score(y_test,bagging.predict(x_test)))\n",
    "print(metrics.recall_score(y_test,bagging.predict(x_test)))\n",
    "print(metrics.classification_report(y_test,bagging.predict(x_test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,bagging.predict(x_test)))\n",
    "accuracy['bagging']=metrics.accuracy_score(y_test,bagging.predict(x_test))\n",
    "recall['bagging']=metrics.recall_score(y_test,bagging.predict(x_test))\n",
    "precision['bagging']=metrics.precision_score(y_test,bagging.predict(x_test))\n",
    "f1['bagging']=metrics.f1_score(y_test,bagging.predict(x_test))\n",
    "models['bagging']=bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328e1ee",
   "metadata": {},
   "source": [
    "#### roc-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f2dd579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc=metrics.roc_auc_score(y_test,bagging.predict(x_test))\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,bagging.predict_proba(x_test)[:,1])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr,tpr,color=\"blue\",label=\"logit model(area= %0.2f)\"%auc)\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate (1-true negative rate)\",size=12)\n",
    "plt.ylabel(\"True Positive Rate\",size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1038b7c1",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7202d",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e1c420e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=3, max_features=4,\n",
       "                                              random_state=23),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'max_depth': [2, 3, 4, 5],\n",
       "                          'n_estimators': range(64, 125)}],\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid=[{'n_estimators':range(64,125),'max_depth':[2,3,4,5]}]\n",
    "rf = RandomForestClassifier(max_features=4,max_depth=3,criterion='gini',random_state=23)\n",
    "gsrf = GridSearchCV(rf,param_grid,scoring='recall',n_jobs=-1,cv=kfold)\n",
    "gsrf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e6a0dc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 2, 'n_estimators': 107}, 0.7891963966425528)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.best_params_ , gsrf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1c50a",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6134a285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7408333333333333\n",
      "0.8267326732673267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71       594\n",
      "           1       0.71      0.83      0.76       606\n",
      "\n",
      "    accuracy                           0.74      1200\n",
      "   macro avg       0.75      0.74      0.74      1200\n",
      "weighted avg       0.75      0.74      0.74      1200\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[388 206]\n",
      " [105 501]]\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=107,max_depth=2, max_features=4,criterion='gini',random_state=23)\n",
    "model_rf.fit(x_train,y_train)\n",
    "print(metrics.accuracy_score(y_test,model_rf.predict(x_test)))\n",
    "print(metrics.recall_score(y_test,model_rf.predict(x_test)))\n",
    "print(metrics.classification_report(y_test,model_rf.predict(x_test)))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,model_rf.predict(x_test)))\n",
    "accuracy['rf']=metrics.accuracy_score(y_test,model_rf.predict(x_test))\n",
    "recall['rf']=metrics.recall_score(y_test,model_rf.predict(x_test))\n",
    "precision['rf']=metrics.precision_score(y_test,model_rf.predict(x_test))\n",
    "f1['rf']=metrics.f1_score(y_test,model_rf.predict(x_test))\n",
    "models['rf']=model_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e6a5c",
   "metadata": {},
   "source": [
    "#### roc-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eeb5cc9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc=metrics.roc_auc_score(y_test,model_rf.predict(x_test))\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,model_rf.predict_proba(x_test)[:,1])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr,tpr,color=\"blue\",label=\"logit model(area= %0.2f)\"%auc)\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate (1-true negative rate)\",size=12)\n",
    "plt.ylabel(\"True Positive Rate\",size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f38c0a",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a124c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c4e7c",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "202fecc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=LGBMClassifier(learning_rate=0.09, random_state=42),\n",
       "             n_jobs=-1, param_grid=[{'max_depth': [2, 3, 4, 5]}],\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_grid=[{'max_depth':[2,3,4,5]}]\n",
    "model_lgb = lgb.LGBMClassifier(learning_rate=0.09,random_state=42)\n",
    "gslgb = GridSearchCV(model_lgb,param_grid,scoring='recall',n_jobs=-1,cv=kfold)\n",
    "gslgb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f03d4ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 4}, 0.7722174355073113)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gslgb.best_params_ , gslgb.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611b5db",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87d220b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.09, max_depth=4, random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm=lgb.LGBMClassifier(learning_rate=0.09,random_state=42,max_depth=4)\n",
    "lgbm.fit(x_train,y_train,eval_metric='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "17510200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7566666666666667\n",
      "0.806930693069307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       594\n",
      "           1       0.74      0.81      0.77       606\n",
      "\n",
      "    accuracy                           0.76      1200\n",
      "   macro avg       0.76      0.76      0.76      1200\n",
      "weighted avg       0.76      0.76      0.76      1200\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[419 175]\n",
      " [117 489]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=lgbm.predict(x_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "print(metrics.recall_score(y_test,y_pred))\n",
    "print(metrics.classification_report(y_test,y_pred))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,y_pred))\n",
    "accuracy['lgbm']=metrics.accuracy_score(y_test,y_pred)\n",
    "recall['lgbm']=metrics.recall_score(y_test,y_pred)\n",
    "precision['lgbm']=metrics.precision_score(y_test,y_pred)\n",
    "f1['lgbm']=metrics.f1_score(y_test,y_pred)\n",
    "models['lgbm']=lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97c6df",
   "metadata": {},
   "source": [
    "#### roc-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "285442a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc=metrics.roc_auc_score(y_test,lgbm.predict(x_test))\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,lgbm.predict_proba(x_test)[:,1])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr,tpr,color=\"blue\",label=\"logit model(area= %0.2f)\"%auc)\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate (1-true negative rate)\",size=12)\n",
    "plt.ylabel(\"True Positive Rate\",size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5c31c3",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec57fb9",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35fa6474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "65/65 [==============================] - 2s 8ms/step - loss: 0.6931 - accuracy: 0.5126 - val_loss: 0.6929 - val_accuracy: 0.5180\n",
      "Epoch 2/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.5163 - val_loss: 0.6927 - val_accuracy: 0.5180\n",
      "Epoch 3/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5163 - val_loss: 0.6927 - val_accuracy: 0.5180\n",
      "Epoch 4/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.5180\n",
      "Epoch 5/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.5180\n",
      "Epoch 6/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.5180\n",
      "Epoch 7/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.5180\n",
      "Epoch 8/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 9/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 10/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 11/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 12/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 13/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 14/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 15/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 16/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 17/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 18/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 19/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 20/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 21/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 22/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 23/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 24/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 25/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 26/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 27/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 28/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 29/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 30/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 31/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 32/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 33/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 34/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 35/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 36/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 37/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 38/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 39/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 40/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 41/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 42/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 43/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 44/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 45/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 46/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 47/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 48/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 49/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 50/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 51/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 52/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 53/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 54/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 55/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 56/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 57/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 58/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 60/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 61/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 62/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 63/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 64/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 65/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 66/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 67/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 68/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 69/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 70/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 71/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 72/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 73/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 74/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 75/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 76/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 77/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 78/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 79/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 80/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 81/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 82/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 83/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 84/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 85/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 86/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 87/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 88/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 89/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 90/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 91/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 92/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 93/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 94/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 95/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 96/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 97/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 98/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 99/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 100/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 101/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 102/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 103/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 104/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 105/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 106/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 107/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 108/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 109/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 110/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 111/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 112/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 113/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 114/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 115/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 116/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 117/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 118/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 119/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 120/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 121/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 122/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 123/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 124/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 125/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 126/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 127/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 128/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 129/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 130/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 131/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 132/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 133/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 134/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 135/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 136/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 137/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 138/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 139/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 140/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 141/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 142/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 143/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 144/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 145/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 146/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 147/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 148/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 149/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 150/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 151/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 152/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 153/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 154/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 155/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 156/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 157/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 158/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 159/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 160/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 161/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 162/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 163/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 164/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 165/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 166/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 167/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 168/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 169/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 170/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 171/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 172/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 174/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 175/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 176/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 177/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 178/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 179/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 180/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 181/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 182/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 183/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 184/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 185/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 186/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 187/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 188/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 189/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 190/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 191/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 192/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 193/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 194/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 195/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 196/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 197/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 198/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 199/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 200/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 201/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 202/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 203/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 204/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 205/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 206/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 207/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 208/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 209/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 210/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 211/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 212/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 213/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 214/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 215/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 216/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 217/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 218/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 219/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 220/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 221/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 222/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 223/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 224/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 225/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 226/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 227/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 228/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 229/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 230/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 231/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 232/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 233/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 234/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 235/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 236/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 237/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 238/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 239/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 240/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 241/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 242/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 243/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 244/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 245/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 246/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 247/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 248/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 249/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 250/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "65/65 [==============================] - 1s 7ms/step - loss: 0.7002 - accuracy: 0.5253 - val_loss: 0.6960 - val_accuracy: 0.5388\n",
      "Epoch 2/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.5537 - val_loss: 0.6921 - val_accuracy: 0.5634\n",
      "Epoch 3/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6903 - accuracy: 0.5919 - val_loss: 0.6873 - val_accuracy: 0.6265\n",
      "Epoch 4/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.6460 - val_loss: 0.6797 - val_accuracy: 0.6801\n",
      "Epoch 5/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.6837 - val_loss: 0.6693 - val_accuracy: 0.7016\n",
      "Epoch 6/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.7017 - val_loss: 0.6516 - val_accuracy: 0.7186\n",
      "Epoch 7/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.7135 - val_loss: 0.6322 - val_accuracy: 0.7256\n",
      "Epoch 8/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.7213 - val_loss: 0.6131 - val_accuracy: 0.7306\n",
      "Epoch 9/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.7260 - val_loss: 0.5962 - val_accuracy: 0.7375\n",
      "Epoch 10/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.7334 - val_loss: 0.5838 - val_accuracy: 0.7382\n",
      "Epoch 11/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7347 - val_loss: 0.5735 - val_accuracy: 0.7382\n",
      "Epoch 12/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7397 - val_loss: 0.5651 - val_accuracy: 0.7438\n",
      "Epoch 13/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7421 - val_loss: 0.5585 - val_accuracy: 0.7457\n",
      "Epoch 14/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7440 - val_loss: 0.5539 - val_accuracy: 0.7451\n",
      "Epoch 15/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.7484 - val_loss: 0.5500 - val_accuracy: 0.7476\n",
      "Epoch 16/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7484 - val_loss: 0.5470 - val_accuracy: 0.7495\n",
      "Epoch 17/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7515 - val_loss: 0.5443 - val_accuracy: 0.7445\n",
      "Epoch 18/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7481 - val_loss: 0.5415 - val_accuracy: 0.7483\n",
      "Epoch 19/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7484 - val_loss: 0.5395 - val_accuracy: 0.7426\n",
      "Epoch 20/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7496 - val_loss: 0.5377 - val_accuracy: 0.7388\n",
      "Epoch 21/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7484 - val_loss: 0.5361 - val_accuracy: 0.7382\n",
      "Epoch 22/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7474 - val_loss: 0.5348 - val_accuracy: 0.7401\n",
      "Epoch 23/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7502 - val_loss: 0.5333 - val_accuracy: 0.7413\n",
      "Epoch 24/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7505 - val_loss: 0.5321 - val_accuracy: 0.7388\n",
      "Epoch 25/250\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7499 - val_loss: 0.5311 - val_accuracy: 0.7407\n",
      "Epoch 26/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7512 - val_loss: 0.5304 - val_accuracy: 0.7401\n",
      "Epoch 27/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7505 - val_loss: 0.5292 - val_accuracy: 0.7388\n",
      "Epoch 28/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7499 - val_loss: 0.5285 - val_accuracy: 0.7407\n",
      "Epoch 29/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7509 - val_loss: 0.5276 - val_accuracy: 0.7413\n",
      "Epoch 30/250\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7499 - val_loss: 0.5267 - val_accuracy: 0.7420\n",
      "Epoch 31/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7496 - val_loss: 0.5259 - val_accuracy: 0.7420\n",
      "Epoch 32/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7471 - val_loss: 0.5250 - val_accuracy: 0.7413\n",
      "Epoch 33/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7502 - val_loss: 0.5239 - val_accuracy: 0.7420\n",
      "Epoch 34/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7499 - val_loss: 0.5232 - val_accuracy: 0.7426\n",
      "Epoch 35/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7499 - val_loss: 0.5224 - val_accuracy: 0.7432\n",
      "Epoch 36/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7505 - val_loss: 0.5217 - val_accuracy: 0.7438\n",
      "Epoch 37/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7496 - val_loss: 0.5207 - val_accuracy: 0.7420\n",
      "Epoch 38/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7496 - val_loss: 0.5198 - val_accuracy: 0.7407\n",
      "Epoch 39/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7521 - val_loss: 0.5189 - val_accuracy: 0.7401\n",
      "Epoch 40/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7474 - val_loss: 0.5183 - val_accuracy: 0.7413\n",
      "Epoch 41/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7505 - val_loss: 0.5177 - val_accuracy: 0.7407\n",
      "Epoch 42/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7490 - val_loss: 0.5174 - val_accuracy: 0.7413\n",
      "Epoch 43/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7499 - val_loss: 0.5170 - val_accuracy: 0.7394\n",
      "Epoch 44/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7502 - val_loss: 0.5163 - val_accuracy: 0.7401\n",
      "Epoch 45/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7490 - val_loss: 0.5159 - val_accuracy: 0.7394\n",
      "Epoch 46/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7493 - val_loss: 0.5157 - val_accuracy: 0.7394\n",
      "Epoch 47/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7493 - val_loss: 0.5151 - val_accuracy: 0.7388\n",
      "Epoch 48/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7487 - val_loss: 0.5146 - val_accuracy: 0.7394\n",
      "Epoch 49/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7499 - val_loss: 0.5142 - val_accuracy: 0.7394\n",
      "Epoch 50/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7474 - val_loss: 0.5141 - val_accuracy: 0.7401\n",
      "Epoch 51/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7509 - val_loss: 0.5137 - val_accuracy: 0.7445\n",
      "Epoch 52/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7474 - val_loss: 0.5134 - val_accuracy: 0.7401\n",
      "Epoch 53/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7477 - val_loss: 0.5132 - val_accuracy: 0.7401\n",
      "Epoch 54/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7502 - val_loss: 0.5127 - val_accuracy: 0.7426\n",
      "Epoch 55/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7490 - val_loss: 0.5124 - val_accuracy: 0.7413\n",
      "Epoch 56/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7477 - val_loss: 0.5125 - val_accuracy: 0.7401\n",
      "Epoch 57/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7490 - val_loss: 0.5120 - val_accuracy: 0.7451\n",
      "Epoch 58/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7474 - val_loss: 0.5119 - val_accuracy: 0.7426\n",
      "Epoch 59/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7481 - val_loss: 0.5119 - val_accuracy: 0.7394\n",
      "Epoch 60/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7471 - val_loss: 0.5114 - val_accuracy: 0.7394\n",
      "Epoch 61/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7518 - val_loss: 0.5112 - val_accuracy: 0.7420\n",
      "Epoch 62/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7481 - val_loss: 0.5110 - val_accuracy: 0.7438\n",
      "Epoch 63/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7477 - val_loss: 0.5109 - val_accuracy: 0.7407\n",
      "Epoch 64/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7518 - val_loss: 0.5105 - val_accuracy: 0.7445\n",
      "Epoch 65/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7477 - val_loss: 0.5104 - val_accuracy: 0.7438\n",
      "Epoch 66/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7477 - val_loss: 0.5102 - val_accuracy: 0.7394\n",
      "Epoch 67/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7496 - val_loss: 0.5102 - val_accuracy: 0.7438\n",
      "Epoch 68/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7496 - val_loss: 0.5098 - val_accuracy: 0.7445\n",
      "Epoch 69/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7493 - val_loss: 0.5099 - val_accuracy: 0.7445\n",
      "Epoch 70/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7487 - val_loss: 0.5097 - val_accuracy: 0.7438\n",
      "Epoch 71/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7471 - val_loss: 0.5098 - val_accuracy: 0.7394\n",
      "Epoch 72/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7499 - val_loss: 0.5093 - val_accuracy: 0.7420\n",
      "Epoch 73/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7481 - val_loss: 0.5094 - val_accuracy: 0.7413\n",
      "Epoch 74/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7465 - val_loss: 0.5092 - val_accuracy: 0.7413\n",
      "Epoch 75/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7426\n",
      "Epoch 76/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7468 - val_loss: 0.5092 - val_accuracy: 0.7413\n",
      "Epoch 77/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7471 - val_loss: 0.5090 - val_accuracy: 0.7413\n",
      "Epoch 78/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7496 - val_loss: 0.5090 - val_accuracy: 0.7401\n",
      "Epoch 79/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7481 - val_loss: 0.5088 - val_accuracy: 0.7426\n",
      "Epoch 80/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7487 - val_loss: 0.5087 - val_accuracy: 0.7413\n",
      "Epoch 81/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7499 - val_loss: 0.5089 - val_accuracy: 0.7394\n",
      "Epoch 82/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7502 - val_loss: 0.5087 - val_accuracy: 0.7420\n",
      "Epoch 83/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7471 - val_loss: 0.5088 - val_accuracy: 0.7394\n",
      "Epoch 84/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7493 - val_loss: 0.5084 - val_accuracy: 0.7407\n",
      "Epoch 85/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7484 - val_loss: 0.5084 - val_accuracy: 0.7401\n",
      "Epoch 86/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7484 - val_loss: 0.5085 - val_accuracy: 0.7401\n",
      "Epoch 87/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7487 - val_loss: 0.5081 - val_accuracy: 0.7401\n",
      "Epoch 88/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7499 - val_loss: 0.5084 - val_accuracy: 0.7407\n",
      "Epoch 89/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7484 - val_loss: 0.5082 - val_accuracy: 0.7388\n",
      "Epoch 90/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7474 - val_loss: 0.5081 - val_accuracy: 0.7401\n",
      "Epoch 91/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7375\n",
      "Epoch 92/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7490 - val_loss: 0.5079 - val_accuracy: 0.7375\n",
      "Epoch 93/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7487 - val_loss: 0.5078 - val_accuracy: 0.7401\n",
      "Epoch 94/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7490 - val_loss: 0.5078 - val_accuracy: 0.7426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7490 - val_loss: 0.5077 - val_accuracy: 0.7407\n",
      "Epoch 96/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7481 - val_loss: 0.5078 - val_accuracy: 0.7413\n",
      "Epoch 97/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7487 - val_loss: 0.5078 - val_accuracy: 0.7445\n",
      "Epoch 98/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7468 - val_loss: 0.5076 - val_accuracy: 0.7413\n",
      "Epoch 99/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7487 - val_loss: 0.5075 - val_accuracy: 0.7401\n",
      "Epoch 100/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7477 - val_loss: 0.5075 - val_accuracy: 0.7401\n",
      "Epoch 101/250\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7471 - val_loss: 0.5076 - val_accuracy: 0.7350\n",
      "Epoch 102/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7484 - val_loss: 0.5074 - val_accuracy: 0.7369\n",
      "Epoch 103/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7420\n",
      "Epoch 104/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7462 - val_loss: 0.5073 - val_accuracy: 0.7394\n",
      "Epoch 105/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7493 - val_loss: 0.5074 - val_accuracy: 0.7388\n",
      "Epoch 106/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7487 - val_loss: 0.5074 - val_accuracy: 0.7382\n",
      "Epoch 107/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7484 - val_loss: 0.5074 - val_accuracy: 0.7382\n",
      "Epoch 108/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7474 - val_loss: 0.5074 - val_accuracy: 0.7388\n",
      "Epoch 109/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7496 - val_loss: 0.5075 - val_accuracy: 0.7388\n",
      "Epoch 110/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7465 - val_loss: 0.5074 - val_accuracy: 0.7363\n",
      "Epoch 111/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7471 - val_loss: 0.5073 - val_accuracy: 0.7369\n",
      "Epoch 112/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7499 - val_loss: 0.5074 - val_accuracy: 0.7382\n",
      "Epoch 113/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7493 - val_loss: 0.5072 - val_accuracy: 0.7369\n",
      "Epoch 114/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7484 - val_loss: 0.5073 - val_accuracy: 0.7382\n",
      "Epoch 115/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7477 - val_loss: 0.5076 - val_accuracy: 0.7388\n",
      "Epoch 116/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7394\n",
      "Epoch 117/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7490 - val_loss: 0.5076 - val_accuracy: 0.7369\n",
      "Epoch 118/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7487 - val_loss: 0.5077 - val_accuracy: 0.7369\n",
      "Epoch 119/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7496 - val_loss: 0.5074 - val_accuracy: 0.7356\n",
      "Epoch 120/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7518 - val_loss: 0.5076 - val_accuracy: 0.7363\n",
      "Epoch 121/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7481 - val_loss: 0.5073 - val_accuracy: 0.7350\n",
      "Epoch 122/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
      "Epoch 123/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7356\n",
      "Epoch 124/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7493 - val_loss: 0.5075 - val_accuracy: 0.7356\n",
      "Epoch 125/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7487 - val_loss: 0.5074 - val_accuracy: 0.7356\n",
      "Epoch 126/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7481 - val_loss: 0.5071 - val_accuracy: 0.7331\n",
      "Epoch 127/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7509 - val_loss: 0.5075 - val_accuracy: 0.7350\n",
      "Epoch 128/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7338\n",
      "Epoch 129/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7490 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
      "Epoch 130/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7487 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
      "Epoch 131/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7496 - val_loss: 0.5072 - val_accuracy: 0.7338\n",
      "Epoch 132/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7484 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
      "Epoch 133/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7481 - val_loss: 0.5071 - val_accuracy: 0.7356\n",
      "Epoch 134/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7484 - val_loss: 0.5073 - val_accuracy: 0.7363\n",
      "Epoch 135/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7477 - val_loss: 0.5071 - val_accuracy: 0.7338\n",
      "Epoch 136/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
      "Epoch 137/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7487 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
      "Epoch 138/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7515 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
      "Epoch 139/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7490 - val_loss: 0.5068 - val_accuracy: 0.7338\n",
      "Epoch 140/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7499 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
      "Epoch 141/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7490 - val_loss: 0.5070 - val_accuracy: 0.7338\n",
      "Epoch 142/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7493 - val_loss: 0.5070 - val_accuracy: 0.7356\n",
      "Epoch 143/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7505 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
      "Epoch 144/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7490 - val_loss: 0.5071 - val_accuracy: 0.7350\n",
      "Epoch 145/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7471 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
      "Epoch 146/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7449 - val_loss: 0.5070 - val_accuracy: 0.7338\n",
      "Epoch 147/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7484 - val_loss: 0.5071 - val_accuracy: 0.7338\n",
      "Epoch 148/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7496 - val_loss: 0.5068 - val_accuracy: 0.7338\n",
      "Epoch 149/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7481 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
      "Epoch 150/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7490 - val_loss: 0.5072 - val_accuracy: 0.7338\n",
      "Epoch 151/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7493 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
      "Epoch 152/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7487 - val_loss: 0.5071 - val_accuracy: 0.7350\n",
      "Epoch 153/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7477 - val_loss: 0.5070 - val_accuracy: 0.7331\n",
      "Epoch 154/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7496 - val_loss: 0.5071 - val_accuracy: 0.7350\n",
      "Epoch 155/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7505 - val_loss: 0.5071 - val_accuracy: 0.7350\n",
      "Epoch 156/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7481 - val_loss: 0.5070 - val_accuracy: 0.7350\n",
      "Epoch 157/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7474 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
      "Epoch 158/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7474 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
      "Epoch 159/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7490 - val_loss: 0.5070 - val_accuracy: 0.7338\n",
      "Epoch 160/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7325\n",
      "Epoch 161/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7477 - val_loss: 0.5074 - val_accuracy: 0.7338\n",
      "Epoch 162/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7487 - val_loss: 0.5074 - val_accuracy: 0.7331\n",
      "Epoch 163/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7496 - val_loss: 0.5073 - val_accuracy: 0.7356\n",
      "Epoch 164/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7484 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
      "Epoch 165/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7496 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
      "Epoch 166/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7496 - val_loss: 0.5076 - val_accuracy: 0.7350\n",
      "Epoch 167/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7477 - val_loss: 0.5072 - val_accuracy: 0.7350\n",
      "Epoch 168/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7477 - val_loss: 0.5072 - val_accuracy: 0.7338\n",
      "Epoch 169/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7477 - val_loss: 0.5069 - val_accuracy: 0.7338\n",
      "Epoch 170/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7484 - val_loss: 0.5074 - val_accuracy: 0.7325\n",
      "Epoch 171/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7484 - val_loss: 0.5073 - val_accuracy: 0.7338\n",
      "Epoch 172/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7487 - val_loss: 0.5071 - val_accuracy: 0.7331\n",
      "Epoch 173/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7471 - val_loss: 0.5075 - val_accuracy: 0.7350\n",
      "Epoch 174/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7350\n",
      "Epoch 175/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7487 - val_loss: 0.5071 - val_accuracy: 0.7350\n",
      "Epoch 176/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7481 - val_loss: 0.5073 - val_accuracy: 0.7338\n",
      "Epoch 177/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7471 - val_loss: 0.5072 - val_accuracy: 0.7338\n",
      "Epoch 178/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7474 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
      "Epoch 179/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7490 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
      "Epoch 180/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7490 - val_loss: 0.5073 - val_accuracy: 0.7338\n",
      "Epoch 181/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7481 - val_loss: 0.5074 - val_accuracy: 0.7338\n",
      "Epoch 182/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7490 - val_loss: 0.5074 - val_accuracy: 0.7338\n",
      "Epoch 183/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7499 - val_loss: 0.5071 - val_accuracy: 0.7338\n",
      "Epoch 184/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7496 - val_loss: 0.5077 - val_accuracy: 0.7331\n",
      "Epoch 185/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7502 - val_loss: 0.5072 - val_accuracy: 0.7325\n",
      "Epoch 186/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7484 - val_loss: 0.5074 - val_accuracy: 0.7338\n",
      "Epoch 187/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7496 - val_loss: 0.5074 - val_accuracy: 0.7338\n",
      "Epoch 188/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7487 - val_loss: 0.5075 - val_accuracy: 0.7338\n",
      "Epoch 189/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7499 - val_loss: 0.5074 - val_accuracy: 0.7331\n",
      "Epoch 190/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7331\n",
      "Epoch 191/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7484 - val_loss: 0.5072 - val_accuracy: 0.7338\n",
      "Epoch 192/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
      "Epoch 193/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7496 - val_loss: 0.5075 - val_accuracy: 0.7338\n",
      "Epoch 194/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7496 - val_loss: 0.5075 - val_accuracy: 0.7338\n",
      "Epoch 195/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7481 - val_loss: 0.5075 - val_accuracy: 0.7325\n",
      "Epoch 196/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7471 - val_loss: 0.5076 - val_accuracy: 0.7331\n",
      "Epoch 197/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7505 - val_loss: 0.5081 - val_accuracy: 0.7350\n",
      "Epoch 198/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7331\n",
      "Epoch 199/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7484 - val_loss: 0.5077 - val_accuracy: 0.7331\n",
      "Epoch 200/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7484 - val_loss: 0.5077 - val_accuracy: 0.7331\n",
      "Epoch 201/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7481 - val_loss: 0.5074 - val_accuracy: 0.7338\n",
      "Epoch 202/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7477 - val_loss: 0.5073 - val_accuracy: 0.7319\n",
      "Epoch 203/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7493 - val_loss: 0.5077 - val_accuracy: 0.7331\n",
      "Epoch 204/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7471 - val_loss: 0.5078 - val_accuracy: 0.7319\n",
      "Epoch 205/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7474 - val_loss: 0.5080 - val_accuracy: 0.7331\n",
      "Epoch 206/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7490 - val_loss: 0.5076 - val_accuracy: 0.7331\n",
      "Epoch 207/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7344\n",
      "Epoch 208/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7481 - val_loss: 0.5077 - val_accuracy: 0.7331\n",
      "Epoch 209/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7496 - val_loss: 0.5076 - val_accuracy: 0.7331\n",
      "Epoch 210/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7484 - val_loss: 0.5077 - val_accuracy: 0.7331\n",
      "Epoch 211/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7493 - val_loss: 0.5078 - val_accuracy: 0.7331\n",
      "Epoch 212/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7468 - val_loss: 0.5079 - val_accuracy: 0.7306\n",
      "Epoch 213/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7493 - val_loss: 0.5079 - val_accuracy: 0.7325\n",
      "Epoch 214/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7477 - val_loss: 0.5076 - val_accuracy: 0.7325\n",
      "Epoch 215/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7474 - val_loss: 0.5077 - val_accuracy: 0.7331\n",
      "Epoch 216/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7493 - val_loss: 0.5079 - val_accuracy: 0.7325\n",
      "Epoch 217/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7474 - val_loss: 0.5079 - val_accuracy: 0.7338\n",
      "Epoch 218/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7477 - val_loss: 0.5078 - val_accuracy: 0.7331\n",
      "Epoch 219/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7493 - val_loss: 0.5078 - val_accuracy: 0.7319\n",
      "Epoch 220/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7487 - val_loss: 0.5073 - val_accuracy: 0.7331\n",
      "Epoch 221/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7487 - val_loss: 0.5079 - val_accuracy: 0.7338\n",
      "Epoch 222/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7477 - val_loss: 0.5076 - val_accuracy: 0.7319\n",
      "Epoch 223/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7481 - val_loss: 0.5080 - val_accuracy: 0.7331\n",
      "Epoch 224/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7477 - val_loss: 0.5078 - val_accuracy: 0.7331\n",
      "Epoch 225/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7468 - val_loss: 0.5079 - val_accuracy: 0.7325\n",
      "Epoch 226/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7490 - val_loss: 0.5076 - val_accuracy: 0.7338\n",
      "Epoch 227/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7325\n",
      "Epoch 228/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7474 - val_loss: 0.5079 - val_accuracy: 0.7331\n",
      "Epoch 229/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7487 - val_loss: 0.5077 - val_accuracy: 0.7331\n",
      "Epoch 230/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7490 - val_loss: 0.5078 - val_accuracy: 0.7331\n",
      "Epoch 231/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7325\n",
      "Epoch 232/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7471 - val_loss: 0.5077 - val_accuracy: 0.7325\n",
      "Epoch 233/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7493 - val_loss: 0.5079 - val_accuracy: 0.7325\n",
      "Epoch 234/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7481 - val_loss: 0.5078 - val_accuracy: 0.7331\n",
      "Epoch 235/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7474 - val_loss: 0.5081 - val_accuracy: 0.7325\n",
      "Epoch 236/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7338\n",
      "Epoch 237/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7484 - val_loss: 0.5076 - val_accuracy: 0.7325\n",
      "Epoch 238/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7465 - val_loss: 0.5081 - val_accuracy: 0.7325\n",
      "Epoch 239/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7481 - val_loss: 0.5080 - val_accuracy: 0.7325\n",
      "Epoch 240/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7477 - val_loss: 0.5079 - val_accuracy: 0.7338\n",
      "Epoch 241/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7331\n",
      "Epoch 242/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7481 - val_loss: 0.5075 - val_accuracy: 0.7338\n",
      "Epoch 243/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7487 - val_loss: 0.5078 - val_accuracy: 0.7325\n",
      "Epoch 244/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7490 - val_loss: 0.5078 - val_accuracy: 0.7325\n",
      "Epoch 245/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7496 - val_loss: 0.5076 - val_accuracy: 0.7331\n",
      "Epoch 246/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7471 - val_loss: 0.5079 - val_accuracy: 0.7331\n",
      "Epoch 247/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7484 - val_loss: 0.5079 - val_accuracy: 0.7331\n",
      "Epoch 248/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7487 - val_loss: 0.5078 - val_accuracy: 0.7331\n",
      "Epoch 249/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7493 - val_loss: 0.5078 - val_accuracy: 0.7325\n",
      "Epoch 250/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7477 - val_loss: 0.5078 - val_accuracy: 0.7331\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "Epoch 1/250\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.7190 - accuracy: 0.4678 - val_loss: 0.7036 - val_accuracy: 0.4625\n",
      "Epoch 2/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5207 - val_loss: 0.6849 - val_accuracy: 0.5521\n",
      "Epoch 3/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.6072 - val_loss: 0.6614 - val_accuracy: 0.6650\n",
      "Epoch 4/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.6681 - val_loss: 0.6336 - val_accuracy: 0.7035\n",
      "Epoch 5/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6967 - val_loss: 0.6103 - val_accuracy: 0.7224\n",
      "Epoch 6/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6058 - accuracy: 0.7260 - val_loss: 0.5951 - val_accuracy: 0.7293\n",
      "Epoch 7/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.7341 - val_loss: 0.5847 - val_accuracy: 0.7325\n",
      "Epoch 8/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.7347 - val_loss: 0.5765 - val_accuracy: 0.7325\n",
      "Epoch 9/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7375 - val_loss: 0.5702 - val_accuracy: 0.7356\n",
      "Epoch 10/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7387 - val_loss: 0.5650 - val_accuracy: 0.7344\n",
      "Epoch 11/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.7421 - val_loss: 0.5607 - val_accuracy: 0.7325\n",
      "Epoch 12/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7440 - val_loss: 0.5567 - val_accuracy: 0.7369\n",
      "Epoch 13/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7456 - val_loss: 0.5540 - val_accuracy: 0.7338\n",
      "Epoch 14/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7477 - val_loss: 0.5515 - val_accuracy: 0.7338\n",
      "Epoch 15/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7446 - val_loss: 0.5496 - val_accuracy: 0.7375\n",
      "Epoch 16/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7465 - val_loss: 0.5475 - val_accuracy: 0.7356\n",
      "Epoch 17/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7453 - val_loss: 0.5460 - val_accuracy: 0.7363\n",
      "Epoch 18/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7462 - val_loss: 0.5440 - val_accuracy: 0.7388\n",
      "Epoch 19/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7443 - val_loss: 0.5431 - val_accuracy: 0.7382\n",
      "Epoch 20/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7449 - val_loss: 0.5409 - val_accuracy: 0.7407\n",
      "Epoch 21/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7443 - val_loss: 0.5391 - val_accuracy: 0.7407\n",
      "Epoch 22/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7443 - val_loss: 0.5386 - val_accuracy: 0.7356\n",
      "Epoch 23/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7446 - val_loss: 0.5368 - val_accuracy: 0.7369\n",
      "Epoch 24/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7456 - val_loss: 0.5353 - val_accuracy: 0.7388\n",
      "Epoch 25/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7462 - val_loss: 0.5345 - val_accuracy: 0.7388\n",
      "Epoch 26/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7462 - val_loss: 0.5328 - val_accuracy: 0.7413\n",
      "Epoch 27/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7474 - val_loss: 0.5321 - val_accuracy: 0.7394\n",
      "Epoch 28/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7456 - val_loss: 0.5309 - val_accuracy: 0.7394\n",
      "Epoch 29/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7477 - val_loss: 0.5296 - val_accuracy: 0.7382\n",
      "Epoch 30/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7468 - val_loss: 0.5285 - val_accuracy: 0.7388\n",
      "Epoch 31/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7484 - val_loss: 0.5275 - val_accuracy: 0.7407\n",
      "Epoch 32/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7490 - val_loss: 0.5268 - val_accuracy: 0.7420\n",
      "Epoch 33/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7493 - val_loss: 0.5263 - val_accuracy: 0.7394\n",
      "Epoch 34/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7493 - val_loss: 0.5257 - val_accuracy: 0.7420\n",
      "Epoch 35/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7477 - val_loss: 0.5243 - val_accuracy: 0.7413\n",
      "Epoch 36/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7487 - val_loss: 0.5232 - val_accuracy: 0.7407\n",
      "Epoch 37/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7509 - val_loss: 0.5227 - val_accuracy: 0.7445\n",
      "Epoch 38/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7474 - val_loss: 0.5218 - val_accuracy: 0.7413\n",
      "Epoch 39/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7502 - val_loss: 0.5212 - val_accuracy: 0.7445\n",
      "Epoch 40/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7499 - val_loss: 0.5206 - val_accuracy: 0.7445\n",
      "Epoch 41/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7490 - val_loss: 0.5200 - val_accuracy: 0.7438\n",
      "Epoch 42/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7502 - val_loss: 0.5192 - val_accuracy: 0.7438\n",
      "Epoch 43/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7490 - val_loss: 0.5188 - val_accuracy: 0.7432\n",
      "Epoch 44/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7496 - val_loss: 0.5178 - val_accuracy: 0.7413\n",
      "Epoch 45/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7490 - val_loss: 0.5178 - val_accuracy: 0.7426\n",
      "Epoch 46/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7512 - val_loss: 0.5170 - val_accuracy: 0.7445\n",
      "Epoch 47/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7484 - val_loss: 0.5164 - val_accuracy: 0.7451\n",
      "Epoch 48/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7490 - val_loss: 0.5156 - val_accuracy: 0.7445\n",
      "Epoch 49/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7477 - val_loss: 0.5153 - val_accuracy: 0.7445\n",
      "Epoch 50/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7502 - val_loss: 0.5146 - val_accuracy: 0.7451\n",
      "Epoch 51/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7499 - val_loss: 0.5144 - val_accuracy: 0.7438\n",
      "Epoch 52/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7484 - val_loss: 0.5139 - val_accuracy: 0.7445\n",
      "Epoch 53/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7493 - val_loss: 0.5139 - val_accuracy: 0.7457\n",
      "Epoch 54/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7499 - val_loss: 0.5133 - val_accuracy: 0.7432\n",
      "Epoch 55/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7509 - val_loss: 0.5131 - val_accuracy: 0.7432\n",
      "Epoch 56/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7518 - val_loss: 0.5129 - val_accuracy: 0.7432\n",
      "Epoch 57/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7499 - val_loss: 0.5128 - val_accuracy: 0.7420\n",
      "Epoch 58/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7505 - val_loss: 0.5125 - val_accuracy: 0.7426\n",
      "Epoch 59/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7512 - val_loss: 0.5124 - val_accuracy: 0.7407\n",
      "Epoch 60/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7505 - val_loss: 0.5124 - val_accuracy: 0.7407\n",
      "Epoch 61/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7512 - val_loss: 0.5120 - val_accuracy: 0.7426\n",
      "Epoch 62/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7524 - val_loss: 0.5119 - val_accuracy: 0.7413\n",
      "Epoch 63/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7502 - val_loss: 0.5117 - val_accuracy: 0.7413\n",
      "Epoch 64/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7509 - val_loss: 0.5116 - val_accuracy: 0.7407\n",
      "Epoch 65/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7505 - val_loss: 0.5110 - val_accuracy: 0.7420\n",
      "Epoch 66/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7512 - val_loss: 0.5113 - val_accuracy: 0.7420\n",
      "Epoch 67/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7509 - val_loss: 0.5115 - val_accuracy: 0.7413\n",
      "Epoch 68/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7502 - val_loss: 0.5112 - val_accuracy: 0.7401\n",
      "Epoch 69/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7515 - val_loss: 0.5110 - val_accuracy: 0.7407\n",
      "Epoch 70/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7530 - val_loss: 0.5108 - val_accuracy: 0.7407\n",
      "Epoch 71/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7521 - val_loss: 0.5115 - val_accuracy: 0.7438\n",
      "Epoch 72/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7496 - val_loss: 0.5105 - val_accuracy: 0.7401\n",
      "Epoch 73/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7518 - val_loss: 0.5104 - val_accuracy: 0.7401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7546 - val_loss: 0.5107 - val_accuracy: 0.7413\n",
      "Epoch 75/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7509 - val_loss: 0.5102 - val_accuracy: 0.7407\n",
      "Epoch 76/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7512 - val_loss: 0.5102 - val_accuracy: 0.7401\n",
      "Epoch 77/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7524 - val_loss: 0.5103 - val_accuracy: 0.7413\n",
      "Epoch 78/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7518 - val_loss: 0.5103 - val_accuracy: 0.7420\n",
      "Epoch 79/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7515 - val_loss: 0.5101 - val_accuracy: 0.7413\n",
      "Epoch 80/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7518 - val_loss: 0.5100 - val_accuracy: 0.7407\n",
      "Epoch 81/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7521 - val_loss: 0.5098 - val_accuracy: 0.7413\n",
      "Epoch 82/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7515 - val_loss: 0.5098 - val_accuracy: 0.7413\n",
      "Epoch 83/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7533 - val_loss: 0.5095 - val_accuracy: 0.7401\n",
      "Epoch 84/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7530 - val_loss: 0.5101 - val_accuracy: 0.7438\n",
      "Epoch 85/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7521 - val_loss: 0.5096 - val_accuracy: 0.7401\n",
      "Epoch 86/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7533 - val_loss: 0.5099 - val_accuracy: 0.7420\n",
      "Epoch 87/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7533 - val_loss: 0.5096 - val_accuracy: 0.7394\n",
      "Epoch 88/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7533 - val_loss: 0.5094 - val_accuracy: 0.7407\n",
      "Epoch 89/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7518 - val_loss: 0.5091 - val_accuracy: 0.7401\n",
      "Epoch 90/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7527 - val_loss: 0.5095 - val_accuracy: 0.7432\n",
      "Epoch 91/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7533 - val_loss: 0.5097 - val_accuracy: 0.7420\n",
      "Epoch 92/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7521 - val_loss: 0.5094 - val_accuracy: 0.7420\n",
      "Epoch 93/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7543 - val_loss: 0.5095 - val_accuracy: 0.7432\n",
      "Epoch 94/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7518 - val_loss: 0.5091 - val_accuracy: 0.7401\n",
      "Epoch 95/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7546 - val_loss: 0.5092 - val_accuracy: 0.7394\n",
      "Epoch 96/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7527 - val_loss: 0.5093 - val_accuracy: 0.7420\n",
      "Epoch 97/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7533 - val_loss: 0.5093 - val_accuracy: 0.7426\n",
      "Epoch 98/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7527 - val_loss: 0.5089 - val_accuracy: 0.7426\n",
      "Epoch 99/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7543 - val_loss: 0.5095 - val_accuracy: 0.7451\n",
      "Epoch 100/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7527 - val_loss: 0.5088 - val_accuracy: 0.7426\n",
      "Epoch 101/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7530 - val_loss: 0.5090 - val_accuracy: 0.7438\n",
      "Epoch 102/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7524 - val_loss: 0.5090 - val_accuracy: 0.7438\n",
      "Epoch 103/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7533 - val_loss: 0.5091 - val_accuracy: 0.7438\n",
      "Epoch 104/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7537 - val_loss: 0.5095 - val_accuracy: 0.7464\n",
      "Epoch 105/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7543 - val_loss: 0.5089 - val_accuracy: 0.7401\n",
      "Epoch 106/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7521 - val_loss: 0.5092 - val_accuracy: 0.7457\n",
      "Epoch 107/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7527 - val_loss: 0.5088 - val_accuracy: 0.7432\n",
      "Epoch 108/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7540 - val_loss: 0.5101 - val_accuracy: 0.7495\n",
      "Epoch 109/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7543 - val_loss: 0.5098 - val_accuracy: 0.7464\n",
      "Epoch 110/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7524 - val_loss: 0.5091 - val_accuracy: 0.7451\n",
      "Epoch 111/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7527 - val_loss: 0.5088 - val_accuracy: 0.7413\n",
      "Epoch 112/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7540 - val_loss: 0.5088 - val_accuracy: 0.7451\n",
      "Epoch 113/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7530 - val_loss: 0.5089 - val_accuracy: 0.7464\n",
      "Epoch 114/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7543 - val_loss: 0.5090 - val_accuracy: 0.7451\n",
      "Epoch 115/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7552 - val_loss: 0.5091 - val_accuracy: 0.7483\n",
      "Epoch 116/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7530 - val_loss: 0.5094 - val_accuracy: 0.7470\n",
      "Epoch 117/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7521 - val_loss: 0.5087 - val_accuracy: 0.7420\n",
      "Epoch 118/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7552 - val_loss: 0.5091 - val_accuracy: 0.7464\n",
      "Epoch 119/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7549 - val_loss: 0.5087 - val_accuracy: 0.7457\n",
      "Epoch 120/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7543 - val_loss: 0.5096 - val_accuracy: 0.7470\n",
      "Epoch 121/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7549 - val_loss: 0.5092 - val_accuracy: 0.7470\n",
      "Epoch 122/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7555 - val_loss: 0.5088 - val_accuracy: 0.7451\n",
      "Epoch 123/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7509 - val_loss: 0.5097 - val_accuracy: 0.7495\n",
      "Epoch 124/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7521 - val_loss: 0.5086 - val_accuracy: 0.7451\n",
      "Epoch 125/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7543 - val_loss: 0.5088 - val_accuracy: 0.7445\n",
      "Epoch 126/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7549 - val_loss: 0.5089 - val_accuracy: 0.7445\n",
      "Epoch 127/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7543 - val_loss: 0.5094 - val_accuracy: 0.7470\n",
      "Epoch 128/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7546 - val_loss: 0.5092 - val_accuracy: 0.7470\n",
      "Epoch 129/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7555 - val_loss: 0.5087 - val_accuracy: 0.7451\n",
      "Epoch 130/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7540 - val_loss: 0.5088 - val_accuracy: 0.7451\n",
      "Epoch 131/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7558 - val_loss: 0.5088 - val_accuracy: 0.7445\n",
      "Epoch 132/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7540 - val_loss: 0.5086 - val_accuracy: 0.7457\n",
      "Epoch 133/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7524 - val_loss: 0.5088 - val_accuracy: 0.7432\n",
      "Epoch 134/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7565 - val_loss: 0.5093 - val_accuracy: 0.7476\n",
      "Epoch 135/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7543 - val_loss: 0.5087 - val_accuracy: 0.7426\n",
      "Epoch 136/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7537 - val_loss: 0.5089 - val_accuracy: 0.7476\n",
      "Epoch 137/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7543 - val_loss: 0.5086 - val_accuracy: 0.7451\n",
      "Epoch 138/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7549 - val_loss: 0.5085 - val_accuracy: 0.7420\n",
      "Epoch 139/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7527 - val_loss: 0.5086 - val_accuracy: 0.7413\n",
      "Epoch 140/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7552 - val_loss: 0.5086 - val_accuracy: 0.7451\n",
      "Epoch 141/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7524 - val_loss: 0.5084 - val_accuracy: 0.7457\n",
      "Epoch 142/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7549 - val_loss: 0.5086 - val_accuracy: 0.7451\n",
      "Epoch 143/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7540 - val_loss: 0.5084 - val_accuracy: 0.7451\n",
      "Epoch 144/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7546 - val_loss: 0.5090 - val_accuracy: 0.7483\n",
      "Epoch 145/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7540 - val_loss: 0.5087 - val_accuracy: 0.7445\n",
      "Epoch 146/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7558 - val_loss: 0.5090 - val_accuracy: 0.7470\n",
      "Epoch 147/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7549 - val_loss: 0.5082 - val_accuracy: 0.7457\n",
      "Epoch 148/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7546 - val_loss: 0.5090 - val_accuracy: 0.7489\n",
      "Epoch 149/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7549 - val_loss: 0.5086 - val_accuracy: 0.7457\n",
      "Epoch 150/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7540 - val_loss: 0.5093 - val_accuracy: 0.7489\n",
      "Epoch 151/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7527 - val_loss: 0.5081 - val_accuracy: 0.7464\n",
      "Epoch 152/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7546 - val_loss: 0.5088 - val_accuracy: 0.7476\n",
      "Epoch 153/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7552 - val_loss: 0.5083 - val_accuracy: 0.7445\n",
      "Epoch 154/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7546 - val_loss: 0.5087 - val_accuracy: 0.7451\n",
      "Epoch 155/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7530 - val_loss: 0.5084 - val_accuracy: 0.7438\n",
      "Epoch 156/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7561 - val_loss: 0.5089 - val_accuracy: 0.7483\n",
      "Epoch 157/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7451\n",
      "Epoch 158/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7555 - val_loss: 0.5086 - val_accuracy: 0.7451\n",
      "Epoch 159/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7546 - val_loss: 0.5085 - val_accuracy: 0.7438\n",
      "Epoch 160/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7546 - val_loss: 0.5085 - val_accuracy: 0.7438\n",
      "Epoch 161/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7524 - val_loss: 0.5082 - val_accuracy: 0.7420\n",
      "Epoch 162/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7568 - val_loss: 0.5085 - val_accuracy: 0.7445\n",
      "Epoch 163/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7543 - val_loss: 0.5091 - val_accuracy: 0.7502\n",
      "Epoch 164/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7512 - val_loss: 0.5082 - val_accuracy: 0.7451\n",
      "Epoch 165/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7530 - val_loss: 0.5081 - val_accuracy: 0.7438\n",
      "Epoch 166/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7527 - val_loss: 0.5082 - val_accuracy: 0.7451\n",
      "Epoch 167/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7543 - val_loss: 0.5084 - val_accuracy: 0.7438\n",
      "Epoch 168/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7555 - val_loss: 0.5084 - val_accuracy: 0.7445\n",
      "Epoch 169/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7546 - val_loss: 0.5087 - val_accuracy: 0.7464\n",
      "Epoch 170/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7555 - val_loss: 0.5090 - val_accuracy: 0.7495\n",
      "Epoch 171/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7543 - val_loss: 0.5081 - val_accuracy: 0.7445\n",
      "Epoch 172/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7552 - val_loss: 0.5082 - val_accuracy: 0.7438\n",
      "Epoch 173/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7546 - val_loss: 0.5085 - val_accuracy: 0.7432\n",
      "Epoch 174/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7540 - val_loss: 0.5084 - val_accuracy: 0.7438\n",
      "Epoch 175/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7540 - val_loss: 0.5086 - val_accuracy: 0.7451\n",
      "Epoch 176/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7524 - val_loss: 0.5085 - val_accuracy: 0.7438\n",
      "Epoch 177/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7537 - val_loss: 0.5086 - val_accuracy: 0.7457\n",
      "Epoch 178/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7540 - val_loss: 0.5083 - val_accuracy: 0.7445\n",
      "Epoch 179/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7527 - val_loss: 0.5080 - val_accuracy: 0.7432\n",
      "Epoch 180/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7558 - val_loss: 0.5084 - val_accuracy: 0.7432\n",
      "Epoch 181/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7524 - val_loss: 0.5084 - val_accuracy: 0.7470\n",
      "Epoch 182/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7527 - val_loss: 0.5080 - val_accuracy: 0.7426\n",
      "Epoch 183/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7518 - val_loss: 0.5084 - val_accuracy: 0.7432\n",
      "Epoch 184/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7540 - val_loss: 0.5084 - val_accuracy: 0.7476\n",
      "Epoch 185/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7524 - val_loss: 0.5087 - val_accuracy: 0.7489\n",
      "Epoch 186/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7515 - val_loss: 0.5090 - val_accuracy: 0.7489\n",
      "Epoch 187/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7515 - val_loss: 0.5082 - val_accuracy: 0.7432\n",
      "Epoch 188/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7549 - val_loss: 0.5083 - val_accuracy: 0.7432\n",
      "Epoch 189/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7490 - val_loss: 0.5080 - val_accuracy: 0.7438\n",
      "Epoch 190/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7524 - val_loss: 0.5080 - val_accuracy: 0.7432\n",
      "Epoch 191/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7533 - val_loss: 0.5084 - val_accuracy: 0.7426\n",
      "Epoch 192/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7537 - val_loss: 0.5084 - val_accuracy: 0.7426\n",
      "Epoch 193/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7530 - val_loss: 0.5079 - val_accuracy: 0.7438\n",
      "Epoch 194/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7552 - val_loss: 0.5080 - val_accuracy: 0.7426\n",
      "Epoch 195/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7527 - val_loss: 0.5091 - val_accuracy: 0.7502\n",
      "Epoch 196/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7524 - val_loss: 0.5080 - val_accuracy: 0.7432\n",
      "Epoch 197/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7552 - val_loss: 0.5081 - val_accuracy: 0.7438\n",
      "Epoch 198/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7527 - val_loss: 0.5082 - val_accuracy: 0.7426\n",
      "Epoch 199/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7512 - val_loss: 0.5079 - val_accuracy: 0.7432\n",
      "Epoch 200/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7537 - val_loss: 0.5080 - val_accuracy: 0.7438\n",
      "Epoch 201/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7515 - val_loss: 0.5080 - val_accuracy: 0.7426\n",
      "Epoch 202/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7540 - val_loss: 0.5079 - val_accuracy: 0.7438\n",
      "Epoch 203/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7546 - val_loss: 0.5079 - val_accuracy: 0.7438\n",
      "Epoch 204/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7527 - val_loss: 0.5092 - val_accuracy: 0.7502\n",
      "Epoch 205/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5078 - val_accuracy: 0.7432\n",
      "Epoch 206/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7527 - val_loss: 0.5084 - val_accuracy: 0.7413\n",
      "Epoch 207/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7543 - val_loss: 0.5082 - val_accuracy: 0.7432\n",
      "Epoch 208/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7524 - val_loss: 0.5088 - val_accuracy: 0.7476\n",
      "Epoch 209/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7530 - val_loss: 0.5078 - val_accuracy: 0.7438\n",
      "Epoch 210/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7530 - val_loss: 0.5080 - val_accuracy: 0.7432\n",
      "Epoch 211/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7521 - val_loss: 0.5084 - val_accuracy: 0.7476\n",
      "Epoch 212/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7537 - val_loss: 0.5082 - val_accuracy: 0.7426\n",
      "Epoch 213/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7515 - val_loss: 0.5082 - val_accuracy: 0.7432\n",
      "Epoch 214/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7546 - val_loss: 0.5084 - val_accuracy: 0.7426\n",
      "Epoch 215/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.5077 - val_accuracy: 0.7451\n",
      "Epoch 216/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7546 - val_loss: 0.5082 - val_accuracy: 0.7438\n",
      "Epoch 217/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7521 - val_loss: 0.5078 - val_accuracy: 0.7426\n",
      "Epoch 218/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7530 - val_loss: 0.5080 - val_accuracy: 0.7432\n",
      "Epoch 219/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7555 - val_loss: 0.5083 - val_accuracy: 0.7432\n",
      "Epoch 220/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5082 - val_accuracy: 0.7432\n",
      "Epoch 221/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7558 - val_loss: 0.5080 - val_accuracy: 0.7432\n",
      "Epoch 222/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7518 - val_loss: 0.5076 - val_accuracy: 0.7438\n",
      "Epoch 223/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7546 - val_loss: 0.5083 - val_accuracy: 0.7432\n",
      "Epoch 224/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7530 - val_loss: 0.5078 - val_accuracy: 0.7432\n",
      "Epoch 225/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7527 - val_loss: 0.5081 - val_accuracy: 0.7432\n",
      "Epoch 226/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7543 - val_loss: 0.5081 - val_accuracy: 0.7432\n",
      "Epoch 227/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7537 - val_loss: 0.5077 - val_accuracy: 0.7445\n",
      "Epoch 228/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7540 - val_loss: 0.5078 - val_accuracy: 0.7432\n",
      "Epoch 229/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7537 - val_loss: 0.5082 - val_accuracy: 0.7426\n",
      "Epoch 230/250\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7521 - val_loss: 0.5080 - val_accuracy: 0.7432\n",
      "Epoch 231/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7521 - val_loss: 0.5079 - val_accuracy: 0.7445\n",
      "Epoch 232/250\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7524 - val_loss: 0.5080 - val_accuracy: 0.7432\n",
      "Epoch 233/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7546 - val_loss: 0.5082 - val_accuracy: 0.7438\n",
      "Epoch 234/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7530 - val_loss: 0.5079 - val_accuracy: 0.7426\n",
      "Epoch 235/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7549 - val_loss: 0.5080 - val_accuracy: 0.7438\n",
      "Epoch 236/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7530 - val_loss: 0.5087 - val_accuracy: 0.7445\n",
      "Epoch 237/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7521 - val_loss: 0.5079 - val_accuracy: 0.7445\n",
      "Epoch 238/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7530 - val_loss: 0.5081 - val_accuracy: 0.7438\n",
      "Epoch 239/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5088 - val_accuracy: 0.7483\n",
      "Epoch 240/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7530 - val_loss: 0.5078 - val_accuracy: 0.7438\n",
      "Epoch 241/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7527 - val_loss: 0.5082 - val_accuracy: 0.7426\n",
      "Epoch 242/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7518 - val_loss: 0.5078 - val_accuracy: 0.7438\n",
      "Epoch 243/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7540 - val_loss: 0.5084 - val_accuracy: 0.7420\n",
      "Epoch 244/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7524 - val_loss: 0.5079 - val_accuracy: 0.7445\n",
      "Epoch 245/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7540 - val_loss: 0.5085 - val_accuracy: 0.7413\n",
      "Epoch 246/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7533 - val_loss: 0.5082 - val_accuracy: 0.7426\n",
      "Epoch 247/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5080 - val_accuracy: 0.7432\n",
      "Epoch 248/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7527 - val_loss: 0.5079 - val_accuracy: 0.7445\n",
      "Epoch 249/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7533 - val_loss: 0.5082 - val_accuracy: 0.7438\n",
      "Epoch 250/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7515 - val_loss: 0.5083 - val_accuracy: 0.7445\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "Epoch 1/250\n",
      "65/65 [==============================] - 1s 5ms/step - loss: 0.6715 - accuracy: 0.6236 - val_loss: 0.6692 - val_accuracy: 0.6656\n",
      "Epoch 2/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6812 - val_loss: 0.6579 - val_accuracy: 0.6845\n",
      "Epoch 3/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6902 - val_loss: 0.6462 - val_accuracy: 0.6978\n",
      "Epoch 4/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6983 - val_loss: 0.6343 - val_accuracy: 0.7054\n",
      "Epoch 5/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.7098 - val_loss: 0.6223 - val_accuracy: 0.7028\n",
      "Epoch 6/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.7135 - val_loss: 0.6122 - val_accuracy: 0.7117\n",
      "Epoch 7/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.7185 - val_loss: 0.6038 - val_accuracy: 0.7306\n",
      "Epoch 8/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.7306 - val_loss: 0.5951 - val_accuracy: 0.7237\n",
      "Epoch 9/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.7238 - val_loss: 0.5892 - val_accuracy: 0.7287\n",
      "Epoch 10/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.7294 - val_loss: 0.5829 - val_accuracy: 0.7268\n",
      "Epoch 11/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.7337 - val_loss: 0.5777 - val_accuracy: 0.7249\n",
      "Epoch 12/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7331 - val_loss: 0.5728 - val_accuracy: 0.7205\n",
      "Epoch 13/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7362 - val_loss: 0.5700 - val_accuracy: 0.7224\n",
      "Epoch 14/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7365 - val_loss: 0.5657 - val_accuracy: 0.7237\n",
      "Epoch 15/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7381 - val_loss: 0.5622 - val_accuracy: 0.7237\n",
      "Epoch 16/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7397 - val_loss: 0.5599 - val_accuracy: 0.7243\n",
      "Epoch 17/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7397 - val_loss: 0.5570 - val_accuracy: 0.7268\n",
      "Epoch 18/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7400 - val_loss: 0.5557 - val_accuracy: 0.7249\n",
      "Epoch 19/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7403 - val_loss: 0.5526 - val_accuracy: 0.7319\n",
      "Epoch 20/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7412 - val_loss: 0.5514 - val_accuracy: 0.7268\n",
      "Epoch 21/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7409 - val_loss: 0.5496 - val_accuracy: 0.7256\n",
      "Epoch 22/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7428 - val_loss: 0.5474 - val_accuracy: 0.7293\n",
      "Epoch 23/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7440 - val_loss: 0.5466 - val_accuracy: 0.7262\n",
      "Epoch 24/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7421 - val_loss: 0.5452 - val_accuracy: 0.7262\n",
      "Epoch 25/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7431 - val_loss: 0.5438 - val_accuracy: 0.7268\n",
      "Epoch 26/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7431 - val_loss: 0.5424 - val_accuracy: 0.7287\n",
      "Epoch 27/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7421 - val_loss: 0.5412 - val_accuracy: 0.7300\n",
      "Epoch 28/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7425 - val_loss: 0.5398 - val_accuracy: 0.7287\n",
      "Epoch 29/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7449 - val_loss: 0.5381 - val_accuracy: 0.7312\n",
      "Epoch 30/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7456 - val_loss: 0.5374 - val_accuracy: 0.7300\n",
      "Epoch 31/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7459 - val_loss: 0.5363 - val_accuracy: 0.7306\n",
      "Epoch 32/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7449 - val_loss: 0.5349 - val_accuracy: 0.7312\n",
      "Epoch 33/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7471 - val_loss: 0.5337 - val_accuracy: 0.7306\n",
      "Epoch 34/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7456 - val_loss: 0.5329 - val_accuracy: 0.7312\n",
      "Epoch 35/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7465 - val_loss: 0.5320 - val_accuracy: 0.7319\n",
      "Epoch 36/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7449 - val_loss: 0.5311 - val_accuracy: 0.7319\n",
      "Epoch 37/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7459 - val_loss: 0.5307 - val_accuracy: 0.7325\n",
      "Epoch 38/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7453 - val_loss: 0.5299 - val_accuracy: 0.7312\n",
      "Epoch 39/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7462 - val_loss: 0.5291 - val_accuracy: 0.7331\n",
      "Epoch 40/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7456 - val_loss: 0.5287 - val_accuracy: 0.7306\n",
      "Epoch 41/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7456 - val_loss: 0.5281 - val_accuracy: 0.7306\n",
      "Epoch 42/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7474 - val_loss: 0.5275 - val_accuracy: 0.7306\n",
      "Epoch 43/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7471 - val_loss: 0.5272 - val_accuracy: 0.7306\n",
      "Epoch 44/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7493 - val_loss: 0.5265 - val_accuracy: 0.7338\n",
      "Epoch 45/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7474 - val_loss: 0.5261 - val_accuracy: 0.7338\n",
      "Epoch 46/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7484 - val_loss: 0.5258 - val_accuracy: 0.7350\n",
      "Epoch 47/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7502 - val_loss: 0.5254 - val_accuracy: 0.7338\n",
      "Epoch 48/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7496 - val_loss: 0.5252 - val_accuracy: 0.7331\n",
      "Epoch 49/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7502 - val_loss: 0.5248 - val_accuracy: 0.7363\n",
      "Epoch 50/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7484 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
      "Epoch 51/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7505 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
      "Epoch 52/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7499 - val_loss: 0.5236 - val_accuracy: 0.7344\n",
      "Epoch 53/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7496 - val_loss: 0.5234 - val_accuracy: 0.7369\n",
      "Epoch 54/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7512 - val_loss: 0.5230 - val_accuracy: 0.7356\n",
      "Epoch 55/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7499 - val_loss: 0.5227 - val_accuracy: 0.7356\n",
      "Epoch 56/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7509 - val_loss: 0.5223 - val_accuracy: 0.7369\n",
      "Epoch 57/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7505 - val_loss: 0.5220 - val_accuracy: 0.7350\n",
      "Epoch 58/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7496 - val_loss: 0.5220 - val_accuracy: 0.7369\n",
      "Epoch 59/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7509 - val_loss: 0.5217 - val_accuracy: 0.7363\n",
      "Epoch 60/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7505 - val_loss: 0.5216 - val_accuracy: 0.7388\n",
      "Epoch 61/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7502 - val_loss: 0.5215 - val_accuracy: 0.7388\n",
      "Epoch 62/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7496 - val_loss: 0.5213 - val_accuracy: 0.7331\n",
      "Epoch 63/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7487 - val_loss: 0.5212 - val_accuracy: 0.7394\n",
      "Epoch 64/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7509 - val_loss: 0.5207 - val_accuracy: 0.7338\n",
      "Epoch 65/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7493 - val_loss: 0.5206 - val_accuracy: 0.7388\n",
      "Epoch 66/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7487 - val_loss: 0.5206 - val_accuracy: 0.7388\n",
      "Epoch 67/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7481 - val_loss: 0.5208 - val_accuracy: 0.7401\n",
      "Epoch 68/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7509 - val_loss: 0.5198 - val_accuracy: 0.7356\n",
      "Epoch 69/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7496 - val_loss: 0.5198 - val_accuracy: 0.7388\n",
      "Epoch 70/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7493 - val_loss: 0.5197 - val_accuracy: 0.7382\n",
      "Epoch 71/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7493 - val_loss: 0.5196 - val_accuracy: 0.7382\n",
      "Epoch 72/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7499 - val_loss: 0.5197 - val_accuracy: 0.7407\n",
      "Epoch 73/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7502 - val_loss: 0.5194 - val_accuracy: 0.7394\n",
      "Epoch 74/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7502 - val_loss: 0.5195 - val_accuracy: 0.7401\n",
      "Epoch 75/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7512 - val_loss: 0.5192 - val_accuracy: 0.7388\n",
      "Epoch 76/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7493 - val_loss: 0.5190 - val_accuracy: 0.7375\n",
      "Epoch 77/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7502 - val_loss: 0.5189 - val_accuracy: 0.7375\n",
      "Epoch 78/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7487 - val_loss: 0.5188 - val_accuracy: 0.7375\n",
      "Epoch 79/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7484 - val_loss: 0.5188 - val_accuracy: 0.7356\n",
      "Epoch 80/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7502 - val_loss: 0.5185 - val_accuracy: 0.7356\n",
      "Epoch 81/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7484 - val_loss: 0.5185 - val_accuracy: 0.7375\n",
      "Epoch 82/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7493 - val_loss: 0.5185 - val_accuracy: 0.7331\n",
      "Epoch 83/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7509 - val_loss: 0.5182 - val_accuracy: 0.7356\n",
      "Epoch 84/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7505 - val_loss: 0.5182 - val_accuracy: 0.7363\n",
      "Epoch 85/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7493 - val_loss: 0.5182 - val_accuracy: 0.7363\n",
      "Epoch 86/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7502 - val_loss: 0.5183 - val_accuracy: 0.7356\n",
      "Epoch 87/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7496 - val_loss: 0.5183 - val_accuracy: 0.7369\n",
      "Epoch 88/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7512 - val_loss: 0.5183 - val_accuracy: 0.7344\n",
      "Epoch 89/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7518 - val_loss: 0.5179 - val_accuracy: 0.7319\n",
      "Epoch 90/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7505 - val_loss: 0.5178 - val_accuracy: 0.7338\n",
      "Epoch 91/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7515 - val_loss: 0.5179 - val_accuracy: 0.7338\n",
      "Epoch 92/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7512 - val_loss: 0.5177 - val_accuracy: 0.7331\n",
      "Epoch 93/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7515 - val_loss: 0.5173 - val_accuracy: 0.7312\n",
      "Epoch 94/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7512 - val_loss: 0.5176 - val_accuracy: 0.7338\n",
      "Epoch 95/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7509 - val_loss: 0.5175 - val_accuracy: 0.7312\n",
      "Epoch 96/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7512 - val_loss: 0.5175 - val_accuracy: 0.7338\n",
      "Epoch 97/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7515 - val_loss: 0.5172 - val_accuracy: 0.7312\n",
      "Epoch 98/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7524 - val_loss: 0.5174 - val_accuracy: 0.7331\n",
      "Epoch 99/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7518 - val_loss: 0.5170 - val_accuracy: 0.7293\n",
      "Epoch 100/250\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5106 - accuracy: 0.7512 - val_loss: 0.5172 - val_accuracy: 0.7331\n",
      "Epoch 101/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7518 - val_loss: 0.5175 - val_accuracy: 0.7350\n",
      "Epoch 102/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7540 - val_loss: 0.5171 - val_accuracy: 0.7325\n",
      "Epoch 103/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7521 - val_loss: 0.5174 - val_accuracy: 0.7363\n",
      "Epoch 104/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7518 - val_loss: 0.5171 - val_accuracy: 0.7350\n",
      "Epoch 105/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7558 - val_loss: 0.5169 - val_accuracy: 0.7338\n",
      "Epoch 106/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7537 - val_loss: 0.5169 - val_accuracy: 0.7293\n",
      "Epoch 107/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7524 - val_loss: 0.5170 - val_accuracy: 0.7325\n",
      "Epoch 108/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7537 - val_loss: 0.5168 - val_accuracy: 0.7293\n",
      "Epoch 109/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7543 - val_loss: 0.5167 - val_accuracy: 0.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7537 - val_loss: 0.5169 - val_accuracy: 0.7338\n",
      "Epoch 111/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7530 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 112/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7540 - val_loss: 0.5165 - val_accuracy: 0.7306\n",
      "Epoch 113/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7533 - val_loss: 0.5167 - val_accuracy: 0.7306\n",
      "Epoch 114/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7533 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 115/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7530 - val_loss: 0.5163 - val_accuracy: 0.7293\n",
      "Epoch 116/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7543 - val_loss: 0.5164 - val_accuracy: 0.7300\n",
      "Epoch 117/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7561 - val_loss: 0.5168 - val_accuracy: 0.7325\n",
      "Epoch 118/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7555 - val_loss: 0.5167 - val_accuracy: 0.7306\n",
      "Epoch 119/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7561 - val_loss: 0.5163 - val_accuracy: 0.7287\n",
      "Epoch 120/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7555 - val_loss: 0.5163 - val_accuracy: 0.7287\n",
      "Epoch 121/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7561 - val_loss: 0.5166 - val_accuracy: 0.7325\n",
      "Epoch 122/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7533 - val_loss: 0.5164 - val_accuracy: 0.7306\n",
      "Epoch 123/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7568 - val_loss: 0.5168 - val_accuracy: 0.7325\n",
      "Epoch 124/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7558 - val_loss: 0.5164 - val_accuracy: 0.7306\n",
      "Epoch 125/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7561 - val_loss: 0.5162 - val_accuracy: 0.7287\n",
      "Epoch 126/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7561 - val_loss: 0.5161 - val_accuracy: 0.7268\n",
      "Epoch 127/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7577 - val_loss: 0.5164 - val_accuracy: 0.7306\n",
      "Epoch 128/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7571 - val_loss: 0.5165 - val_accuracy: 0.7306\n",
      "Epoch 129/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7546 - val_loss: 0.5164 - val_accuracy: 0.7319\n",
      "Epoch 130/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7577 - val_loss: 0.5165 - val_accuracy: 0.7287\n",
      "Epoch 131/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7549 - val_loss: 0.5165 - val_accuracy: 0.7300\n",
      "Epoch 132/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7558 - val_loss: 0.5170 - val_accuracy: 0.7306\n",
      "Epoch 133/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7552 - val_loss: 0.5166 - val_accuracy: 0.7287\n",
      "Epoch 134/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7558 - val_loss: 0.5166 - val_accuracy: 0.7281\n",
      "Epoch 135/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7565 - val_loss: 0.5167 - val_accuracy: 0.7293\n",
      "Epoch 136/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7540 - val_loss: 0.5162 - val_accuracy: 0.7262\n",
      "Epoch 137/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7565 - val_loss: 0.5166 - val_accuracy: 0.7262\n",
      "Epoch 138/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7561 - val_loss: 0.5163 - val_accuracy: 0.7237\n",
      "Epoch 139/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7546 - val_loss: 0.5161 - val_accuracy: 0.7262\n",
      "Epoch 140/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7568 - val_loss: 0.5165 - val_accuracy: 0.7287\n",
      "Epoch 141/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7565 - val_loss: 0.5171 - val_accuracy: 0.7262\n",
      "Epoch 142/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7552 - val_loss: 0.5169 - val_accuracy: 0.7274\n",
      "Epoch 143/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7552 - val_loss: 0.5166 - val_accuracy: 0.7256\n",
      "Epoch 144/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7561 - val_loss: 0.5168 - val_accuracy: 0.7274\n",
      "Epoch 145/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7537 - val_loss: 0.5165 - val_accuracy: 0.7237\n",
      "Epoch 146/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7543 - val_loss: 0.5168 - val_accuracy: 0.7274\n",
      "Epoch 147/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7571 - val_loss: 0.5165 - val_accuracy: 0.7230\n",
      "Epoch 148/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7568 - val_loss: 0.5171 - val_accuracy: 0.7268\n",
      "Epoch 149/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7552 - val_loss: 0.5170 - val_accuracy: 0.7293\n",
      "Epoch 150/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7549 - val_loss: 0.5167 - val_accuracy: 0.7243\n",
      "Epoch 151/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7561 - val_loss: 0.5168 - val_accuracy: 0.7256\n",
      "Epoch 152/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7565 - val_loss: 0.5165 - val_accuracy: 0.7256\n",
      "Epoch 153/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7580 - val_loss: 0.5171 - val_accuracy: 0.7281\n",
      "Epoch 154/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7543 - val_loss: 0.5165 - val_accuracy: 0.7268\n",
      "Epoch 155/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7537 - val_loss: 0.5162 - val_accuracy: 0.7281\n",
      "Epoch 156/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7561 - val_loss: 0.5162 - val_accuracy: 0.7281\n",
      "Epoch 157/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7571 - val_loss: 0.5168 - val_accuracy: 0.7287\n",
      "Epoch 158/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7552 - val_loss: 0.5167 - val_accuracy: 0.7293\n",
      "Epoch 159/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7568 - val_loss: 0.5165 - val_accuracy: 0.7274\n",
      "Epoch 160/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7571 - val_loss: 0.5163 - val_accuracy: 0.7249\n",
      "Epoch 161/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7558 - val_loss: 0.5162 - val_accuracy: 0.7287\n",
      "Epoch 162/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7571 - val_loss: 0.5165 - val_accuracy: 0.7274\n",
      "Epoch 163/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7555 - val_loss: 0.5165 - val_accuracy: 0.7281\n",
      "Epoch 164/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7565 - val_loss: 0.5165 - val_accuracy: 0.7274\n",
      "Epoch 165/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7555 - val_loss: 0.5162 - val_accuracy: 0.7281\n",
      "Epoch 166/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7577 - val_loss: 0.5161 - val_accuracy: 0.7306\n",
      "Epoch 167/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7558 - val_loss: 0.5162 - val_accuracy: 0.7287\n",
      "Epoch 168/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7537 - val_loss: 0.5163 - val_accuracy: 0.7274\n",
      "Epoch 169/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7549 - val_loss: 0.5168 - val_accuracy: 0.7287\n",
      "Epoch 170/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7555 - val_loss: 0.5164 - val_accuracy: 0.7287\n",
      "Epoch 171/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7546 - val_loss: 0.5164 - val_accuracy: 0.7262\n",
      "Epoch 172/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7543 - val_loss: 0.5165 - val_accuracy: 0.7274\n",
      "Epoch 173/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7558 - val_loss: 0.5159 - val_accuracy: 0.7256\n",
      "Epoch 174/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7555 - val_loss: 0.5162 - val_accuracy: 0.7268\n",
      "Epoch 175/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7552 - val_loss: 0.5161 - val_accuracy: 0.7274\n",
      "Epoch 176/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7568 - val_loss: 0.5162 - val_accuracy: 0.7287\n",
      "Epoch 177/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7561 - val_loss: 0.5164 - val_accuracy: 0.7300\n",
      "Epoch 178/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7552 - val_loss: 0.5162 - val_accuracy: 0.7287\n",
      "Epoch 179/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7565 - val_loss: 0.5158 - val_accuracy: 0.7281\n",
      "Epoch 180/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7552 - val_loss: 0.5159 - val_accuracy: 0.7287\n",
      "Epoch 181/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7565 - val_loss: 0.5159 - val_accuracy: 0.7306\n",
      "Epoch 182/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7565 - val_loss: 0.5166 - val_accuracy: 0.7274\n",
      "Epoch 183/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7568 - val_loss: 0.5160 - val_accuracy: 0.7287\n",
      "Epoch 184/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7555 - val_loss: 0.5159 - val_accuracy: 0.7281\n",
      "Epoch 185/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7558 - val_loss: 0.5159 - val_accuracy: 0.7274\n",
      "Epoch 186/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7558 - val_loss: 0.5163 - val_accuracy: 0.7262\n",
      "Epoch 187/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7552 - val_loss: 0.5169 - val_accuracy: 0.7262\n",
      "Epoch 188/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7568 - val_loss: 0.5166 - val_accuracy: 0.7274\n",
      "Epoch 189/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7552 - val_loss: 0.5161 - val_accuracy: 0.7281\n",
      "Epoch 190/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7565 - val_loss: 0.5163 - val_accuracy: 0.7262\n",
      "Epoch 191/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7552 - val_loss: 0.5158 - val_accuracy: 0.7274\n",
      "Epoch 192/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7558 - val_loss: 0.5160 - val_accuracy: 0.7274\n",
      "Epoch 193/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7571 - val_loss: 0.5156 - val_accuracy: 0.7300\n",
      "Epoch 194/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7565 - val_loss: 0.5155 - val_accuracy: 0.7281\n",
      "Epoch 195/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7549 - val_loss: 0.5158 - val_accuracy: 0.7281\n",
      "Epoch 196/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7561 - val_loss: 0.5164 - val_accuracy: 0.7287\n",
      "Epoch 197/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7546 - val_loss: 0.5158 - val_accuracy: 0.7274\n",
      "Epoch 198/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7543 - val_loss: 0.5164 - val_accuracy: 0.7268\n",
      "Epoch 199/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7540 - val_loss: 0.5157 - val_accuracy: 0.7293\n",
      "Epoch 200/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7555 - val_loss: 0.5158 - val_accuracy: 0.7281\n",
      "Epoch 201/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7546 - val_loss: 0.5157 - val_accuracy: 0.7281\n",
      "Epoch 202/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7568 - val_loss: 0.5159 - val_accuracy: 0.7306\n",
      "Epoch 203/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7543 - val_loss: 0.5157 - val_accuracy: 0.7293\n",
      "Epoch 204/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7555 - val_loss: 0.5162 - val_accuracy: 0.7287\n",
      "Epoch 205/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7543 - val_loss: 0.5158 - val_accuracy: 0.7293\n",
      "Epoch 206/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7558 - val_loss: 0.5162 - val_accuracy: 0.7281\n",
      "Epoch 207/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7543 - val_loss: 0.5158 - val_accuracy: 0.7300\n",
      "Epoch 208/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7561 - val_loss: 0.5162 - val_accuracy: 0.7319\n",
      "Epoch 209/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7546 - val_loss: 0.5157 - val_accuracy: 0.7274\n",
      "Epoch 210/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7549 - val_loss: 0.5157 - val_accuracy: 0.7306\n",
      "Epoch 211/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7549 - val_loss: 0.5158 - val_accuracy: 0.7312\n",
      "Epoch 212/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7549 - val_loss: 0.5158 - val_accuracy: 0.7287\n",
      "Epoch 213/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7537 - val_loss: 0.5161 - val_accuracy: 0.7306\n",
      "Epoch 214/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7546 - val_loss: 0.5162 - val_accuracy: 0.7268\n",
      "Epoch 215/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7533 - val_loss: 0.5159 - val_accuracy: 0.7306\n",
      "Epoch 216/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7543 - val_loss: 0.5165 - val_accuracy: 0.7274\n",
      "Epoch 217/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7537 - val_loss: 0.5154 - val_accuracy: 0.7306\n",
      "Epoch 218/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7540 - val_loss: 0.5158 - val_accuracy: 0.7293\n",
      "Epoch 219/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7515 - val_loss: 0.5159 - val_accuracy: 0.7287\n",
      "Epoch 220/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7537 - val_loss: 0.5157 - val_accuracy: 0.7325\n",
      "Epoch 221/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7543 - val_loss: 0.5156 - val_accuracy: 0.7319\n",
      "Epoch 222/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7555 - val_loss: 0.5161 - val_accuracy: 0.7293\n",
      "Epoch 223/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7521 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 224/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7543 - val_loss: 0.5154 - val_accuracy: 0.7300\n",
      "Epoch 225/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7527 - val_loss: 0.5155 - val_accuracy: 0.7300\n",
      "Epoch 226/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7543 - val_loss: 0.5157 - val_accuracy: 0.7306\n",
      "Epoch 227/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7524 - val_loss: 0.5159 - val_accuracy: 0.7312\n",
      "Epoch 228/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7546 - val_loss: 0.5159 - val_accuracy: 0.7293\n",
      "Epoch 229/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7543 - val_loss: 0.5156 - val_accuracy: 0.7319\n",
      "Epoch 230/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7537 - val_loss: 0.5156 - val_accuracy: 0.7293\n",
      "Epoch 231/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7530 - val_loss: 0.5154 - val_accuracy: 0.7268\n",
      "Epoch 232/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7537 - val_loss: 0.5161 - val_accuracy: 0.7268\n",
      "Epoch 233/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7543 - val_loss: 0.5159 - val_accuracy: 0.7293\n",
      "Epoch 234/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7537 - val_loss: 0.5160 - val_accuracy: 0.7287\n",
      "Epoch 235/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7521 - val_loss: 0.5156 - val_accuracy: 0.7281\n",
      "Epoch 236/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7533 - val_loss: 0.5150 - val_accuracy: 0.7281\n",
      "Epoch 237/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7530 - val_loss: 0.5154 - val_accuracy: 0.7300\n",
      "Epoch 238/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7546 - val_loss: 0.5161 - val_accuracy: 0.7300\n",
      "Epoch 239/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7518 - val_loss: 0.5151 - val_accuracy: 0.7281\n",
      "Epoch 240/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7546 - val_loss: 0.5158 - val_accuracy: 0.7287\n",
      "Epoch 241/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7540 - val_loss: 0.5153 - val_accuracy: 0.7281\n",
      "Epoch 242/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7546 - val_loss: 0.5155 - val_accuracy: 0.7274\n",
      "Epoch 243/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7543 - val_loss: 0.5153 - val_accuracy: 0.7300\n",
      "Epoch 244/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7540 - val_loss: 0.5154 - val_accuracy: 0.7268\n",
      "Epoch 245/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7530 - val_loss: 0.5155 - val_accuracy: 0.7262\n",
      "Epoch 246/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7543 - val_loss: 0.5154 - val_accuracy: 0.7281\n",
      "Epoch 247/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7527 - val_loss: 0.5149 - val_accuracy: 0.7274\n",
      "Epoch 248/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5146 - val_accuracy: 0.7287\n",
      "Epoch 249/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7533 - val_loss: 0.5146 - val_accuracy: 0.7268\n",
      "Epoch 250/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7524 - val_loss: 0.5147 - val_accuracy: 0.7262\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "65/65 [==============================] - 1s 6ms/step - loss: 0.6904 - accuracy: 0.5440 - val_loss: 0.6852 - val_accuracy: 0.5640\n",
      "Epoch 2/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.6137 - val_loss: 0.6676 - val_accuracy: 0.6454\n",
      "Epoch 3/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6802 - val_loss: 0.6409 - val_accuracy: 0.6871\n",
      "Epoch 4/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.7104 - val_loss: 0.6146 - val_accuracy: 0.7142\n",
      "Epoch 5/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6069 - accuracy: 0.7229 - val_loss: 0.5956 - val_accuracy: 0.7293\n",
      "Epoch 6/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.7306 - val_loss: 0.5822 - val_accuracy: 0.7382\n",
      "Epoch 7/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.7375 - val_loss: 0.5725 - val_accuracy: 0.7363\n",
      "Epoch 8/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7365 - val_loss: 0.5648 - val_accuracy: 0.7356\n",
      "Epoch 9/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7397 - val_loss: 0.5590 - val_accuracy: 0.7369\n",
      "Epoch 10/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7440 - val_loss: 0.5544 - val_accuracy: 0.7420\n",
      "Epoch 11/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7459 - val_loss: 0.5506 - val_accuracy: 0.7426\n",
      "Epoch 12/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7468 - val_loss: 0.5477 - val_accuracy: 0.7413\n",
      "Epoch 13/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7502 - val_loss: 0.5447 - val_accuracy: 0.7426\n",
      "Epoch 14/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7493 - val_loss: 0.5429 - val_accuracy: 0.7407\n",
      "Epoch 15/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7502 - val_loss: 0.5410 - val_accuracy: 0.7407\n",
      "Epoch 16/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7502 - val_loss: 0.5395 - val_accuracy: 0.7401\n",
      "Epoch 17/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7493 - val_loss: 0.5379 - val_accuracy: 0.7407\n",
      "Epoch 18/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7487 - val_loss: 0.5368 - val_accuracy: 0.7388\n",
      "Epoch 19/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7499 - val_loss: 0.5356 - val_accuracy: 0.7394\n",
      "Epoch 20/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7502 - val_loss: 0.5345 - val_accuracy: 0.7394\n",
      "Epoch 21/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7481 - val_loss: 0.5334 - val_accuracy: 0.7394\n",
      "Epoch 22/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7496 - val_loss: 0.5330 - val_accuracy: 0.7382\n",
      "Epoch 23/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7487 - val_loss: 0.5314 - val_accuracy: 0.7382\n",
      "Epoch 24/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7518 - val_loss: 0.5308 - val_accuracy: 0.7388\n",
      "Epoch 25/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7515 - val_loss: 0.5302 - val_accuracy: 0.7382\n",
      "Epoch 26/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7512 - val_loss: 0.5293 - val_accuracy: 0.7375\n",
      "Epoch 27/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7505 - val_loss: 0.5288 - val_accuracy: 0.7382\n",
      "Epoch 28/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7493 - val_loss: 0.5280 - val_accuracy: 0.7388\n",
      "Epoch 29/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7490 - val_loss: 0.5272 - val_accuracy: 0.7369\n",
      "Epoch 30/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7502 - val_loss: 0.5268 - val_accuracy: 0.7382\n",
      "Epoch 31/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7509 - val_loss: 0.5261 - val_accuracy: 0.7394\n",
      "Epoch 32/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7512 - val_loss: 0.5259 - val_accuracy: 0.7394\n",
      "Epoch 33/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7505 - val_loss: 0.5252 - val_accuracy: 0.7401\n",
      "Epoch 34/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7496 - val_loss: 0.5249 - val_accuracy: 0.7369\n",
      "Epoch 35/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7515 - val_loss: 0.5244 - val_accuracy: 0.7382\n",
      "Epoch 36/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7487 - val_loss: 0.5235 - val_accuracy: 0.7382\n",
      "Epoch 37/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7509 - val_loss: 0.5232 - val_accuracy: 0.7369\n",
      "Epoch 38/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7490 - val_loss: 0.5225 - val_accuracy: 0.7369\n",
      "Epoch 39/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7502 - val_loss: 0.5221 - val_accuracy: 0.7369\n",
      "Epoch 40/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7502 - val_loss: 0.5219 - val_accuracy: 0.7382\n",
      "Epoch 41/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7496 - val_loss: 0.5214 - val_accuracy: 0.7375\n",
      "Epoch 42/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7496 - val_loss: 0.5211 - val_accuracy: 0.7382\n",
      "Epoch 43/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7502 - val_loss: 0.5209 - val_accuracy: 0.7420\n",
      "Epoch 44/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7484 - val_loss: 0.5208 - val_accuracy: 0.7426\n",
      "Epoch 45/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7496 - val_loss: 0.5202 - val_accuracy: 0.7407\n",
      "Epoch 46/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7493 - val_loss: 0.5201 - val_accuracy: 0.7426\n",
      "Epoch 47/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7499 - val_loss: 0.5194 - val_accuracy: 0.7394\n",
      "Epoch 48/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7509 - val_loss: 0.5194 - val_accuracy: 0.7420\n",
      "Epoch 49/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7481 - val_loss: 0.5195 - val_accuracy: 0.7438\n",
      "Epoch 50/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7481 - val_loss: 0.5187 - val_accuracy: 0.7420\n",
      "Epoch 51/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7487 - val_loss: 0.5185 - val_accuracy: 0.7432\n",
      "Epoch 52/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7496 - val_loss: 0.5186 - val_accuracy: 0.7432\n",
      "Epoch 53/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7487 - val_loss: 0.5181 - val_accuracy: 0.7426\n",
      "Epoch 54/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7496 - val_loss: 0.5176 - val_accuracy: 0.7426\n",
      "Epoch 55/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7505 - val_loss: 0.5174 - val_accuracy: 0.7426\n",
      "Epoch 56/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7490 - val_loss: 0.5173 - val_accuracy: 0.7432\n",
      "Epoch 57/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7499 - val_loss: 0.5167 - val_accuracy: 0.7426\n",
      "Epoch 58/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7490 - val_loss: 0.5165 - val_accuracy: 0.7426\n",
      "Epoch 59/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7502 - val_loss: 0.5162 - val_accuracy: 0.7438\n",
      "Epoch 60/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7474 - val_loss: 0.5159 - val_accuracy: 0.7420\n",
      "Epoch 61/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7481 - val_loss: 0.5159 - val_accuracy: 0.7438\n",
      "Epoch 62/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7496 - val_loss: 0.5155 - val_accuracy: 0.7438\n",
      "Epoch 63/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7493 - val_loss: 0.5155 - val_accuracy: 0.7445\n",
      "Epoch 64/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7493 - val_loss: 0.5152 - val_accuracy: 0.7438\n",
      "Epoch 65/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7484 - val_loss: 0.5150 - val_accuracy: 0.7438\n",
      "Epoch 66/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7477 - val_loss: 0.5151 - val_accuracy: 0.7432\n",
      "Epoch 67/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7468 - val_loss: 0.5150 - val_accuracy: 0.7432\n",
      "Epoch 68/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7493 - val_loss: 0.5148 - val_accuracy: 0.7438\n",
      "Epoch 69/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7484 - val_loss: 0.5144 - val_accuracy: 0.7438\n",
      "Epoch 70/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7490 - val_loss: 0.5142 - val_accuracy: 0.7426\n",
      "Epoch 71/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7502 - val_loss: 0.5146 - val_accuracy: 0.7426\n",
      "Epoch 72/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7481 - val_loss: 0.5140 - val_accuracy: 0.7420\n",
      "Epoch 73/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7477 - val_loss: 0.5136 - val_accuracy: 0.7438\n",
      "Epoch 74/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7490 - val_loss: 0.5142 - val_accuracy: 0.7420\n",
      "Epoch 75/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7493 - val_loss: 0.5139 - val_accuracy: 0.7413\n",
      "Epoch 76/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7493 - val_loss: 0.5136 - val_accuracy: 0.7432\n",
      "Epoch 77/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7499 - val_loss: 0.5135 - val_accuracy: 0.7413\n",
      "Epoch 78/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7487 - val_loss: 0.5134 - val_accuracy: 0.7432\n",
      "Epoch 79/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7484 - val_loss: 0.5132 - val_accuracy: 0.7438\n",
      "Epoch 80/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7490 - val_loss: 0.5131 - val_accuracy: 0.7426\n",
      "Epoch 81/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7496 - val_loss: 0.5135 - val_accuracy: 0.7426\n",
      "Epoch 82/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7487 - val_loss: 0.5135 - val_accuracy: 0.7420\n",
      "Epoch 83/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7505 - val_loss: 0.5135 - val_accuracy: 0.7407\n",
      "Epoch 84/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7490 - val_loss: 0.5129 - val_accuracy: 0.7407\n",
      "Epoch 85/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7484 - val_loss: 0.5130 - val_accuracy: 0.7420\n",
      "Epoch 86/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5126 - val_accuracy: 0.7420\n",
      "Epoch 87/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7487 - val_loss: 0.5127 - val_accuracy: 0.7426\n",
      "Epoch 88/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7493 - val_loss: 0.5130 - val_accuracy: 0.7420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7505 - val_loss: 0.5128 - val_accuracy: 0.7401\n",
      "Epoch 90/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7490 - val_loss: 0.5128 - val_accuracy: 0.7407\n",
      "Epoch 91/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7484 - val_loss: 0.5124 - val_accuracy: 0.7426\n",
      "Epoch 92/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7493 - val_loss: 0.5126 - val_accuracy: 0.7420\n",
      "Epoch 93/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7499 - val_loss: 0.5124 - val_accuracy: 0.7407\n",
      "Epoch 94/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7502 - val_loss: 0.5122 - val_accuracy: 0.7407\n",
      "Epoch 95/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7496 - val_loss: 0.5121 - val_accuracy: 0.7413\n",
      "Epoch 96/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7499 - val_loss: 0.5124 - val_accuracy: 0.7407\n",
      "Epoch 97/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7496 - val_loss: 0.5122 - val_accuracy: 0.7413\n",
      "Epoch 98/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7499 - val_loss: 0.5120 - val_accuracy: 0.7401\n",
      "Epoch 99/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7487 - val_loss: 0.5118 - val_accuracy: 0.7432\n",
      "Epoch 100/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7496 - val_loss: 0.5127 - val_accuracy: 0.7432\n",
      "Epoch 101/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7462 - val_loss: 0.5119 - val_accuracy: 0.7420\n",
      "Epoch 102/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7496 - val_loss: 0.5118 - val_accuracy: 0.7413\n",
      "Epoch 103/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7512 - val_loss: 0.5122 - val_accuracy: 0.7426\n",
      "Epoch 104/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7477 - val_loss: 0.5120 - val_accuracy: 0.7407\n",
      "Epoch 105/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7477 - val_loss: 0.5116 - val_accuracy: 0.7413\n",
      "Epoch 106/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7477 - val_loss: 0.5114 - val_accuracy: 0.7420\n",
      "Epoch 107/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7484 - val_loss: 0.5118 - val_accuracy: 0.7413\n",
      "Epoch 108/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7487 - val_loss: 0.5117 - val_accuracy: 0.7413\n",
      "Epoch 109/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7484 - val_loss: 0.5117 - val_accuracy: 0.7413\n",
      "Epoch 110/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5117 - val_accuracy: 0.7407\n",
      "Epoch 111/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7493 - val_loss: 0.5118 - val_accuracy: 0.7420\n",
      "Epoch 112/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7477 - val_loss: 0.5116 - val_accuracy: 0.7407\n",
      "Epoch 113/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7487 - val_loss: 0.5115 - val_accuracy: 0.7413\n",
      "Epoch 114/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7509 - val_loss: 0.5115 - val_accuracy: 0.7432\n",
      "Epoch 115/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7490 - val_loss: 0.5112 - val_accuracy: 0.7407\n",
      "Epoch 116/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7487 - val_loss: 0.5117 - val_accuracy: 0.7426\n",
      "Epoch 117/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7487 - val_loss: 0.5111 - val_accuracy: 0.7413\n",
      "Epoch 118/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7446 - val_loss: 0.5108 - val_accuracy: 0.7413\n",
      "Epoch 119/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7474 - val_loss: 0.5108 - val_accuracy: 0.7413\n",
      "Epoch 120/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7487 - val_loss: 0.5108 - val_accuracy: 0.7407\n",
      "Epoch 121/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7468 - val_loss: 0.5107 - val_accuracy: 0.7394\n",
      "Epoch 122/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7487 - val_loss: 0.5117 - val_accuracy: 0.7451\n",
      "Epoch 123/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7490 - val_loss: 0.5110 - val_accuracy: 0.7407\n",
      "Epoch 124/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7487 - val_loss: 0.5109 - val_accuracy: 0.7438\n",
      "Epoch 125/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7493 - val_loss: 0.5107 - val_accuracy: 0.7413\n",
      "Epoch 126/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7490 - val_loss: 0.5108 - val_accuracy: 0.7426\n",
      "Epoch 127/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7490 - val_loss: 0.5110 - val_accuracy: 0.7438\n",
      "Epoch 128/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7499 - val_loss: 0.5103 - val_accuracy: 0.7426\n",
      "Epoch 129/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7487 - val_loss: 0.5109 - val_accuracy: 0.7413\n",
      "Epoch 130/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7484 - val_loss: 0.5105 - val_accuracy: 0.7432\n",
      "Epoch 131/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7496 - val_loss: 0.5104 - val_accuracy: 0.7426\n",
      "Epoch 132/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7490 - val_loss: 0.5106 - val_accuracy: 0.7432\n",
      "Epoch 133/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7481 - val_loss: 0.5107 - val_accuracy: 0.7438\n",
      "Epoch 134/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7499 - val_loss: 0.5106 - val_accuracy: 0.7432\n",
      "Epoch 135/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7490 - val_loss: 0.5107 - val_accuracy: 0.7432\n",
      "Epoch 136/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7505 - val_loss: 0.5107 - val_accuracy: 0.7438\n",
      "Epoch 137/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7477 - val_loss: 0.5108 - val_accuracy: 0.7438\n",
      "Epoch 138/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7493 - val_loss: 0.5105 - val_accuracy: 0.7426\n",
      "Epoch 139/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7493 - val_loss: 0.5104 - val_accuracy: 0.7438\n",
      "Epoch 140/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7487 - val_loss: 0.5105 - val_accuracy: 0.7426\n",
      "Epoch 141/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7484 - val_loss: 0.5102 - val_accuracy: 0.7438\n",
      "Epoch 142/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7509 - val_loss: 0.5103 - val_accuracy: 0.7426\n",
      "Epoch 143/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5105 - val_accuracy: 0.7420\n",
      "Epoch 144/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7487 - val_loss: 0.5102 - val_accuracy: 0.7426\n",
      "Epoch 145/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7490 - val_loss: 0.5106 - val_accuracy: 0.7426\n",
      "Epoch 146/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7496 - val_loss: 0.5105 - val_accuracy: 0.7438\n",
      "Epoch 147/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7493 - val_loss: 0.5106 - val_accuracy: 0.7420\n",
      "Epoch 148/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7484 - val_loss: 0.5107 - val_accuracy: 0.7445\n",
      "Epoch 149/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7484 - val_loss: 0.5109 - val_accuracy: 0.7432\n",
      "Epoch 150/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7474 - val_loss: 0.5103 - val_accuracy: 0.7426\n",
      "Epoch 151/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7499 - val_loss: 0.5102 - val_accuracy: 0.7426\n",
      "Epoch 152/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7496 - val_loss: 0.5101 - val_accuracy: 0.7420\n",
      "Epoch 153/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7465 - val_loss: 0.5098 - val_accuracy: 0.7420\n",
      "Epoch 154/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7512 - val_loss: 0.5100 - val_accuracy: 0.7426\n",
      "Epoch 155/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7484 - val_loss: 0.5102 - val_accuracy: 0.7438\n",
      "Epoch 156/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7496 - val_loss: 0.5102 - val_accuracy: 0.7432\n",
      "Epoch 157/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7484 - val_loss: 0.5097 - val_accuracy: 0.7426\n",
      "Epoch 158/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7487 - val_loss: 0.5099 - val_accuracy: 0.7413\n",
      "Epoch 159/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7481 - val_loss: 0.5101 - val_accuracy: 0.7432\n",
      "Epoch 160/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7487 - val_loss: 0.5097 - val_accuracy: 0.7438\n",
      "Epoch 161/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7468 - val_loss: 0.5099 - val_accuracy: 0.7432\n",
      "Epoch 162/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7493 - val_loss: 0.5098 - val_accuracy: 0.7413\n",
      "Epoch 163/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5103 - val_accuracy: 0.7432\n",
      "Epoch 164/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7481 - val_loss: 0.5098 - val_accuracy: 0.7401\n",
      "Epoch 165/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7490 - val_loss: 0.5095 - val_accuracy: 0.7432\n",
      "Epoch 166/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7481 - val_loss: 0.5098 - val_accuracy: 0.7420\n",
      "Epoch 167/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7490 - val_loss: 0.5098 - val_accuracy: 0.7420\n",
      "Epoch 168/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7496 - val_loss: 0.5100 - val_accuracy: 0.7445\n",
      "Epoch 169/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7474 - val_loss: 0.5097 - val_accuracy: 0.7438\n",
      "Epoch 170/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7477 - val_loss: 0.5105 - val_accuracy: 0.7451\n",
      "Epoch 171/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7487 - val_loss: 0.5097 - val_accuracy: 0.7426\n",
      "Epoch 172/250\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5101 - val_accuracy: 0.7445\n",
      "Epoch 173/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7493 - val_loss: 0.5098 - val_accuracy: 0.7426\n",
      "Epoch 174/250\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5058 - accuracy: 0.7465 - val_loss: 0.5100 - val_accuracy: 0.7432\n",
      "Epoch 175/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7499 - val_loss: 0.5099 - val_accuracy: 0.7420\n",
      "Epoch 176/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7496 - val_loss: 0.5100 - val_accuracy: 0.7426\n",
      "Epoch 177/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7505 - val_loss: 0.5101 - val_accuracy: 0.7445\n",
      "Epoch 178/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7496 - val_loss: 0.5095 - val_accuracy: 0.7426\n",
      "Epoch 179/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7484 - val_loss: 0.5099 - val_accuracy: 0.7432\n",
      "Epoch 180/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7481 - val_loss: 0.5096 - val_accuracy: 0.7420\n",
      "Epoch 181/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7487 - val_loss: 0.5097 - val_accuracy: 0.7420\n",
      "Epoch 182/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7496 - val_loss: 0.5100 - val_accuracy: 0.7438\n",
      "Epoch 183/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7477 - val_loss: 0.5101 - val_accuracy: 0.7445\n",
      "Epoch 184/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7477 - val_loss: 0.5097 - val_accuracy: 0.7394\n",
      "Epoch 185/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7509 - val_loss: 0.5100 - val_accuracy: 0.7438\n",
      "Epoch 186/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7487 - val_loss: 0.5102 - val_accuracy: 0.7432\n",
      "Epoch 187/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7502 - val_loss: 0.5101 - val_accuracy: 0.7432\n",
      "Epoch 188/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7487 - val_loss: 0.5101 - val_accuracy: 0.7426\n",
      "Epoch 189/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7493 - val_loss: 0.5100 - val_accuracy: 0.7401\n",
      "Epoch 190/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7499 - val_loss: 0.5101 - val_accuracy: 0.7445\n",
      "Epoch 191/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7490 - val_loss: 0.5101 - val_accuracy: 0.7432\n",
      "Epoch 192/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7499 - val_loss: 0.5098 - val_accuracy: 0.7401\n",
      "Epoch 193/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5102 - val_accuracy: 0.7438\n",
      "Epoch 194/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7499 - val_loss: 0.5100 - val_accuracy: 0.7407\n",
      "Epoch 195/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7490 - val_loss: 0.5098 - val_accuracy: 0.7407\n",
      "Epoch 196/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5101 - val_accuracy: 0.7451\n",
      "Epoch 197/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7505 - val_loss: 0.5101 - val_accuracy: 0.7413\n",
      "Epoch 198/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7499 - val_loss: 0.5099 - val_accuracy: 0.7420\n",
      "Epoch 199/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7484 - val_loss: 0.5100 - val_accuracy: 0.7401\n",
      "Epoch 200/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7499 - val_loss: 0.5101 - val_accuracy: 0.7420\n",
      "Epoch 201/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7493 - val_loss: 0.5101 - val_accuracy: 0.7432\n",
      "Epoch 202/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7481 - val_loss: 0.5102 - val_accuracy: 0.7413\n",
      "Epoch 203/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7462 - val_loss: 0.5101 - val_accuracy: 0.7407\n",
      "Epoch 204/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7496 - val_loss: 0.5100 - val_accuracy: 0.7420\n",
      "Epoch 205/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7490 - val_loss: 0.5100 - val_accuracy: 0.7420\n",
      "Epoch 206/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7499 - val_loss: 0.5099 - val_accuracy: 0.7401\n",
      "Epoch 207/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7493 - val_loss: 0.5100 - val_accuracy: 0.7420\n",
      "Epoch 208/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7487 - val_loss: 0.5098 - val_accuracy: 0.7394\n",
      "Epoch 209/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7484 - val_loss: 0.5101 - val_accuracy: 0.7407\n",
      "Epoch 210/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7505 - val_loss: 0.5098 - val_accuracy: 0.7388\n",
      "Epoch 211/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7496 - val_loss: 0.5101 - val_accuracy: 0.7426\n",
      "Epoch 212/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7487 - val_loss: 0.5101 - val_accuracy: 0.7407\n",
      "Epoch 213/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7512 - val_loss: 0.5100 - val_accuracy: 0.7420\n",
      "Epoch 214/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7471 - val_loss: 0.5102 - val_accuracy: 0.7420\n",
      "Epoch 215/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7496 - val_loss: 0.5103 - val_accuracy: 0.7426\n",
      "Epoch 216/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7499 - val_loss: 0.5102 - val_accuracy: 0.7407\n",
      "Epoch 217/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7496 - val_loss: 0.5104 - val_accuracy: 0.7426\n",
      "Epoch 218/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7490 - val_loss: 0.5100 - val_accuracy: 0.7413\n",
      "Epoch 219/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7481 - val_loss: 0.5103 - val_accuracy: 0.7426\n",
      "Epoch 220/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7515 - val_loss: 0.5098 - val_accuracy: 0.7394\n",
      "Epoch 221/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5102 - val_accuracy: 0.7432\n",
      "Epoch 222/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7481 - val_loss: 0.5101 - val_accuracy: 0.7401\n",
      "Epoch 223/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7490 - val_loss: 0.5099 - val_accuracy: 0.7420\n",
      "Epoch 224/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7493 - val_loss: 0.5103 - val_accuracy: 0.7426\n",
      "Epoch 225/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7490 - val_loss: 0.5102 - val_accuracy: 0.7413\n",
      "Epoch 226/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7484 - val_loss: 0.5103 - val_accuracy: 0.7432\n",
      "Epoch 227/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7509 - val_loss: 0.5102 - val_accuracy: 0.7432\n",
      "Epoch 228/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7505 - val_loss: 0.5101 - val_accuracy: 0.7407\n",
      "Epoch 229/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7490 - val_loss: 0.5098 - val_accuracy: 0.7388\n",
      "Epoch 230/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7496 - val_loss: 0.5098 - val_accuracy: 0.7388\n",
      "Epoch 231/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7481 - val_loss: 0.5097 - val_accuracy: 0.7407\n",
      "Epoch 232/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7484 - val_loss: 0.5098 - val_accuracy: 0.7401\n",
      "Epoch 233/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7493 - val_loss: 0.5100 - val_accuracy: 0.7426\n",
      "Epoch 234/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5102 - val_accuracy: 0.7445\n",
      "Epoch 235/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7496 - val_loss: 0.5099 - val_accuracy: 0.7426\n",
      "Epoch 236/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7505 - val_loss: 0.5099 - val_accuracy: 0.7420\n",
      "Epoch 237/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7518 - val_loss: 0.5099 - val_accuracy: 0.7394\n",
      "Epoch 238/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7496 - val_loss: 0.5100 - val_accuracy: 0.7407\n",
      "Epoch 239/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7512 - val_loss: 0.5100 - val_accuracy: 0.7407\n",
      "Epoch 240/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7512 - val_loss: 0.5099 - val_accuracy: 0.7426\n",
      "Epoch 241/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7490 - val_loss: 0.5097 - val_accuracy: 0.7401\n",
      "Epoch 242/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7505 - val_loss: 0.5096 - val_accuracy: 0.7407\n",
      "Epoch 243/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7487 - val_loss: 0.5099 - val_accuracy: 0.7445\n",
      "Epoch 244/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7499 - val_loss: 0.5097 - val_accuracy: 0.7401\n",
      "Epoch 245/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7499 - val_loss: 0.5099 - val_accuracy: 0.7420\n",
      "Epoch 246/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7502 - val_loss: 0.5100 - val_accuracy: 0.7438\n",
      "Epoch 247/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7509 - val_loss: 0.5095 - val_accuracy: 0.7420\n",
      "Epoch 248/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7499 - val_loss: 0.5102 - val_accuracy: 0.7476\n",
      "Epoch 249/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7515 - val_loss: 0.5100 - val_accuracy: 0.7445\n",
      "Epoch 250/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7512 - val_loss: 0.5106 - val_accuracy: 0.7476\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "65/65 [==============================] - 1s 7ms/step - loss: 0.6662 - accuracy: 0.5599 - val_loss: 0.6571 - val_accuracy: 0.6095\n",
      "Epoch 2/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6740 - val_loss: 0.6382 - val_accuracy: 0.6694\n",
      "Epoch 3/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.7030 - val_loss: 0.6193 - val_accuracy: 0.6845\n",
      "Epoch 4/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.7095 - val_loss: 0.6002 - val_accuracy: 0.6984\n",
      "Epoch 5/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7145 - val_loss: 0.5805 - val_accuracy: 0.7117\n",
      "Epoch 6/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7247 - val_loss: 0.5624 - val_accuracy: 0.7237\n",
      "Epoch 7/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.7313 - val_loss: 0.5474 - val_accuracy: 0.7319\n",
      "Epoch 8/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7353 - val_loss: 0.5388 - val_accuracy: 0.7356\n",
      "Epoch 9/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7353 - val_loss: 0.5329 - val_accuracy: 0.7426\n",
      "Epoch 10/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7372 - val_loss: 0.5287 - val_accuracy: 0.7420\n",
      "Epoch 11/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7387 - val_loss: 0.5257 - val_accuracy: 0.7413\n",
      "Epoch 12/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7412 - val_loss: 0.5235 - val_accuracy: 0.7394\n",
      "Epoch 13/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7406 - val_loss: 0.5216 - val_accuracy: 0.7382\n",
      "Epoch 14/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7415 - val_loss: 0.5204 - val_accuracy: 0.7420\n",
      "Epoch 15/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7431 - val_loss: 0.5190 - val_accuracy: 0.7426\n",
      "Epoch 16/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7449 - val_loss: 0.5181 - val_accuracy: 0.7445\n",
      "Epoch 17/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7443 - val_loss: 0.5171 - val_accuracy: 0.7445\n",
      "Epoch 18/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7456 - val_loss: 0.5164 - val_accuracy: 0.7413\n",
      "Epoch 19/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7471 - val_loss: 0.5158 - val_accuracy: 0.7426\n",
      "Epoch 20/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7477 - val_loss: 0.5151 - val_accuracy: 0.7413\n",
      "Epoch 21/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7481 - val_loss: 0.5145 - val_accuracy: 0.7420\n",
      "Epoch 22/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7471 - val_loss: 0.5143 - val_accuracy: 0.7394\n",
      "Epoch 23/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7477 - val_loss: 0.5138 - val_accuracy: 0.7401\n",
      "Epoch 24/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7481 - val_loss: 0.5132 - val_accuracy: 0.7407\n",
      "Epoch 25/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7490 - val_loss: 0.5129 - val_accuracy: 0.7394\n",
      "Epoch 26/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7490 - val_loss: 0.5123 - val_accuracy: 0.7394\n",
      "Epoch 27/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7487 - val_loss: 0.5122 - val_accuracy: 0.7369\n",
      "Epoch 28/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7474 - val_loss: 0.5118 - val_accuracy: 0.7388\n",
      "Epoch 29/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7484 - val_loss: 0.5113 - val_accuracy: 0.7413\n",
      "Epoch 30/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7481 - val_loss: 0.5111 - val_accuracy: 0.7413\n",
      "Epoch 31/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7490 - val_loss: 0.5110 - val_accuracy: 0.7407\n",
      "Epoch 32/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7484 - val_loss: 0.5106 - val_accuracy: 0.7413\n",
      "Epoch 33/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7474 - val_loss: 0.5101 - val_accuracy: 0.7420\n",
      "Epoch 34/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7496 - val_loss: 0.5098 - val_accuracy: 0.7420\n",
      "Epoch 35/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7509 - val_loss: 0.5098 - val_accuracy: 0.7394\n",
      "Epoch 36/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7481 - val_loss: 0.5093 - val_accuracy: 0.7388\n",
      "Epoch 37/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7502 - val_loss: 0.5095 - val_accuracy: 0.7388\n",
      "Epoch 38/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7493 - val_loss: 0.5090 - val_accuracy: 0.7407\n",
      "Epoch 39/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7518 - val_loss: 0.5092 - val_accuracy: 0.7394\n",
      "Epoch 40/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5092 - val_accuracy: 0.7401\n",
      "Epoch 41/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7509 - val_loss: 0.5085 - val_accuracy: 0.7394\n",
      "Epoch 42/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5096 - val_accuracy: 0.7388\n",
      "Epoch 43/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7502 - val_loss: 0.5085 - val_accuracy: 0.7388\n",
      "Epoch 44/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7481 - val_loss: 0.5084 - val_accuracy: 0.7401\n",
      "Epoch 45/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7527 - val_loss: 0.5091 - val_accuracy: 0.7382\n",
      "Epoch 46/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7518 - val_loss: 0.5082 - val_accuracy: 0.7420\n",
      "Epoch 47/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7515 - val_loss: 0.5082 - val_accuracy: 0.7413\n",
      "Epoch 48/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7505 - val_loss: 0.5081 - val_accuracy: 0.7401\n",
      "Epoch 49/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7413\n",
      "Epoch 50/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7512 - val_loss: 0.5083 - val_accuracy: 0.7426\n",
      "Epoch 51/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7413\n",
      "Epoch 52/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7493 - val_loss: 0.5078 - val_accuracy: 0.7407\n",
      "Epoch 53/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7490 - val_loss: 0.5082 - val_accuracy: 0.7413\n",
      "Epoch 54/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7432\n",
      "Epoch 55/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7509 - val_loss: 0.5080 - val_accuracy: 0.7432\n",
      "Epoch 56/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7505 - val_loss: 0.5075 - val_accuracy: 0.7420\n",
      "Epoch 57/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7432\n",
      "Epoch 58/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7512 - val_loss: 0.5079 - val_accuracy: 0.7426\n",
      "Epoch 59/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7515 - val_loss: 0.5077 - val_accuracy: 0.7438\n",
      "Epoch 60/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7512 - val_loss: 0.5077 - val_accuracy: 0.7426\n",
      "Epoch 61/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7499 - val_loss: 0.5078 - val_accuracy: 0.7451\n",
      "Epoch 62/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7512 - val_loss: 0.5076 - val_accuracy: 0.7457\n",
      "Epoch 63/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7515 - val_loss: 0.5083 - val_accuracy: 0.7438\n",
      "Epoch 64/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7487 - val_loss: 0.5087 - val_accuracy: 0.7432\n",
      "Epoch 65/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7484 - val_loss: 0.5077 - val_accuracy: 0.7438\n",
      "Epoch 66/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7496 - val_loss: 0.5074 - val_accuracy: 0.7445\n",
      "Epoch 67/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7512 - val_loss: 0.5074 - val_accuracy: 0.7426\n",
      "Epoch 69/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7484 - val_loss: 0.5077 - val_accuracy: 0.7457\n",
      "Epoch 70/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7426\n",
      "Epoch 71/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7451\n",
      "Epoch 72/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7432\n",
      "Epoch 73/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7496 - val_loss: 0.5072 - val_accuracy: 0.7407\n",
      "Epoch 74/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7512 - val_loss: 0.5075 - val_accuracy: 0.7445\n",
      "Epoch 75/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7496 - val_loss: 0.5075 - val_accuracy: 0.7407\n",
      "Epoch 76/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7515 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 77/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7499 - val_loss: 0.5073 - val_accuracy: 0.7464\n",
      "Epoch 78/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7484 - val_loss: 0.5073 - val_accuracy: 0.7457\n",
      "Epoch 79/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7505 - val_loss: 0.5080 - val_accuracy: 0.7457\n",
      "Epoch 80/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7487 - val_loss: 0.5073 - val_accuracy: 0.7464\n",
      "Epoch 81/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7496 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 82/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7490 - val_loss: 0.5072 - val_accuracy: 0.7457\n",
      "Epoch 83/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7484 - val_loss: 0.5075 - val_accuracy: 0.7451\n",
      "Epoch 84/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7487 - val_loss: 0.5077 - val_accuracy: 0.7394\n",
      "Epoch 85/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7518 - val_loss: 0.5077 - val_accuracy: 0.7464\n",
      "Epoch 86/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7487 - val_loss: 0.5078 - val_accuracy: 0.7483\n",
      "Epoch 87/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7496 - val_loss: 0.5075 - val_accuracy: 0.7432\n",
      "Epoch 88/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7474 - val_loss: 0.5075 - val_accuracy: 0.7420\n",
      "Epoch 89/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7490 - val_loss: 0.5082 - val_accuracy: 0.7457\n",
      "Epoch 90/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7499 - val_loss: 0.5074 - val_accuracy: 0.7432\n",
      "Epoch 91/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7451\n",
      "Epoch 92/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7502 - val_loss: 0.5073 - val_accuracy: 0.7432\n",
      "Epoch 93/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7484 - val_loss: 0.5075 - val_accuracy: 0.7413\n",
      "Epoch 94/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7481 - val_loss: 0.5074 - val_accuracy: 0.7451\n",
      "Epoch 95/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7487 - val_loss: 0.5072 - val_accuracy: 0.7438\n",
      "Epoch 96/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7493 - val_loss: 0.5074 - val_accuracy: 0.7457\n",
      "Epoch 97/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7490 - val_loss: 0.5076 - val_accuracy: 0.7457\n",
      "Epoch 98/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7493 - val_loss: 0.5072 - val_accuracy: 0.7451\n",
      "Epoch 99/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7481 - val_loss: 0.5073 - val_accuracy: 0.7451\n",
      "Epoch 100/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7493 - val_loss: 0.5074 - val_accuracy: 0.7451\n",
      "Epoch 101/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7445\n",
      "Epoch 102/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7481 - val_loss: 0.5075 - val_accuracy: 0.7420\n",
      "Epoch 103/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7481 - val_loss: 0.5074 - val_accuracy: 0.7445\n",
      "Epoch 104/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 105/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7493 - val_loss: 0.5075 - val_accuracy: 0.7445\n",
      "Epoch 106/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7524 - val_loss: 0.5077 - val_accuracy: 0.7457\n",
      "Epoch 107/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7445\n",
      "Epoch 108/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7477 - val_loss: 0.5076 - val_accuracy: 0.7426\n",
      "Epoch 109/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7420\n",
      "Epoch 110/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7515 - val_loss: 0.5075 - val_accuracy: 0.7451\n",
      "Epoch 111/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7464\n",
      "Epoch 112/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7490 - val_loss: 0.5072 - val_accuracy: 0.7445\n",
      "Epoch 113/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7493 - val_loss: 0.5075 - val_accuracy: 0.7464\n",
      "Epoch 114/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7451\n",
      "Epoch 115/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7496 - val_loss: 0.5076 - val_accuracy: 0.7445\n",
      "Epoch 116/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7457\n",
      "Epoch 117/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7502 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 118/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7515 - val_loss: 0.5073 - val_accuracy: 0.7445\n",
      "Epoch 119/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7502 - val_loss: 0.5076 - val_accuracy: 0.7451\n",
      "Epoch 120/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7457\n",
      "Epoch 121/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7499 - val_loss: 0.5076 - val_accuracy: 0.7445\n",
      "Epoch 122/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7493 - val_loss: 0.5074 - val_accuracy: 0.7438\n",
      "Epoch 123/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 124/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7509 - val_loss: 0.5078 - val_accuracy: 0.7445\n",
      "Epoch 125/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7481 - val_loss: 0.5082 - val_accuracy: 0.7464\n",
      "Epoch 126/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7509 - val_loss: 0.5079 - val_accuracy: 0.7464\n",
      "Epoch 127/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7505 - val_loss: 0.5074 - val_accuracy: 0.7445\n",
      "Epoch 128/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7499 - val_loss: 0.5075 - val_accuracy: 0.7432\n",
      "Epoch 129/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7505 - val_loss: 0.5076 - val_accuracy: 0.7464\n",
      "Epoch 130/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7470\n",
      "Epoch 131/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7505 - val_loss: 0.5080 - val_accuracy: 0.7457\n",
      "Epoch 132/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7502 - val_loss: 0.5079 - val_accuracy: 0.7457\n",
      "Epoch 133/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7509 - val_loss: 0.5079 - val_accuracy: 0.7445\n",
      "Epoch 134/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7515 - val_loss: 0.5080 - val_accuracy: 0.7470\n",
      "Epoch 135/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7512 - val_loss: 0.5077 - val_accuracy: 0.7451\n",
      "Epoch 136/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7499 - val_loss: 0.5082 - val_accuracy: 0.7470\n",
      "Epoch 137/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7464\n",
      "Epoch 138/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7505 - val_loss: 0.5079 - val_accuracy: 0.7464\n",
      "Epoch 139/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7496 - val_loss: 0.5076 - val_accuracy: 0.7438\n",
      "Epoch 140/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7502 - val_loss: 0.5084 - val_accuracy: 0.7464\n",
      "Epoch 141/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7451\n",
      "Epoch 142/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7509 - val_loss: 0.5078 - val_accuracy: 0.7457\n",
      "Epoch 143/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7512 - val_loss: 0.5081 - val_accuracy: 0.7470\n",
      "Epoch 144/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7484 - val_loss: 0.5079 - val_accuracy: 0.7445\n",
      "Epoch 145/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7457\n",
      "Epoch 146/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7496 - val_loss: 0.5080 - val_accuracy: 0.7451\n",
      "Epoch 147/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7505 - val_loss: 0.5080 - val_accuracy: 0.7457\n",
      "Epoch 148/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7499 - val_loss: 0.5079 - val_accuracy: 0.7451\n",
      "Epoch 149/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7490 - val_loss: 0.5079 - val_accuracy: 0.7451\n",
      "Epoch 150/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7499 - val_loss: 0.5081 - val_accuracy: 0.7451\n",
      "Epoch 151/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7451\n",
      "Epoch 152/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7481 - val_loss: 0.5080 - val_accuracy: 0.7457\n",
      "Epoch 153/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7481 - val_loss: 0.5077 - val_accuracy: 0.7445\n",
      "Epoch 154/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7484 - val_loss: 0.5081 - val_accuracy: 0.7457\n",
      "Epoch 155/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7438\n",
      "Epoch 156/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7505 - val_loss: 0.5079 - val_accuracy: 0.7445\n",
      "Epoch 157/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7496 - val_loss: 0.5079 - val_accuracy: 0.7445\n",
      "Epoch 158/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7505 - val_loss: 0.5079 - val_accuracy: 0.7464\n",
      "Epoch 159/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7512 - val_loss: 0.5077 - val_accuracy: 0.7445\n",
      "Epoch 160/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7490 - val_loss: 0.5081 - val_accuracy: 0.7451\n",
      "Epoch 161/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7464\n",
      "Epoch 162/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7505 - val_loss: 0.5077 - val_accuracy: 0.7457\n",
      "Epoch 163/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7518 - val_loss: 0.5078 - val_accuracy: 0.7457\n",
      "Epoch 164/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7509 - val_loss: 0.5080 - val_accuracy: 0.7445\n",
      "Epoch 165/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7487 - val_loss: 0.5080 - val_accuracy: 0.7464\n",
      "Epoch 166/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7484 - val_loss: 0.5076 - val_accuracy: 0.7438\n",
      "Epoch 167/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7502 - val_loss: 0.5078 - val_accuracy: 0.7464\n",
      "Epoch 168/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7499 - val_loss: 0.5077 - val_accuracy: 0.7451\n",
      "Epoch 169/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7493 - val_loss: 0.5074 - val_accuracy: 0.7445\n",
      "Epoch 170/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7505 - val_loss: 0.5081 - val_accuracy: 0.7457\n",
      "Epoch 171/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7490 - val_loss: 0.5076 - val_accuracy: 0.7451\n",
      "Epoch 172/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7521 - val_loss: 0.5084 - val_accuracy: 0.7445\n",
      "Epoch 173/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7502 - val_loss: 0.5074 - val_accuracy: 0.7445\n",
      "Epoch 174/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7490 - val_loss: 0.5089 - val_accuracy: 0.7445\n",
      "Epoch 175/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7515 - val_loss: 0.5079 - val_accuracy: 0.7438\n",
      "Epoch 176/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7502 - val_loss: 0.5080 - val_accuracy: 0.7451\n",
      "Epoch 177/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7493 - val_loss: 0.5077 - val_accuracy: 0.7445\n",
      "Epoch 178/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7493 - val_loss: 0.5074 - val_accuracy: 0.7432\n",
      "Epoch 179/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7518 - val_loss: 0.5076 - val_accuracy: 0.7451\n",
      "Epoch 180/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7490 - val_loss: 0.5077 - val_accuracy: 0.7445\n",
      "Epoch 181/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7487 - val_loss: 0.5080 - val_accuracy: 0.7445\n",
      "Epoch 182/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7515 - val_loss: 0.5082 - val_accuracy: 0.7432\n",
      "Epoch 183/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7490 - val_loss: 0.5080 - val_accuracy: 0.7451\n",
      "Epoch 184/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7490 - val_loss: 0.5083 - val_accuracy: 0.7464\n",
      "Epoch 185/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7502 - val_loss: 0.5077 - val_accuracy: 0.7445\n",
      "Epoch 186/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7533 - val_loss: 0.5082 - val_accuracy: 0.7451\n",
      "Epoch 187/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7505 - val_loss: 0.5079 - val_accuracy: 0.7457\n",
      "Epoch 188/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7502 - val_loss: 0.5085 - val_accuracy: 0.7464\n",
      "Epoch 189/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7505 - val_loss: 0.5081 - val_accuracy: 0.7457\n",
      "Epoch 190/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7484 - val_loss: 0.5084 - val_accuracy: 0.7445\n",
      "Epoch 191/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7512 - val_loss: 0.5092 - val_accuracy: 0.7445\n",
      "Epoch 192/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7505 - val_loss: 0.5085 - val_accuracy: 0.7445\n",
      "Epoch 193/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7502 - val_loss: 0.5083 - val_accuracy: 0.7451\n",
      "Epoch 194/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7502 - val_loss: 0.5089 - val_accuracy: 0.7451\n",
      "Epoch 195/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7474 - val_loss: 0.5088 - val_accuracy: 0.7464\n",
      "Epoch 196/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7481 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 197/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7490 - val_loss: 0.5087 - val_accuracy: 0.7470\n",
      "Epoch 198/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7502 - val_loss: 0.5104 - val_accuracy: 0.7445\n",
      "Epoch 199/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7515 - val_loss: 0.5085 - val_accuracy: 0.7445\n",
      "Epoch 200/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7509 - val_loss: 0.5083 - val_accuracy: 0.7457\n",
      "Epoch 201/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7487 - val_loss: 0.5085 - val_accuracy: 0.7445\n",
      "Epoch 202/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7512 - val_loss: 0.5087 - val_accuracy: 0.7464\n",
      "Epoch 203/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7499 - val_loss: 0.5091 - val_accuracy: 0.7457\n",
      "Epoch 204/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7496 - val_loss: 0.5090 - val_accuracy: 0.7464\n",
      "Epoch 205/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7496 - val_loss: 0.5091 - val_accuracy: 0.7457\n",
      "Epoch 206/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7515 - val_loss: 0.5090 - val_accuracy: 0.7451\n",
      "Epoch 207/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7515 - val_loss: 0.5087 - val_accuracy: 0.7464\n",
      "Epoch 208/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7502 - val_loss: 0.5086 - val_accuracy: 0.7464\n",
      "Epoch 209/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7509 - val_loss: 0.5099 - val_accuracy: 0.7445\n",
      "Epoch 210/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7509 - val_loss: 0.5090 - val_accuracy: 0.7451\n",
      "Epoch 211/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7512 - val_loss: 0.5087 - val_accuracy: 0.7432\n",
      "Epoch 212/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7493 - val_loss: 0.5087 - val_accuracy: 0.7464\n",
      "Epoch 213/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7499 - val_loss: 0.5092 - val_accuracy: 0.7451\n",
      "Epoch 214/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7493 - val_loss: 0.5094 - val_accuracy: 0.7438\n",
      "Epoch 215/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7524 - val_loss: 0.5091 - val_accuracy: 0.7445\n",
      "Epoch 216/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7524 - val_loss: 0.5088 - val_accuracy: 0.7457\n",
      "Epoch 217/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7515 - val_loss: 0.5090 - val_accuracy: 0.7445\n",
      "Epoch 218/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7468 - val_loss: 0.5098 - val_accuracy: 0.7457\n",
      "Epoch 219/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7512 - val_loss: 0.5091 - val_accuracy: 0.7457\n",
      "Epoch 220/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7505 - val_loss: 0.5089 - val_accuracy: 0.7445\n",
      "Epoch 221/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7490 - val_loss: 0.5100 - val_accuracy: 0.7451\n",
      "Epoch 222/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7509 - val_loss: 0.5091 - val_accuracy: 0.7451\n",
      "Epoch 223/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7477 - val_loss: 0.5094 - val_accuracy: 0.7457\n",
      "Epoch 224/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7502 - val_loss: 0.5091 - val_accuracy: 0.7451\n",
      "Epoch 225/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7505 - val_loss: 0.5092 - val_accuracy: 0.7451\n",
      "Epoch 226/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7505 - val_loss: 0.5092 - val_accuracy: 0.7470\n",
      "Epoch 227/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7496 - val_loss: 0.5092 - val_accuracy: 0.7457\n",
      "Epoch 228/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7457\n",
      "Epoch 229/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7490 - val_loss: 0.5092 - val_accuracy: 0.7457\n",
      "Epoch 230/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7502 - val_loss: 0.5092 - val_accuracy: 0.7451\n",
      "Epoch 231/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7493 - val_loss: 0.5091 - val_accuracy: 0.7445\n",
      "Epoch 232/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7490 - val_loss: 0.5093 - val_accuracy: 0.7445\n",
      "Epoch 233/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7487 - val_loss: 0.5090 - val_accuracy: 0.7457\n",
      "Epoch 234/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7490 - val_loss: 0.5092 - val_accuracy: 0.7457\n",
      "Epoch 235/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7502 - val_loss: 0.5091 - val_accuracy: 0.7457\n",
      "Epoch 236/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7502 - val_loss: 0.5091 - val_accuracy: 0.7445\n",
      "Epoch 237/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7515 - val_loss: 0.5091 - val_accuracy: 0.7451\n",
      "Epoch 238/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7490 - val_loss: 0.5092 - val_accuracy: 0.7457\n",
      "Epoch 239/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7512 - val_loss: 0.5089 - val_accuracy: 0.7464\n",
      "Epoch 240/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7484 - val_loss: 0.5088 - val_accuracy: 0.7464\n",
      "Epoch 241/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7487 - val_loss: 0.5091 - val_accuracy: 0.7457\n",
      "Epoch 242/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7505 - val_loss: 0.5091 - val_accuracy: 0.7438\n",
      "Epoch 243/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7527 - val_loss: 0.5088 - val_accuracy: 0.7451\n",
      "Epoch 244/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7505 - val_loss: 0.5090 - val_accuracy: 0.7457\n",
      "Epoch 245/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7484 - val_loss: 0.5090 - val_accuracy: 0.7451\n",
      "Epoch 246/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7499 - val_loss: 0.5093 - val_accuracy: 0.7470\n",
      "Epoch 247/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7509 - val_loss: 0.5092 - val_accuracy: 0.7457\n",
      "Epoch 248/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7481 - val_loss: 0.5088 - val_accuracy: 0.7470\n",
      "Epoch 249/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7477 - val_loss: 0.5092 - val_accuracy: 0.7451\n",
      "Epoch 250/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7512 - val_loss: 0.5090 - val_accuracy: 0.7457\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "65/65 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.5151 - val_loss: 0.6929 - val_accuracy: 0.5180\n",
      "Epoch 2/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5163 - val_loss: 0.6928 - val_accuracy: 0.5180\n",
      "Epoch 3/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5163 - val_loss: 0.6927 - val_accuracy: 0.5180\n",
      "Epoch 4/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.5180\n",
      "Epoch 5/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.5180\n",
      "Epoch 6/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.5180\n",
      "Epoch 7/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 8/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 9/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 10/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 11/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 12/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 13/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 14/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 15/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 16/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 17/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 18/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 19/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 20/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 21/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 22/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 23/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 24/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 25/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 26/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 27/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 28/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 29/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 30/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 31/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 32/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 33/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 34/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 35/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 36/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 37/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 38/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 39/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 40/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 41/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 42/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 43/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 44/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 45/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 46/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 47/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 48/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 49/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 50/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 51/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 52/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 53/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 54/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 55/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 56/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 57/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 58/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 59/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 60/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 61/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 62/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 63/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 64/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 65/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 66/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 67/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 68/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 69/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 70/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 71/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 72/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 73/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 74/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 75/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 76/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 77/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 78/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 79/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 80/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 81/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 82/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 83/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 84/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 85/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 86/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 87/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 88/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 89/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 90/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 91/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 92/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 93/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 94/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 95/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 96/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 97/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 98/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 99/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 100/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 101/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 102/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 103/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 105/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 106/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 107/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 108/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 109/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 110/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 111/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 112/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 113/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 114/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 115/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 116/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 117/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 118/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 119/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 120/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 121/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 122/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 123/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 124/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 125/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 126/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 127/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 128/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 129/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 130/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 131/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 132/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 133/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 134/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 135/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 136/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 137/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 138/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 139/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 140/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 141/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 142/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 143/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 144/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 145/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 146/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 147/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 148/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 149/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 150/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 151/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 152/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 153/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 154/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 155/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 156/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 157/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 158/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 159/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 160/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 161/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 162/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 163/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 164/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 165/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 166/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 167/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 168/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 169/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 170/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 171/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 172/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 173/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 174/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 175/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 176/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 177/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 178/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 179/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 180/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 181/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 182/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 183/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 184/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 185/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 186/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 187/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 188/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 189/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 190/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 191/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 192/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 193/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 194/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 195/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 196/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 197/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 198/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 199/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 200/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 201/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 202/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 203/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 204/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 205/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 206/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 207/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 208/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 209/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 210/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 211/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 212/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 213/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 214/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 215/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 216/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 217/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 218/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 219/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 220/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 221/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 222/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 223/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 224/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 225/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 226/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 227/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 228/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 229/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 230/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 231/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 232/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 233/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 234/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 235/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 236/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 237/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 238/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 239/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 240/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 241/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 242/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 243/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 244/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 245/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 246/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 247/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 248/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 249/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 250/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "65/65 [==============================] - 1s 5ms/step - loss: 0.6489 - accuracy: 0.6283 - val_loss: 0.6338 - val_accuracy: 0.6568\n",
      "Epoch 2/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6980 - val_loss: 0.6121 - val_accuracy: 0.6915\n",
      "Epoch 3/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.7182 - val_loss: 0.5972 - val_accuracy: 0.7091\n",
      "Epoch 4/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7281 - val_loss: 0.5873 - val_accuracy: 0.7199\n",
      "Epoch 5/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7285 - val_loss: 0.5781 - val_accuracy: 0.7281\n",
      "Epoch 6/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7362 - val_loss: 0.5710 - val_accuracy: 0.7312\n",
      "Epoch 7/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7428 - val_loss: 0.5648 - val_accuracy: 0.7325\n",
      "Epoch 8/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7446 - val_loss: 0.5600 - val_accuracy: 0.7350\n",
      "Epoch 9/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7456 - val_loss: 0.5560 - val_accuracy: 0.7369\n",
      "Epoch 10/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7459 - val_loss: 0.5525 - val_accuracy: 0.7375\n",
      "Epoch 11/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7443 - val_loss: 0.5494 - val_accuracy: 0.7375\n",
      "Epoch 12/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7471 - val_loss: 0.5467 - val_accuracy: 0.7363\n",
      "Epoch 13/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7496 - val_loss: 0.5442 - val_accuracy: 0.7375\n",
      "Epoch 14/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7490 - val_loss: 0.5420 - val_accuracy: 0.7388\n",
      "Epoch 15/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7502 - val_loss: 0.5404 - val_accuracy: 0.7382\n",
      "Epoch 16/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7496 - val_loss: 0.5385 - val_accuracy: 0.7356\n",
      "Epoch 17/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7484 - val_loss: 0.5370 - val_accuracy: 0.7369\n",
      "Epoch 18/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7502 - val_loss: 0.5356 - val_accuracy: 0.7369\n",
      "Epoch 19/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7509 - val_loss: 0.5343 - val_accuracy: 0.7369\n",
      "Epoch 20/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7512 - val_loss: 0.5331 - val_accuracy: 0.7356\n",
      "Epoch 21/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7527 - val_loss: 0.5320 - val_accuracy: 0.7369\n",
      "Epoch 22/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7518 - val_loss: 0.5314 - val_accuracy: 0.7350\n",
      "Epoch 23/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7515 - val_loss: 0.5305 - val_accuracy: 0.7338\n",
      "Epoch 24/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7533 - val_loss: 0.5299 - val_accuracy: 0.7356\n",
      "Epoch 25/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7509 - val_loss: 0.5289 - val_accuracy: 0.7350\n",
      "Epoch 26/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7515 - val_loss: 0.5280 - val_accuracy: 0.7356\n",
      "Epoch 27/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7518 - val_loss: 0.5276 - val_accuracy: 0.7375\n",
      "Epoch 28/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7509 - val_loss: 0.5268 - val_accuracy: 0.7350\n",
      "Epoch 29/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7515 - val_loss: 0.5264 - val_accuracy: 0.7356\n",
      "Epoch 30/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7512 - val_loss: 0.5260 - val_accuracy: 0.7369\n",
      "Epoch 31/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7518 - val_loss: 0.5253 - val_accuracy: 0.7350\n",
      "Epoch 32/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7530 - val_loss: 0.5245 - val_accuracy: 0.7356\n",
      "Epoch 33/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7521 - val_loss: 0.5238 - val_accuracy: 0.7338\n",
      "Epoch 34/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7509 - val_loss: 0.5236 - val_accuracy: 0.7356\n",
      "Epoch 35/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7509 - val_loss: 0.5228 - val_accuracy: 0.7363\n",
      "Epoch 36/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7537 - val_loss: 0.5227 - val_accuracy: 0.7382\n",
      "Epoch 37/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7524 - val_loss: 0.5222 - val_accuracy: 0.7369\n",
      "Epoch 38/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7530 - val_loss: 0.5219 - val_accuracy: 0.7369\n",
      "Epoch 39/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7521 - val_loss: 0.5216 - val_accuracy: 0.7356\n",
      "Epoch 40/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7524 - val_loss: 0.5211 - val_accuracy: 0.7375\n",
      "Epoch 41/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7524 - val_loss: 0.5206 - val_accuracy: 0.7375\n",
      "Epoch 42/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7533 - val_loss: 0.5203 - val_accuracy: 0.7375\n",
      "Epoch 43/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7540 - val_loss: 0.5199 - val_accuracy: 0.7356\n",
      "Epoch 44/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7533 - val_loss: 0.5199 - val_accuracy: 0.7363\n",
      "Epoch 45/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7515 - val_loss: 0.5195 - val_accuracy: 0.7375\n",
      "Epoch 46/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7515 - val_loss: 0.5192 - val_accuracy: 0.7375\n",
      "Epoch 47/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7537 - val_loss: 0.5188 - val_accuracy: 0.7375\n",
      "Epoch 48/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7527 - val_loss: 0.5185 - val_accuracy: 0.7388\n",
      "Epoch 49/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7527 - val_loss: 0.5177 - val_accuracy: 0.7363\n",
      "Epoch 50/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7515 - val_loss: 0.5173 - val_accuracy: 0.7363\n",
      "Epoch 51/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7512 - val_loss: 0.5171 - val_accuracy: 0.7375\n",
      "Epoch 52/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7521 - val_loss: 0.5164 - val_accuracy: 0.7375\n",
      "Epoch 53/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7521 - val_loss: 0.5161 - val_accuracy: 0.7356\n",
      "Epoch 54/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7518 - val_loss: 0.5161 - val_accuracy: 0.7369\n",
      "Epoch 55/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7524 - val_loss: 0.5159 - val_accuracy: 0.7375\n",
      "Epoch 56/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7502 - val_loss: 0.5154 - val_accuracy: 0.7363\n",
      "Epoch 57/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7518 - val_loss: 0.5152 - val_accuracy: 0.7363\n",
      "Epoch 58/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7521 - val_loss: 0.5150 - val_accuracy: 0.7356\n",
      "Epoch 59/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7521 - val_loss: 0.5148 - val_accuracy: 0.7356\n",
      "Epoch 60/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7512 - val_loss: 0.5144 - val_accuracy: 0.7356\n",
      "Epoch 61/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7521 - val_loss: 0.5142 - val_accuracy: 0.7350\n",
      "Epoch 62/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7496 - val_loss: 0.5140 - val_accuracy: 0.7356\n",
      "Epoch 63/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7493 - val_loss: 0.5138 - val_accuracy: 0.7338\n",
      "Epoch 64/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7496 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
      "Epoch 65/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7518 - val_loss: 0.5136 - val_accuracy: 0.7350\n",
      "Epoch 66/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7505 - val_loss: 0.5135 - val_accuracy: 0.7382\n",
      "Epoch 67/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7484 - val_loss: 0.5130 - val_accuracy: 0.7350\n",
      "Epoch 68/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7533 - val_loss: 0.5132 - val_accuracy: 0.7375\n",
      "Epoch 69/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7496 - val_loss: 0.5132 - val_accuracy: 0.7369\n",
      "Epoch 70/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7496 - val_loss: 0.5128 - val_accuracy: 0.7356\n",
      "Epoch 71/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7518 - val_loss: 0.5129 - val_accuracy: 0.7369\n",
      "Epoch 72/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7490 - val_loss: 0.5125 - val_accuracy: 0.7369\n",
      "Epoch 73/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7505 - val_loss: 0.5126 - val_accuracy: 0.7350\n",
      "Epoch 74/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7487 - val_loss: 0.5123 - val_accuracy: 0.7356\n",
      "Epoch 75/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7515 - val_loss: 0.5121 - val_accuracy: 0.7375\n",
      "Epoch 76/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7509 - val_loss: 0.5119 - val_accuracy: 0.7350\n",
      "Epoch 77/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7484 - val_loss: 0.5121 - val_accuracy: 0.7375\n",
      "Epoch 78/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7518 - val_loss: 0.5117 - val_accuracy: 0.7363\n",
      "Epoch 79/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7487 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
      "Epoch 80/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7490 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
      "Epoch 81/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7527 - val_loss: 0.5116 - val_accuracy: 0.7375\n",
      "Epoch 82/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7481 - val_loss: 0.5114 - val_accuracy: 0.7401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7490 - val_loss: 0.5116 - val_accuracy: 0.7388\n",
      "Epoch 84/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7499 - val_loss: 0.5115 - val_accuracy: 0.7369\n",
      "Epoch 85/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7484 - val_loss: 0.5117 - val_accuracy: 0.7420\n",
      "Epoch 86/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7509 - val_loss: 0.5113 - val_accuracy: 0.7388\n",
      "Epoch 87/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7496 - val_loss: 0.5114 - val_accuracy: 0.7363\n",
      "Epoch 88/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7512 - val_loss: 0.5110 - val_accuracy: 0.7388\n",
      "Epoch 89/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7496 - val_loss: 0.5112 - val_accuracy: 0.7363\n",
      "Epoch 90/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7499 - val_loss: 0.5107 - val_accuracy: 0.7363\n",
      "Epoch 91/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7481 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
      "Epoch 92/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7505 - val_loss: 0.5109 - val_accuracy: 0.7375\n",
      "Epoch 93/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7502 - val_loss: 0.5110 - val_accuracy: 0.7382\n",
      "Epoch 94/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7499 - val_loss: 0.5109 - val_accuracy: 0.7369\n",
      "Epoch 95/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7509 - val_loss: 0.5109 - val_accuracy: 0.7363\n",
      "Epoch 96/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7521 - val_loss: 0.5108 - val_accuracy: 0.7394\n",
      "Epoch 97/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7505 - val_loss: 0.5107 - val_accuracy: 0.7369\n",
      "Epoch 98/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7496 - val_loss: 0.5108 - val_accuracy: 0.7375\n",
      "Epoch 99/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7487 - val_loss: 0.5106 - val_accuracy: 0.7375\n",
      "Epoch 100/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7515 - val_loss: 0.5105 - val_accuracy: 0.7394\n",
      "Epoch 101/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7502 - val_loss: 0.5107 - val_accuracy: 0.7413\n",
      "Epoch 102/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7505 - val_loss: 0.5103 - val_accuracy: 0.7388\n",
      "Epoch 103/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7487 - val_loss: 0.5101 - val_accuracy: 0.7401\n",
      "Epoch 104/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7499 - val_loss: 0.5104 - val_accuracy: 0.7375\n",
      "Epoch 105/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7490 - val_loss: 0.5102 - val_accuracy: 0.7388\n",
      "Epoch 106/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7502 - val_loss: 0.5101 - val_accuracy: 0.7401\n",
      "Epoch 107/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7505 - val_loss: 0.5103 - val_accuracy: 0.7382\n",
      "Epoch 108/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7521 - val_loss: 0.5107 - val_accuracy: 0.7420\n",
      "Epoch 109/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7493 - val_loss: 0.5102 - val_accuracy: 0.7401\n",
      "Epoch 110/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7512 - val_loss: 0.5103 - val_accuracy: 0.7375\n",
      "Epoch 111/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7521 - val_loss: 0.5100 - val_accuracy: 0.7369\n",
      "Epoch 112/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5100 - val_accuracy: 0.7394\n",
      "Epoch 113/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7505 - val_loss: 0.5100 - val_accuracy: 0.7413\n",
      "Epoch 114/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7515 - val_loss: 0.5101 - val_accuracy: 0.7413\n",
      "Epoch 115/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7515 - val_loss: 0.5098 - val_accuracy: 0.7394\n",
      "Epoch 116/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7502 - val_loss: 0.5099 - val_accuracy: 0.7413\n",
      "Epoch 117/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7518 - val_loss: 0.5098 - val_accuracy: 0.7401\n",
      "Epoch 118/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7509 - val_loss: 0.5099 - val_accuracy: 0.7375\n",
      "Epoch 119/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7521 - val_loss: 0.5101 - val_accuracy: 0.7407\n",
      "Epoch 120/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5103 - val_accuracy: 0.7420\n",
      "Epoch 121/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7515 - val_loss: 0.5101 - val_accuracy: 0.7401\n",
      "Epoch 122/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7502 - val_loss: 0.5099 - val_accuracy: 0.7401\n",
      "Epoch 123/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7505 - val_loss: 0.5098 - val_accuracy: 0.7401\n",
      "Epoch 124/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5096 - val_accuracy: 0.7394\n",
      "Epoch 125/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5102 - val_accuracy: 0.7426\n",
      "Epoch 126/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5097 - val_accuracy: 0.7394\n",
      "Epoch 127/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7509 - val_loss: 0.5100 - val_accuracy: 0.7394\n",
      "Epoch 128/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7521 - val_loss: 0.5095 - val_accuracy: 0.7407\n",
      "Epoch 129/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7527 - val_loss: 0.5098 - val_accuracy: 0.7388\n",
      "Epoch 130/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7527 - val_loss: 0.5098 - val_accuracy: 0.7375\n",
      "Epoch 131/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7518 - val_loss: 0.5099 - val_accuracy: 0.7401\n",
      "Epoch 132/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7502 - val_loss: 0.5094 - val_accuracy: 0.7401\n",
      "Epoch 133/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7505 - val_loss: 0.5096 - val_accuracy: 0.7407\n",
      "Epoch 134/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7524 - val_loss: 0.5097 - val_accuracy: 0.7401\n",
      "Epoch 135/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7546 - val_loss: 0.5098 - val_accuracy: 0.7413\n",
      "Epoch 136/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7515 - val_loss: 0.5099 - val_accuracy: 0.7388\n",
      "Epoch 137/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7493 - val_loss: 0.5099 - val_accuracy: 0.7413\n",
      "Epoch 138/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7515 - val_loss: 0.5099 - val_accuracy: 0.7420\n",
      "Epoch 139/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7515 - val_loss: 0.5095 - val_accuracy: 0.7407\n",
      "Epoch 140/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7521 - val_loss: 0.5096 - val_accuracy: 0.7407\n",
      "Epoch 141/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7521 - val_loss: 0.5094 - val_accuracy: 0.7407\n",
      "Epoch 142/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7502 - val_loss: 0.5096 - val_accuracy: 0.7413\n",
      "Epoch 143/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7509 - val_loss: 0.5097 - val_accuracy: 0.7445\n",
      "Epoch 144/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7521 - val_loss: 0.5094 - val_accuracy: 0.7401\n",
      "Epoch 145/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7521 - val_loss: 0.5093 - val_accuracy: 0.7413\n",
      "Epoch 146/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7527 - val_loss: 0.5095 - val_accuracy: 0.7420\n",
      "Epoch 147/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7524 - val_loss: 0.5094 - val_accuracy: 0.7407\n",
      "Epoch 148/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7509 - val_loss: 0.5097 - val_accuracy: 0.7426\n",
      "Epoch 149/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7512 - val_loss: 0.5095 - val_accuracy: 0.7401\n",
      "Epoch 150/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7518 - val_loss: 0.5093 - val_accuracy: 0.7413\n",
      "Epoch 151/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7515 - val_loss: 0.5096 - val_accuracy: 0.7401\n",
      "Epoch 152/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7505 - val_loss: 0.5098 - val_accuracy: 0.7420\n",
      "Epoch 153/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7527 - val_loss: 0.5096 - val_accuracy: 0.7382\n",
      "Epoch 154/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7496 - val_loss: 0.5094 - val_accuracy: 0.7432\n",
      "Epoch 155/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7530 - val_loss: 0.5092 - val_accuracy: 0.7401\n",
      "Epoch 156/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7505 - val_loss: 0.5093 - val_accuracy: 0.7407\n",
      "Epoch 157/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7496 - val_loss: 0.5092 - val_accuracy: 0.7382\n",
      "Epoch 158/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7512 - val_loss: 0.5094 - val_accuracy: 0.7413\n",
      "Epoch 159/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7512 - val_loss: 0.5100 - val_accuracy: 0.7413\n",
      "Epoch 160/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7527 - val_loss: 0.5094 - val_accuracy: 0.7388\n",
      "Epoch 161/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7505 - val_loss: 0.5093 - val_accuracy: 0.7388\n",
      "Epoch 162/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5098 - val_accuracy: 0.7426\n",
      "Epoch 163/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7527 - val_loss: 0.5097 - val_accuracy: 0.7394\n",
      "Epoch 164/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7502 - val_loss: 0.5095 - val_accuracy: 0.7388\n",
      "Epoch 165/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7518 - val_loss: 0.5096 - val_accuracy: 0.7394\n",
      "Epoch 166/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7496 - val_loss: 0.5094 - val_accuracy: 0.7388\n",
      "Epoch 167/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7512 - val_loss: 0.5097 - val_accuracy: 0.7426\n",
      "Epoch 168/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7496 - val_loss: 0.5096 - val_accuracy: 0.7382\n",
      "Epoch 169/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7502 - val_loss: 0.5096 - val_accuracy: 0.7426\n",
      "Epoch 170/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5094 - val_accuracy: 0.7407\n",
      "Epoch 171/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7527 - val_loss: 0.5093 - val_accuracy: 0.7407\n",
      "Epoch 172/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7512 - val_loss: 0.5092 - val_accuracy: 0.7375\n",
      "Epoch 173/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7515 - val_loss: 0.5095 - val_accuracy: 0.7401\n",
      "Epoch 174/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7512 - val_loss: 0.5096 - val_accuracy: 0.7407\n",
      "Epoch 175/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7512 - val_loss: 0.5093 - val_accuracy: 0.7401\n",
      "Epoch 176/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7530 - val_loss: 0.5098 - val_accuracy: 0.7388\n",
      "Epoch 177/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7527 - val_loss: 0.5098 - val_accuracy: 0.7401\n",
      "Epoch 178/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7518 - val_loss: 0.5098 - val_accuracy: 0.7407\n",
      "Epoch 179/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7512 - val_loss: 0.5097 - val_accuracy: 0.7388\n",
      "Epoch 180/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7515 - val_loss: 0.5098 - val_accuracy: 0.7382\n",
      "Epoch 181/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7537 - val_loss: 0.5098 - val_accuracy: 0.7382\n",
      "Epoch 182/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7537 - val_loss: 0.5099 - val_accuracy: 0.7401\n",
      "Epoch 183/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7512 - val_loss: 0.5096 - val_accuracy: 0.7401\n",
      "Epoch 184/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7533 - val_loss: 0.5094 - val_accuracy: 0.7388\n",
      "Epoch 185/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7505 - val_loss: 0.5095 - val_accuracy: 0.7401\n",
      "Epoch 186/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7512 - val_loss: 0.5098 - val_accuracy: 0.7382\n",
      "Epoch 187/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7502 - val_loss: 0.5098 - val_accuracy: 0.7382\n",
      "Epoch 188/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7515 - val_loss: 0.5100 - val_accuracy: 0.7407\n",
      "Epoch 189/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7530 - val_loss: 0.5101 - val_accuracy: 0.7382\n",
      "Epoch 190/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7518 - val_loss: 0.5101 - val_accuracy: 0.7388\n",
      "Epoch 191/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7512 - val_loss: 0.5104 - val_accuracy: 0.7369\n",
      "Epoch 192/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7509 - val_loss: 0.5098 - val_accuracy: 0.7413\n",
      "Epoch 193/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7521 - val_loss: 0.5099 - val_accuracy: 0.7394\n",
      "Epoch 194/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5099 - val_accuracy: 0.7401\n",
      "Epoch 195/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7533 - val_loss: 0.5099 - val_accuracy: 0.7394\n",
      "Epoch 196/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7521 - val_loss: 0.5100 - val_accuracy: 0.7401\n",
      "Epoch 197/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7512 - val_loss: 0.5101 - val_accuracy: 0.7394\n",
      "Epoch 198/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7530 - val_loss: 0.5102 - val_accuracy: 0.7394\n",
      "Epoch 199/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7509 - val_loss: 0.5096 - val_accuracy: 0.7394\n",
      "Epoch 200/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7502 - val_loss: 0.5105 - val_accuracy: 0.7388\n",
      "Epoch 201/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7515 - val_loss: 0.5097 - val_accuracy: 0.7401\n",
      "Epoch 202/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7512 - val_loss: 0.5098 - val_accuracy: 0.7401\n",
      "Epoch 203/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7490 - val_loss: 0.5108 - val_accuracy: 0.7420\n",
      "Epoch 204/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7530 - val_loss: 0.5103 - val_accuracy: 0.7407\n",
      "Epoch 205/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7521 - val_loss: 0.5102 - val_accuracy: 0.7394\n",
      "Epoch 206/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7505 - val_loss: 0.5102 - val_accuracy: 0.7401\n",
      "Epoch 207/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7518 - val_loss: 0.5104 - val_accuracy: 0.7401\n",
      "Epoch 208/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7509 - val_loss: 0.5103 - val_accuracy: 0.7394\n",
      "Epoch 209/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7502 - val_loss: 0.5099 - val_accuracy: 0.7420\n",
      "Epoch 210/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7521 - val_loss: 0.5099 - val_accuracy: 0.7407\n",
      "Epoch 211/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7505 - val_loss: 0.5103 - val_accuracy: 0.7407\n",
      "Epoch 212/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7518 - val_loss: 0.5102 - val_accuracy: 0.7407\n",
      "Epoch 213/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7490 - val_loss: 0.5103 - val_accuracy: 0.7363\n",
      "Epoch 214/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7499 - val_loss: 0.5101 - val_accuracy: 0.7407\n",
      "Epoch 215/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7505 - val_loss: 0.5102 - val_accuracy: 0.7401\n",
      "Epoch 216/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7499 - val_loss: 0.5102 - val_accuracy: 0.7407\n",
      "Epoch 217/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7509 - val_loss: 0.5102 - val_accuracy: 0.7426\n",
      "Epoch 218/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7499 - val_loss: 0.5104 - val_accuracy: 0.7413\n",
      "Epoch 219/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7527 - val_loss: 0.5105 - val_accuracy: 0.7426\n",
      "Epoch 220/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7499 - val_loss: 0.5105 - val_accuracy: 0.7401\n",
      "Epoch 221/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7515 - val_loss: 0.5103 - val_accuracy: 0.7394\n",
      "Epoch 222/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7502 - val_loss: 0.5105 - val_accuracy: 0.7413\n",
      "Epoch 223/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7512 - val_loss: 0.5102 - val_accuracy: 0.7401\n",
      "Epoch 224/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7505 - val_loss: 0.5105 - val_accuracy: 0.7407\n",
      "Epoch 225/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7505 - val_loss: 0.5107 - val_accuracy: 0.7401\n",
      "Epoch 226/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7515 - val_loss: 0.5108 - val_accuracy: 0.7426\n",
      "Epoch 227/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7509 - val_loss: 0.5107 - val_accuracy: 0.7394\n",
      "Epoch 228/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7496 - val_loss: 0.5108 - val_accuracy: 0.7413\n",
      "Epoch 229/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7509 - val_loss: 0.5106 - val_accuracy: 0.7394\n",
      "Epoch 230/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7515 - val_loss: 0.5104 - val_accuracy: 0.7363\n",
      "Epoch 231/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7490 - val_loss: 0.5107 - val_accuracy: 0.7401\n",
      "Epoch 232/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7512 - val_loss: 0.5106 - val_accuracy: 0.7401\n",
      "Epoch 233/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7487 - val_loss: 0.5110 - val_accuracy: 0.7394\n",
      "Epoch 234/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7515 - val_loss: 0.5111 - val_accuracy: 0.7407\n",
      "Epoch 235/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7518 - val_loss: 0.5110 - val_accuracy: 0.7413\n",
      "Epoch 236/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7512 - val_loss: 0.5108 - val_accuracy: 0.7394\n",
      "Epoch 237/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7502 - val_loss: 0.5110 - val_accuracy: 0.7382\n",
      "Epoch 238/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7512 - val_loss: 0.5110 - val_accuracy: 0.7407\n",
      "Epoch 239/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7502 - val_loss: 0.5109 - val_accuracy: 0.7394\n",
      "Epoch 240/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7521 - val_loss: 0.5110 - val_accuracy: 0.7420\n",
      "Epoch 241/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7521 - val_loss: 0.5107 - val_accuracy: 0.7388\n",
      "Epoch 242/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7477 - val_loss: 0.5109 - val_accuracy: 0.7394\n",
      "Epoch 243/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7496 - val_loss: 0.5108 - val_accuracy: 0.7413\n",
      "Epoch 244/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7515 - val_loss: 0.5106 - val_accuracy: 0.7407\n",
      "Epoch 245/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7509 - val_loss: 0.5107 - val_accuracy: 0.7394\n",
      "Epoch 246/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7496 - val_loss: 0.5109 - val_accuracy: 0.7413\n",
      "Epoch 247/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7499 - val_loss: 0.5105 - val_accuracy: 0.7401\n",
      "Epoch 248/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7496 - val_loss: 0.5106 - val_accuracy: 0.7388\n",
      "Epoch 249/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7505 - val_loss: 0.5110 - val_accuracy: 0.7407\n",
      "Epoch 250/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7493 - val_loss: 0.5111 - val_accuracy: 0.7382\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "Epoch 1/250\n",
      "65/65 [==============================] - 2s 7ms/step - loss: 0.7166 - accuracy: 0.3484 - val_loss: 0.7017 - val_accuracy: 0.3899\n",
      "Epoch 2/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.4523 - val_loss: 0.6935 - val_accuracy: 0.5016\n",
      "Epoch 3/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5098 - val_loss: 0.6928 - val_accuracy: 0.5167\n",
      "Epoch 4/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5154 - val_loss: 0.6926 - val_accuracy: 0.5180\n",
      "Epoch 5/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.5180\n",
      "Epoch 6/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.5180\n",
      "Epoch 7/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 8/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 9/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 10/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 11/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 12/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 13/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 14/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 15/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 16/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 17/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 18/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 19/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 20/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 21/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 22/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 23/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 24/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 25/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 26/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 27/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 28/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 29/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 30/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 31/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 32/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 33/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 34/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 35/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 36/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 37/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 38/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 39/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 40/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 41/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 42/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 43/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 44/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 45/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 46/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 47/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 48/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 49/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 50/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 51/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 52/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 53/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 54/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 55/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 56/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 57/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 58/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 59/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 60/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 61/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 63/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 64/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 65/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 66/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 67/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 68/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 69/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 70/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 71/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 72/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 73/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 74/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 75/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 76/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 77/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 78/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 79/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 80/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 81/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 82/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 83/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 84/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 85/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 86/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 87/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 88/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 89/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 90/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 91/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 92/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 93/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 94/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 95/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 96/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 97/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 98/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 99/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 100/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 101/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 102/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 103/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 104/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 105/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 106/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 107/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 108/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 109/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 110/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 111/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 112/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 113/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 114/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 115/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 116/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 117/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 118/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 119/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 120/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 121/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 122/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 123/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 124/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 125/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 126/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 127/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 128/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 129/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 130/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 131/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 132/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 133/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 134/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 135/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 136/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 137/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 138/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 139/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 140/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 141/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 142/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 143/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 144/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 145/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 146/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 147/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 148/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 149/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 150/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 151/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 152/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 153/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 154/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 155/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 156/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 157/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 158/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 159/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 160/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 161/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 162/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 163/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 164/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 165/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 166/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 167/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 168/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 169/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 170/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 171/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 172/250\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 173/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 174/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 175/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 176/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 177/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 178/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 179/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 180/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 181/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 182/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 183/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 184/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 185/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 186/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 187/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 188/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 189/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 190/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 191/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 192/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 193/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 194/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 195/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 196/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 197/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 198/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 199/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 200/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 201/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 202/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 203/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 204/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 205/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 206/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 207/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 208/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 209/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 210/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 211/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 212/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 213/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 214/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 215/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 216/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 217/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 218/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 219/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 220/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 221/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 222/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 223/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 224/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 225/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 226/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 227/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 228/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 229/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 230/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 231/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 232/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 233/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 234/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 235/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 236/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 237/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 238/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 239/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 240/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 241/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 242/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 243/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 244/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 245/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 246/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 247/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 248/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 249/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 250/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "38/38 [==============================] - 0s 1ms/step\n",
      "Epoch 1/250\n",
      "65/65 [==============================] - 1s 6ms/step - loss: 0.6894 - accuracy: 0.5306 - val_loss: 0.6779 - val_accuracy: 0.5552\n",
      "Epoch 2/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.5583 - val_loss: 0.6709 - val_accuracy: 0.5754\n",
      "Epoch 3/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.5705 - val_loss: 0.6655 - val_accuracy: 0.5937\n",
      "Epoch 4/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.5888 - val_loss: 0.6605 - val_accuracy: 0.6063\n",
      "Epoch 5/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.5988 - val_loss: 0.6555 - val_accuracy: 0.6088\n",
      "Epoch 6/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.6059 - val_loss: 0.6497 - val_accuracy: 0.6158\n",
      "Epoch 7/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.6156 - val_loss: 0.6423 - val_accuracy: 0.6290\n",
      "Epoch 8/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.6420 - val_loss: 0.6306 - val_accuracy: 0.6852\n",
      "Epoch 9/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.6877 - val_loss: 0.6138 - val_accuracy: 0.7098\n",
      "Epoch 10/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.7160 - val_loss: 0.5963 - val_accuracy: 0.7306\n",
      "Epoch 11/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7400 - val_loss: 0.5831 - val_accuracy: 0.7356\n",
      "Epoch 12/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7481 - val_loss: 0.5750 - val_accuracy: 0.7363\n",
      "Epoch 13/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7518 - val_loss: 0.5691 - val_accuracy: 0.7382\n",
      "Epoch 14/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.7505 - val_loss: 0.5641 - val_accuracy: 0.7382\n",
      "Epoch 15/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7509 - val_loss: 0.5602 - val_accuracy: 0.7388\n",
      "Epoch 16/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.7502 - val_loss: 0.5577 - val_accuracy: 0.7382\n",
      "Epoch 17/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.7509 - val_loss: 0.5547 - val_accuracy: 0.7388\n",
      "Epoch 18/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7487 - val_loss: 0.5519 - val_accuracy: 0.7344\n",
      "Epoch 19/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7499 - val_loss: 0.5499 - val_accuracy: 0.7350\n",
      "Epoch 20/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.7512 - val_loss: 0.5483 - val_accuracy: 0.7369\n",
      "Epoch 21/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7496 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
      "Epoch 22/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7499 - val_loss: 0.5447 - val_accuracy: 0.7344\n",
      "Epoch 23/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7515 - val_loss: 0.5432 - val_accuracy: 0.7356\n",
      "Epoch 24/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7490 - val_loss: 0.5416 - val_accuracy: 0.7356\n",
      "Epoch 25/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7521 - val_loss: 0.5408 - val_accuracy: 0.7388\n",
      "Epoch 26/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7509 - val_loss: 0.5398 - val_accuracy: 0.7338\n",
      "Epoch 27/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7527 - val_loss: 0.5388 - val_accuracy: 0.7338\n",
      "Epoch 28/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7512 - val_loss: 0.5375 - val_accuracy: 0.7363\n",
      "Epoch 29/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7505 - val_loss: 0.5367 - val_accuracy: 0.7375\n",
      "Epoch 30/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7512 - val_loss: 0.5356 - val_accuracy: 0.7338\n",
      "Epoch 31/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7499 - val_loss: 0.5345 - val_accuracy: 0.7388\n",
      "Epoch 32/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7533 - val_loss: 0.5335 - val_accuracy: 0.7350\n",
      "Epoch 33/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7530 - val_loss: 0.5324 - val_accuracy: 0.7388\n",
      "Epoch 34/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7509 - val_loss: 0.5318 - val_accuracy: 0.7356\n",
      "Epoch 35/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7530 - val_loss: 0.5310 - val_accuracy: 0.7344\n",
      "Epoch 36/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7518 - val_loss: 0.5308 - val_accuracy: 0.7363\n",
      "Epoch 37/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7509 - val_loss: 0.5295 - val_accuracy: 0.7344\n",
      "Epoch 38/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7521 - val_loss: 0.5291 - val_accuracy: 0.7363\n",
      "Epoch 39/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7518 - val_loss: 0.5282 - val_accuracy: 0.7350\n",
      "Epoch 40/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7521 - val_loss: 0.5277 - val_accuracy: 0.7363\n",
      "Epoch 41/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7515 - val_loss: 0.5267 - val_accuracy: 0.7338\n",
      "Epoch 42/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7540 - val_loss: 0.5262 - val_accuracy: 0.7356\n",
      "Epoch 43/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7499 - val_loss: 0.5258 - val_accuracy: 0.7344\n",
      "Epoch 44/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7533 - val_loss: 0.5261 - val_accuracy: 0.7363\n",
      "Epoch 45/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7505 - val_loss: 0.5251 - val_accuracy: 0.7350\n",
      "Epoch 46/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7499 - val_loss: 0.5247 - val_accuracy: 0.7338\n",
      "Epoch 47/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7518 - val_loss: 0.5244 - val_accuracy: 0.7350\n",
      "Epoch 48/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7512 - val_loss: 0.5241 - val_accuracy: 0.7338\n",
      "Epoch 49/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7518 - val_loss: 0.5242 - val_accuracy: 0.7350\n",
      "Epoch 50/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7496 - val_loss: 0.5234 - val_accuracy: 0.7312\n",
      "Epoch 51/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7515 - val_loss: 0.5233 - val_accuracy: 0.7319\n",
      "Epoch 52/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7521 - val_loss: 0.5229 - val_accuracy: 0.7306\n",
      "Epoch 53/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7518 - val_loss: 0.5226 - val_accuracy: 0.7325\n",
      "Epoch 54/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7515 - val_loss: 0.5230 - val_accuracy: 0.7306\n",
      "Epoch 55/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7512 - val_loss: 0.5222 - val_accuracy: 0.7300\n",
      "Epoch 56/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7490 - val_loss: 0.5222 - val_accuracy: 0.7344\n",
      "Epoch 57/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7527 - val_loss: 0.5221 - val_accuracy: 0.7312\n",
      "Epoch 58/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7540 - val_loss: 0.5214 - val_accuracy: 0.7319\n",
      "Epoch 59/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7530 - val_loss: 0.5212 - val_accuracy: 0.7319\n",
      "Epoch 60/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7509 - val_loss: 0.5213 - val_accuracy: 0.7300\n",
      "Epoch 61/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7493 - val_loss: 0.5211 - val_accuracy: 0.7306\n",
      "Epoch 62/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7515 - val_loss: 0.5212 - val_accuracy: 0.7293\n",
      "Epoch 63/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7512 - val_loss: 0.5210 - val_accuracy: 0.7300\n",
      "Epoch 64/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7509 - val_loss: 0.5207 - val_accuracy: 0.7300\n",
      "Epoch 65/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7546 - val_loss: 0.5213 - val_accuracy: 0.7325\n",
      "Epoch 66/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7499 - val_loss: 0.5206 - val_accuracy: 0.7287\n",
      "Epoch 67/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7530 - val_loss: 0.5204 - val_accuracy: 0.7300\n",
      "Epoch 68/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7533 - val_loss: 0.5205 - val_accuracy: 0.7268\n",
      "Epoch 69/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7477 - val_loss: 0.5201 - val_accuracy: 0.7300\n",
      "Epoch 70/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7512 - val_loss: 0.5201 - val_accuracy: 0.7287\n",
      "Epoch 71/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7509 - val_loss: 0.5199 - val_accuracy: 0.7300\n",
      "Epoch 72/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7505 - val_loss: 0.5201 - val_accuracy: 0.7306\n",
      "Epoch 73/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7524 - val_loss: 0.5202 - val_accuracy: 0.7287\n",
      "Epoch 74/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7509 - val_loss: 0.5199 - val_accuracy: 0.7300\n",
      "Epoch 75/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7499 - val_loss: 0.5197 - val_accuracy: 0.7281\n",
      "Epoch 76/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7512 - val_loss: 0.5198 - val_accuracy: 0.7268\n",
      "Epoch 77/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7524 - val_loss: 0.5198 - val_accuracy: 0.7287\n",
      "Epoch 78/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7540 - val_loss: 0.5201 - val_accuracy: 0.7287\n",
      "Epoch 79/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7515 - val_loss: 0.5195 - val_accuracy: 0.7274\n",
      "Epoch 80/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7493 - val_loss: 0.5193 - val_accuracy: 0.7274\n",
      "Epoch 81/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7521 - val_loss: 0.5195 - val_accuracy: 0.7268\n",
      "Epoch 82/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7512 - val_loss: 0.5191 - val_accuracy: 0.7293\n",
      "Epoch 83/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7512 - val_loss: 0.5195 - val_accuracy: 0.7312\n",
      "Epoch 84/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7496 - val_loss: 0.5190 - val_accuracy: 0.7281\n",
      "Epoch 85/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7509 - val_loss: 0.5192 - val_accuracy: 0.7312\n",
      "Epoch 86/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7533 - val_loss: 0.5192 - val_accuracy: 0.7274\n",
      "Epoch 87/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7512 - val_loss: 0.5188 - val_accuracy: 0.7256\n",
      "Epoch 88/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7518 - val_loss: 0.5192 - val_accuracy: 0.7274\n",
      "Epoch 89/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7509 - val_loss: 0.5190 - val_accuracy: 0.7262\n",
      "Epoch 90/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7509 - val_loss: 0.5189 - val_accuracy: 0.7300\n",
      "Epoch 91/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7527 - val_loss: 0.5190 - val_accuracy: 0.7312\n",
      "Epoch 92/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7515 - val_loss: 0.5190 - val_accuracy: 0.7281\n",
      "Epoch 93/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7509 - val_loss: 0.5189 - val_accuracy: 0.7262\n",
      "Epoch 94/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7521 - val_loss: 0.5185 - val_accuracy: 0.7281\n",
      "Epoch 95/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7512 - val_loss: 0.5184 - val_accuracy: 0.7281\n",
      "Epoch 96/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7499 - val_loss: 0.5186 - val_accuracy: 0.7281\n",
      "Epoch 97/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7530 - val_loss: 0.5182 - val_accuracy: 0.7281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7527 - val_loss: 0.5183 - val_accuracy: 0.7281\n",
      "Epoch 99/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7524 - val_loss: 0.5183 - val_accuracy: 0.7287\n",
      "Epoch 100/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7499 - val_loss: 0.5181 - val_accuracy: 0.7287\n",
      "Epoch 101/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7524 - val_loss: 0.5183 - val_accuracy: 0.7293\n",
      "Epoch 102/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7505 - val_loss: 0.5180 - val_accuracy: 0.7281\n",
      "Epoch 103/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7515 - val_loss: 0.5178 - val_accuracy: 0.7312\n",
      "Epoch 104/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7496 - val_loss: 0.5181 - val_accuracy: 0.7312\n",
      "Epoch 105/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7505 - val_loss: 0.5177 - val_accuracy: 0.7306\n",
      "Epoch 106/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7527 - val_loss: 0.5176 - val_accuracy: 0.7319\n",
      "Epoch 107/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7521 - val_loss: 0.5174 - val_accuracy: 0.7319\n",
      "Epoch 108/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7518 - val_loss: 0.5188 - val_accuracy: 0.7319\n",
      "Epoch 109/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7490 - val_loss: 0.5176 - val_accuracy: 0.7325\n",
      "Epoch 110/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7487 - val_loss: 0.5176 - val_accuracy: 0.7325\n",
      "Epoch 111/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7512 - val_loss: 0.5173 - val_accuracy: 0.7325\n",
      "Epoch 112/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7505 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 113/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7509 - val_loss: 0.5179 - val_accuracy: 0.7331\n",
      "Epoch 114/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7499 - val_loss: 0.5181 - val_accuracy: 0.7331\n",
      "Epoch 115/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7496 - val_loss: 0.5177 - val_accuracy: 0.7331\n",
      "Epoch 116/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7487 - val_loss: 0.5171 - val_accuracy: 0.7306\n",
      "Epoch 117/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7493 - val_loss: 0.5173 - val_accuracy: 0.7338\n",
      "Epoch 118/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7493 - val_loss: 0.5173 - val_accuracy: 0.7331\n",
      "Epoch 119/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7502 - val_loss: 0.5170 - val_accuracy: 0.7312\n",
      "Epoch 120/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7524 - val_loss: 0.5169 - val_accuracy: 0.7338\n",
      "Epoch 121/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7502 - val_loss: 0.5170 - val_accuracy: 0.7338\n",
      "Epoch 122/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7502 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 123/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7540 - val_loss: 0.5174 - val_accuracy: 0.7306\n",
      "Epoch 124/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7490 - val_loss: 0.5168 - val_accuracy: 0.7325\n",
      "Epoch 125/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7521 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
      "Epoch 126/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7518 - val_loss: 0.5163 - val_accuracy: 0.7325\n",
      "Epoch 127/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7505 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 128/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7537 - val_loss: 0.5160 - val_accuracy: 0.7319\n",
      "Epoch 129/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7540 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 130/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7524 - val_loss: 0.5157 - val_accuracy: 0.7338\n",
      "Epoch 131/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7530 - val_loss: 0.5157 - val_accuracy: 0.7338\n",
      "Epoch 132/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7505 - val_loss: 0.5158 - val_accuracy: 0.7306\n",
      "Epoch 133/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7505 - val_loss: 0.5160 - val_accuracy: 0.7350\n",
      "Epoch 134/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7505 - val_loss: 0.5154 - val_accuracy: 0.7300\n",
      "Epoch 135/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7530 - val_loss: 0.5154 - val_accuracy: 0.7306\n",
      "Epoch 136/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7493 - val_loss: 0.5154 - val_accuracy: 0.7338\n",
      "Epoch 137/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7499 - val_loss: 0.5153 - val_accuracy: 0.7356\n",
      "Epoch 138/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7521 - val_loss: 0.5152 - val_accuracy: 0.7319\n",
      "Epoch 139/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7521 - val_loss: 0.5151 - val_accuracy: 0.7331\n",
      "Epoch 140/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7540 - val_loss: 0.5155 - val_accuracy: 0.7350\n",
      "Epoch 141/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7518 - val_loss: 0.5153 - val_accuracy: 0.7350\n",
      "Epoch 142/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7502 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "Epoch 143/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7505 - val_loss: 0.5148 - val_accuracy: 0.7338\n",
      "Epoch 144/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7521 - val_loss: 0.5153 - val_accuracy: 0.7338\n",
      "Epoch 145/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7521 - val_loss: 0.5153 - val_accuracy: 0.7350\n",
      "Epoch 146/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7521 - val_loss: 0.5149 - val_accuracy: 0.7350\n",
      "Epoch 147/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7518 - val_loss: 0.5153 - val_accuracy: 0.7350\n",
      "Epoch 148/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7518 - val_loss: 0.5148 - val_accuracy: 0.7338\n",
      "Epoch 149/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7505 - val_loss: 0.5150 - val_accuracy: 0.7306\n",
      "Epoch 150/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7512 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 151/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7533 - val_loss: 0.5154 - val_accuracy: 0.7363\n",
      "Epoch 152/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7530 - val_loss: 0.5150 - val_accuracy: 0.7350\n",
      "Epoch 153/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7515 - val_loss: 0.5150 - val_accuracy: 0.7356\n",
      "Epoch 154/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7543 - val_loss: 0.5149 - val_accuracy: 0.7319\n",
      "Epoch 155/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7524 - val_loss: 0.5149 - val_accuracy: 0.7331\n",
      "Epoch 156/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7543 - val_loss: 0.5155 - val_accuracy: 0.7356\n",
      "Epoch 157/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7558 - val_loss: 0.5155 - val_accuracy: 0.7363\n",
      "Epoch 158/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7565 - val_loss: 0.5150 - val_accuracy: 0.7325\n",
      "Epoch 159/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7540 - val_loss: 0.5147 - val_accuracy: 0.7344\n",
      "Epoch 160/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7530 - val_loss: 0.5148 - val_accuracy: 0.7350\n",
      "Epoch 161/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7524 - val_loss: 0.5149 - val_accuracy: 0.7363\n",
      "Epoch 162/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7509 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 163/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7530 - val_loss: 0.5147 - val_accuracy: 0.7350\n",
      "Epoch 164/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7524 - val_loss: 0.5151 - val_accuracy: 0.7338\n",
      "Epoch 165/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7524 - val_loss: 0.5147 - val_accuracy: 0.7344\n",
      "Epoch 166/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7543 - val_loss: 0.5148 - val_accuracy: 0.7363\n",
      "Epoch 167/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7518 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 168/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7543 - val_loss: 0.5150 - val_accuracy: 0.7356\n",
      "Epoch 169/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7552 - val_loss: 0.5151 - val_accuracy: 0.7363\n",
      "Epoch 170/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7555 - val_loss: 0.5151 - val_accuracy: 0.7375\n",
      "Epoch 171/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7552 - val_loss: 0.5150 - val_accuracy: 0.7356\n",
      "Epoch 172/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7555 - val_loss: 0.5150 - val_accuracy: 0.7375\n",
      "Epoch 173/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7552 - val_loss: 0.5148 - val_accuracy: 0.7356\n",
      "Epoch 174/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7527 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "Epoch 175/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7533 - val_loss: 0.5153 - val_accuracy: 0.7356\n",
      "Epoch 176/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7549 - val_loss: 0.5147 - val_accuracy: 0.7350\n",
      "Epoch 177/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7533 - val_loss: 0.5147 - val_accuracy: 0.7369\n",
      "Epoch 178/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7543 - val_loss: 0.5159 - val_accuracy: 0.7369\n",
      "Epoch 179/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7552 - val_loss: 0.5149 - val_accuracy: 0.7363\n",
      "Epoch 180/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7546 - val_loss: 0.5150 - val_accuracy: 0.7350\n",
      "Epoch 181/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7524 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "Epoch 182/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7568 - val_loss: 0.5150 - val_accuracy: 0.7331\n",
      "Epoch 183/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7561 - val_loss: 0.5149 - val_accuracy: 0.7350\n",
      "Epoch 184/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7555 - val_loss: 0.5151 - val_accuracy: 0.7350\n",
      "Epoch 185/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7546 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "Epoch 186/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7546 - val_loss: 0.5146 - val_accuracy: 0.7350\n",
      "Epoch 187/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7555 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 188/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7555 - val_loss: 0.5154 - val_accuracy: 0.7375\n",
      "Epoch 189/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7540 - val_loss: 0.5147 - val_accuracy: 0.7344\n",
      "Epoch 190/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7552 - val_loss: 0.5148 - val_accuracy: 0.7331\n",
      "Epoch 191/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7543 - val_loss: 0.5153 - val_accuracy: 0.7325\n",
      "Epoch 192/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7565 - val_loss: 0.5152 - val_accuracy: 0.7356\n",
      "Epoch 193/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7555 - val_loss: 0.5155 - val_accuracy: 0.7356\n",
      "Epoch 194/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7561 - val_loss: 0.5154 - val_accuracy: 0.7344\n",
      "Epoch 195/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7565 - val_loss: 0.5156 - val_accuracy: 0.7331\n",
      "Epoch 196/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7565 - val_loss: 0.5160 - val_accuracy: 0.7344\n",
      "Epoch 197/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7571 - val_loss: 0.5160 - val_accuracy: 0.7356\n",
      "Epoch 198/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7549 - val_loss: 0.5157 - val_accuracy: 0.7331\n",
      "Epoch 199/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7602 - val_loss: 0.5159 - val_accuracy: 0.7338\n",
      "Epoch 200/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7555 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 201/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7565 - val_loss: 0.5152 - val_accuracy: 0.7356\n",
      "Epoch 202/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7530 - val_loss: 0.5155 - val_accuracy: 0.7331\n",
      "Epoch 203/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7583 - val_loss: 0.5152 - val_accuracy: 0.7344\n",
      "Epoch 204/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7571 - val_loss: 0.5156 - val_accuracy: 0.7331\n",
      "Epoch 205/250\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5036 - accuracy: 0.7540 - val_loss: 0.5155 - val_accuracy: 0.7356\n",
      "Epoch 206/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7527 - val_loss: 0.5158 - val_accuracy: 0.7338\n",
      "Epoch 207/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7558 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 208/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7577 - val_loss: 0.5154 - val_accuracy: 0.7350\n",
      "Epoch 209/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7546 - val_loss: 0.5158 - val_accuracy: 0.7350\n",
      "Epoch 210/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7571 - val_loss: 0.5155 - val_accuracy: 0.7369\n",
      "Epoch 211/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7561 - val_loss: 0.5151 - val_accuracy: 0.7325\n",
      "Epoch 212/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7533 - val_loss: 0.5156 - val_accuracy: 0.7356\n",
      "Epoch 213/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7565 - val_loss: 0.5151 - val_accuracy: 0.7363\n",
      "Epoch 214/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7537 - val_loss: 0.5150 - val_accuracy: 0.7331\n",
      "Epoch 215/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7546 - val_loss: 0.5155 - val_accuracy: 0.7325\n",
      "Epoch 216/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7583 - val_loss: 0.5160 - val_accuracy: 0.7338\n",
      "Epoch 217/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7568 - val_loss: 0.5150 - val_accuracy: 0.7338\n",
      "Epoch 218/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7577 - val_loss: 0.5157 - val_accuracy: 0.7331\n",
      "Epoch 219/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7571 - val_loss: 0.5154 - val_accuracy: 0.7344\n",
      "Epoch 220/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7552 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 221/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7543 - val_loss: 0.5150 - val_accuracy: 0.7356\n",
      "Epoch 222/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7565 - val_loss: 0.5151 - val_accuracy: 0.7350\n",
      "Epoch 223/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7571 - val_loss: 0.5158 - val_accuracy: 0.7325\n",
      "Epoch 224/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7549 - val_loss: 0.5155 - val_accuracy: 0.7331\n",
      "Epoch 225/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7571 - val_loss: 0.5155 - val_accuracy: 0.7325\n",
      "Epoch 226/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7546 - val_loss: 0.5153 - val_accuracy: 0.7338\n",
      "Epoch 227/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7589 - val_loss: 0.5153 - val_accuracy: 0.7319\n",
      "Epoch 228/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7561 - val_loss: 0.5158 - val_accuracy: 0.7338\n",
      "Epoch 229/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7558 - val_loss: 0.5152 - val_accuracy: 0.7331\n",
      "Epoch 230/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7561 - val_loss: 0.5153 - val_accuracy: 0.7331\n",
      "Epoch 231/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7589 - val_loss: 0.5151 - val_accuracy: 0.7325\n",
      "Epoch 232/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7561 - val_loss: 0.5155 - val_accuracy: 0.7375\n",
      "Epoch 233/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7543 - val_loss: 0.5152 - val_accuracy: 0.7338\n",
      "Epoch 234/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7540 - val_loss: 0.5150 - val_accuracy: 0.7356\n",
      "Epoch 235/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7574 - val_loss: 0.5151 - val_accuracy: 0.7325\n",
      "Epoch 236/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7565 - val_loss: 0.5155 - val_accuracy: 0.7338\n",
      "Epoch 237/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7586 - val_loss: 0.5153 - val_accuracy: 0.7344\n",
      "Epoch 238/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7561 - val_loss: 0.5154 - val_accuracy: 0.7344\n",
      "Epoch 239/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7552 - val_loss: 0.5152 - val_accuracy: 0.7356\n",
      "Epoch 240/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7555 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 241/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7574 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 242/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7568 - val_loss: 0.5153 - val_accuracy: 0.7338\n",
      "Epoch 243/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7549 - val_loss: 0.5157 - val_accuracy: 0.7331\n",
      "Epoch 244/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7574 - val_loss: 0.5152 - val_accuracy: 0.7325\n",
      "Epoch 245/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7574 - val_loss: 0.5151 - val_accuracy: 0.7325\n",
      "Epoch 246/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7577 - val_loss: 0.5150 - val_accuracy: 0.7319\n",
      "Epoch 247/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7580 - val_loss: 0.5152 - val_accuracy: 0.7325\n",
      "Epoch 248/250\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7565 - val_loss: 0.5154 - val_accuracy: 0.7325\n",
      "Epoch 249/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7558 - val_loss: 0.5149 - val_accuracy: 0.7350\n",
      "Epoch 250/250\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7580 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "38/38 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "recal={}\n",
    "\n",
    "for i in range(1,5):\n",
    "    for j in range(1,i+1):\n",
    "        model_nn=Sequential()\n",
    "        model_nn.add(Dense(4,  activation='relu'))\n",
    "        model_nn.add(Dense(i,  activation='relu'))\n",
    "        model_nn.add(Dense(j,  activation='relu'))\n",
    "        model_nn.add(Dense(1, activation='sigmoid'))\n",
    "        model_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model_nn.fit(x_train, y_train, validation_split=0.33, epochs=250, batch_size=50)\n",
    "        y_pred_nn=np.round(model_nn.predict(x_test))\n",
    "        recal[metrics.recall_score(y_test,y_pred_nn)]=(i,j,metrics.accuracy_score(y_test,y_pred_nn))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60705e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: (4, 3, 0.505),\n",
       " 0.806930693069307: (4, 2, 0.7625),\n",
       " 0.7904290429042904: (2, 2, 0.7616666666666667),\n",
       " 0.7970297029702971: (3, 1, 0.7458333333333333),\n",
       " 0.7937293729372937: (3, 2, 0.7658333333333334),\n",
       " 0.8102310231023102: (3, 3, 0.7541666666666667),\n",
       " 0.7986798679867987: (4, 4, 0.755)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1055733",
   "metadata": {},
   "source": [
    "#### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2ce99366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "65/65 [==============================] - 1s 5ms/step - loss: 0.6864 - accuracy: 0.5281 - val_loss: 0.6613 - val_accuracy: 0.5798\n",
      "Epoch 2/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6128 - val_loss: 0.6286 - val_accuracy: 0.6524\n",
      "Epoch 3/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6759 - val_loss: 0.6023 - val_accuracy: 0.7028\n",
      "Epoch 4/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.7207 - val_loss: 0.5881 - val_accuracy: 0.7268\n",
      "Epoch 5/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7372 - val_loss: 0.5804 - val_accuracy: 0.7281\n",
      "Epoch 6/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7409 - val_loss: 0.5753 - val_accuracy: 0.7274\n",
      "Epoch 7/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7369 - val_loss: 0.5707 - val_accuracy: 0.7293\n",
      "Epoch 8/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7375 - val_loss: 0.5668 - val_accuracy: 0.7274\n",
      "Epoch 9/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7378 - val_loss: 0.5634 - val_accuracy: 0.7274\n",
      "Epoch 10/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7365 - val_loss: 0.5603 - val_accuracy: 0.7319\n",
      "Epoch 11/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7350 - val_loss: 0.5575 - val_accuracy: 0.7338\n",
      "Epoch 12/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7375 - val_loss: 0.5553 - val_accuracy: 0.7369\n",
      "Epoch 13/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7375 - val_loss: 0.5530 - val_accuracy: 0.7356\n",
      "Epoch 14/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7384 - val_loss: 0.5509 - val_accuracy: 0.7350\n",
      "Epoch 15/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7384 - val_loss: 0.5491 - val_accuracy: 0.7375\n",
      "Epoch 16/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7387 - val_loss: 0.5473 - val_accuracy: 0.7356\n",
      "Epoch 17/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7381 - val_loss: 0.5458 - val_accuracy: 0.7344\n",
      "Epoch 18/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7381 - val_loss: 0.5442 - val_accuracy: 0.7363\n",
      "Epoch 19/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7397 - val_loss: 0.5428 - val_accuracy: 0.7356\n",
      "Epoch 20/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7403 - val_loss: 0.5419 - val_accuracy: 0.7369\n",
      "Epoch 21/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7412 - val_loss: 0.5404 - val_accuracy: 0.7375\n",
      "Epoch 22/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7400 - val_loss: 0.5391 - val_accuracy: 0.7394\n",
      "Epoch 23/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7412 - val_loss: 0.5378 - val_accuracy: 0.7382\n",
      "Epoch 24/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7403 - val_loss: 0.5365 - val_accuracy: 0.7382\n",
      "Epoch 25/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7459 - val_loss: 0.5355 - val_accuracy: 0.7407\n",
      "Epoch 26/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7415 - val_loss: 0.5344 - val_accuracy: 0.7388\n",
      "Epoch 27/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7397 - val_loss: 0.5335 - val_accuracy: 0.7401\n",
      "Epoch 28/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7437 - val_loss: 0.5326 - val_accuracy: 0.7420\n",
      "Epoch 29/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7418 - val_loss: 0.5319 - val_accuracy: 0.7432\n",
      "Epoch 30/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7443 - val_loss: 0.5313 - val_accuracy: 0.7413\n",
      "Epoch 31/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7453 - val_loss: 0.5308 - val_accuracy: 0.7413\n",
      "Epoch 32/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7459 - val_loss: 0.5301 - val_accuracy: 0.7413\n",
      "Epoch 33/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7434 - val_loss: 0.5295 - val_accuracy: 0.7407\n",
      "Epoch 34/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7484 - val_loss: 0.5288 - val_accuracy: 0.7394\n",
      "Epoch 35/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7449 - val_loss: 0.5283 - val_accuracy: 0.7375\n",
      "Epoch 36/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7481 - val_loss: 0.5277 - val_accuracy: 0.7413\n",
      "Epoch 37/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7484 - val_loss: 0.5271 - val_accuracy: 0.7407\n",
      "Epoch 38/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7502 - val_loss: 0.5266 - val_accuracy: 0.7407\n",
      "Epoch 39/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7474 - val_loss: 0.5261 - val_accuracy: 0.7401\n",
      "Epoch 40/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7493 - val_loss: 0.5257 - val_accuracy: 0.7401\n",
      "Epoch 41/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7446 - val_loss: 0.5251 - val_accuracy: 0.7401\n",
      "Epoch 42/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7471 - val_loss: 0.5246 - val_accuracy: 0.7407\n",
      "Epoch 43/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7493 - val_loss: 0.5242 - val_accuracy: 0.7413\n",
      "Epoch 44/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7502 - val_loss: 0.5239 - val_accuracy: 0.7413\n",
      "Epoch 45/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7490 - val_loss: 0.5233 - val_accuracy: 0.7438\n",
      "Epoch 46/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7465 - val_loss: 0.5231 - val_accuracy: 0.7413\n",
      "Epoch 47/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7484 - val_loss: 0.5225 - val_accuracy: 0.7426\n",
      "Epoch 48/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7499 - val_loss: 0.5220 - val_accuracy: 0.7401\n",
      "Epoch 49/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7481 - val_loss: 0.5219 - val_accuracy: 0.7413\n",
      "Epoch 50/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7487 - val_loss: 0.5217 - val_accuracy: 0.7426\n",
      "Epoch 51/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7496 - val_loss: 0.5215 - val_accuracy: 0.7432\n",
      "Epoch 52/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7474 - val_loss: 0.5208 - val_accuracy: 0.7413\n",
      "Epoch 53/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7496 - val_loss: 0.5207 - val_accuracy: 0.7413\n",
      "Epoch 54/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7502 - val_loss: 0.5205 - val_accuracy: 0.7432\n",
      "Epoch 55/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7481 - val_loss: 0.5200 - val_accuracy: 0.7413\n",
      "Epoch 56/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7471 - val_loss: 0.5200 - val_accuracy: 0.7394\n",
      "Epoch 57/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7462 - val_loss: 0.5203 - val_accuracy: 0.7438\n",
      "Epoch 58/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7477 - val_loss: 0.5199 - val_accuracy: 0.7445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7496 - val_loss: 0.5191 - val_accuracy: 0.7394\n",
      "Epoch 60/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7505 - val_loss: 0.5189 - val_accuracy: 0.7394\n",
      "Epoch 61/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7505 - val_loss: 0.5187 - val_accuracy: 0.7388\n",
      "Epoch 62/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7512 - val_loss: 0.5187 - val_accuracy: 0.7445\n",
      "Epoch 63/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7474 - val_loss: 0.5184 - val_accuracy: 0.7413\n",
      "Epoch 64/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7505 - val_loss: 0.5182 - val_accuracy: 0.7451\n",
      "Epoch 65/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7509 - val_loss: 0.5178 - val_accuracy: 0.7382\n",
      "Epoch 66/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7515 - val_loss: 0.5182 - val_accuracy: 0.7445\n",
      "Epoch 67/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7487 - val_loss: 0.5175 - val_accuracy: 0.7413\n",
      "Epoch 68/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7509 - val_loss: 0.5171 - val_accuracy: 0.7407\n",
      "Epoch 69/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7515 - val_loss: 0.5174 - val_accuracy: 0.7413\n",
      "Epoch 70/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7509 - val_loss: 0.5173 - val_accuracy: 0.7413\n",
      "Epoch 71/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7502 - val_loss: 0.5168 - val_accuracy: 0.7407\n",
      "Epoch 72/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7477 - val_loss: 0.5167 - val_accuracy: 0.7413\n",
      "Epoch 73/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7487 - val_loss: 0.5165 - val_accuracy: 0.7394\n",
      "Epoch 74/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7502 - val_loss: 0.5164 - val_accuracy: 0.7407\n",
      "Epoch 75/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7484 - val_loss: 0.5164 - val_accuracy: 0.7407\n",
      "Epoch 76/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7502 - val_loss: 0.5162 - val_accuracy: 0.7375\n",
      "Epoch 77/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7481 - val_loss: 0.5160 - val_accuracy: 0.7394\n",
      "Epoch 78/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7512 - val_loss: 0.5161 - val_accuracy: 0.7426\n",
      "Epoch 79/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7502 - val_loss: 0.5159 - val_accuracy: 0.7407\n",
      "Epoch 80/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7481 - val_loss: 0.5159 - val_accuracy: 0.7413\n",
      "Epoch 81/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7505 - val_loss: 0.5157 - val_accuracy: 0.7426\n",
      "Epoch 82/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7487 - val_loss: 0.5162 - val_accuracy: 0.7426\n",
      "Epoch 83/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7502 - val_loss: 0.5155 - val_accuracy: 0.7356\n",
      "Epoch 84/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7509 - val_loss: 0.5153 - val_accuracy: 0.7363\n",
      "Epoch 85/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7468 - val_loss: 0.5151 - val_accuracy: 0.7363\n",
      "Epoch 86/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7474 - val_loss: 0.5149 - val_accuracy: 0.7382\n",
      "Epoch 87/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7493 - val_loss: 0.5150 - val_accuracy: 0.7407\n",
      "Epoch 88/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7477 - val_loss: 0.5152 - val_accuracy: 0.7407\n",
      "Epoch 89/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7487 - val_loss: 0.5148 - val_accuracy: 0.7407\n",
      "Epoch 90/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7481 - val_loss: 0.5147 - val_accuracy: 0.7369\n",
      "Epoch 91/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7481 - val_loss: 0.5145 - val_accuracy: 0.7382\n",
      "Epoch 92/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7481 - val_loss: 0.5146 - val_accuracy: 0.7413\n",
      "Epoch 93/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7484 - val_loss: 0.5145 - val_accuracy: 0.7382\n",
      "Epoch 94/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7496 - val_loss: 0.5144 - val_accuracy: 0.7369\n",
      "Epoch 95/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7509 - val_loss: 0.5142 - val_accuracy: 0.7375\n",
      "Epoch 96/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7493 - val_loss: 0.5142 - val_accuracy: 0.7388\n",
      "Epoch 97/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7512 - val_loss: 0.5140 - val_accuracy: 0.7375\n",
      "Epoch 98/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7496 - val_loss: 0.5140 - val_accuracy: 0.7375\n",
      "Epoch 99/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7453 - val_loss: 0.5139 - val_accuracy: 0.7363\n",
      "Epoch 100/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7496 - val_loss: 0.5138 - val_accuracy: 0.7388\n",
      "Epoch 101/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7502 - val_loss: 0.5137 - val_accuracy: 0.7382\n",
      "Epoch 102/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7512 - val_loss: 0.5143 - val_accuracy: 0.7420\n",
      "Epoch 103/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7496 - val_loss: 0.5136 - val_accuracy: 0.7369\n",
      "Epoch 104/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7502 - val_loss: 0.5135 - val_accuracy: 0.7382\n",
      "Epoch 105/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7512 - val_loss: 0.5138 - val_accuracy: 0.7394\n",
      "Epoch 106/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7490 - val_loss: 0.5134 - val_accuracy: 0.7375\n",
      "Epoch 107/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7502 - val_loss: 0.5133 - val_accuracy: 0.7363\n",
      "Epoch 108/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7515 - val_loss: 0.5132 - val_accuracy: 0.7388\n",
      "Epoch 109/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7509 - val_loss: 0.5131 - val_accuracy: 0.7369\n",
      "Epoch 110/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7499 - val_loss: 0.5134 - val_accuracy: 0.7375\n",
      "Epoch 111/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7509 - val_loss: 0.5131 - val_accuracy: 0.7382\n",
      "Epoch 112/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7502 - val_loss: 0.5133 - val_accuracy: 0.7388\n",
      "Epoch 113/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7512 - val_loss: 0.5130 - val_accuracy: 0.7394\n",
      "Epoch 114/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7515 - val_loss: 0.5129 - val_accuracy: 0.7363\n",
      "Epoch 115/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7499 - val_loss: 0.5128 - val_accuracy: 0.7369\n",
      "Epoch 116/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7502 - val_loss: 0.5128 - val_accuracy: 0.7382\n",
      "Epoch 117/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7512 - val_loss: 0.5127 - val_accuracy: 0.7375\n",
      "Epoch 118/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7502 - val_loss: 0.5127 - val_accuracy: 0.7375\n",
      "Epoch 119/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7499 - val_loss: 0.5125 - val_accuracy: 0.7369\n",
      "Epoch 120/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7509 - val_loss: 0.5126 - val_accuracy: 0.7369\n",
      "Epoch 121/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7521 - val_loss: 0.5129 - val_accuracy: 0.7369\n",
      "Epoch 122/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7518 - val_loss: 0.5126 - val_accuracy: 0.7394\n",
      "Epoch 123/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7499 - val_loss: 0.5126 - val_accuracy: 0.7388\n",
      "Epoch 124/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7484 - val_loss: 0.5128 - val_accuracy: 0.7375\n",
      "Epoch 125/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7481 - val_loss: 0.5128 - val_accuracy: 0.7375\n",
      "Epoch 126/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7505 - val_loss: 0.5125 - val_accuracy: 0.7388\n",
      "Epoch 127/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7521 - val_loss: 0.5122 - val_accuracy: 0.7382\n",
      "Epoch 128/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7509 - val_loss: 0.5120 - val_accuracy: 0.7401\n",
      "Epoch 129/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7515 - val_loss: 0.5121 - val_accuracy: 0.7394\n",
      "Epoch 130/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7496 - val_loss: 0.5121 - val_accuracy: 0.7401\n",
      "Epoch 131/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7505 - val_loss: 0.5120 - val_accuracy: 0.7382\n",
      "Epoch 132/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7515 - val_loss: 0.5120 - val_accuracy: 0.7407\n",
      "Epoch 133/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7509 - val_loss: 0.5122 - val_accuracy: 0.7382\n",
      "Epoch 134/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7515 - val_loss: 0.5119 - val_accuracy: 0.7407\n",
      "Epoch 135/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7499 - val_loss: 0.5119 - val_accuracy: 0.7388\n",
      "Epoch 136/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.5119 - val_accuracy: 0.7382\n",
      "Epoch 137/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7530 - val_loss: 0.5123 - val_accuracy: 0.7350\n",
      "Epoch 138/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5118 - val_accuracy: 0.7388\n",
      "Epoch 139/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7521 - val_loss: 0.5118 - val_accuracy: 0.7388\n",
      "Epoch 140/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7521 - val_loss: 0.5117 - val_accuracy: 0.7369\n",
      "Epoch 141/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7512 - val_loss: 0.5118 - val_accuracy: 0.7382\n",
      "Epoch 142/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7521 - val_loss: 0.5117 - val_accuracy: 0.7382\n",
      "Epoch 143/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7515 - val_loss: 0.5117 - val_accuracy: 0.7401\n",
      "Epoch 144/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.5116 - val_accuracy: 0.7407\n",
      "Epoch 145/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7518 - val_loss: 0.5116 - val_accuracy: 0.7407\n",
      "Epoch 146/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7496 - val_loss: 0.5122 - val_accuracy: 0.7382\n",
      "Epoch 147/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7527 - val_loss: 0.5119 - val_accuracy: 0.7375\n",
      "Epoch 148/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7502 - val_loss: 0.5115 - val_accuracy: 0.7369\n",
      "Epoch 149/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7505 - val_loss: 0.5116 - val_accuracy: 0.7407\n",
      "Epoch 150/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7490 - val_loss: 0.5117 - val_accuracy: 0.7407\n",
      "Epoch 151/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7502 - val_loss: 0.5116 - val_accuracy: 0.7413\n",
      "Epoch 152/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7515 - val_loss: 0.5116 - val_accuracy: 0.7413\n",
      "Epoch 153/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7502 - val_loss: 0.5117 - val_accuracy: 0.7382\n",
      "Epoch 154/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7484 - val_loss: 0.5119 - val_accuracy: 0.7375\n",
      "Epoch 155/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.5117 - val_accuracy: 0.7375\n",
      "Epoch 156/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7499 - val_loss: 0.5120 - val_accuracy: 0.7375\n",
      "Epoch 157/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7546 - val_loss: 0.5116 - val_accuracy: 0.7401\n",
      "Epoch 158/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7524 - val_loss: 0.5123 - val_accuracy: 0.7350\n",
      "Epoch 159/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7515 - val_loss: 0.5118 - val_accuracy: 0.7382\n",
      "Epoch 160/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7518 - val_loss: 0.5116 - val_accuracy: 0.7394\n",
      "Epoch 161/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7515 - val_loss: 0.5120 - val_accuracy: 0.7375\n",
      "Epoch 162/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7505 - val_loss: 0.5116 - val_accuracy: 0.7420\n",
      "Epoch 163/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7502 - val_loss: 0.5116 - val_accuracy: 0.7413\n",
      "Epoch 164/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7518 - val_loss: 0.5114 - val_accuracy: 0.7401\n",
      "Epoch 165/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7521 - val_loss: 0.5119 - val_accuracy: 0.7388\n",
      "Epoch 166/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5116 - val_accuracy: 0.7420\n",
      "Epoch 167/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7518 - val_loss: 0.5114 - val_accuracy: 0.7394\n",
      "Epoch 168/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7509 - val_loss: 0.5115 - val_accuracy: 0.7413\n",
      "Epoch 169/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7512 - val_loss: 0.5116 - val_accuracy: 0.7388\n",
      "Epoch 170/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7490 - val_loss: 0.5130 - val_accuracy: 0.7338\n",
      "Epoch 171/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7518 - val_loss: 0.5118 - val_accuracy: 0.7401\n",
      "Epoch 172/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7509 - val_loss: 0.5116 - val_accuracy: 0.7382\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7505 - val_loss: 0.5115 - val_accuracy: 0.7388\n",
      "Epoch 174/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7496 - val_loss: 0.5115 - val_accuracy: 0.7388\n",
      "Epoch 175/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7515 - val_loss: 0.5115 - val_accuracy: 0.7413\n",
      "Epoch 176/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7518 - val_loss: 0.5121 - val_accuracy: 0.7369\n",
      "Epoch 177/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7533 - val_loss: 0.5117 - val_accuracy: 0.7401\n",
      "Epoch 178/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515 - val_loss: 0.5117 - val_accuracy: 0.7401\n",
      "Epoch 179/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7496 - val_loss: 0.5118 - val_accuracy: 0.7375\n",
      "Epoch 180/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7527 - val_loss: 0.5115 - val_accuracy: 0.7401\n",
      "Epoch 181/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7499 - val_loss: 0.5114 - val_accuracy: 0.7401\n",
      "Epoch 182/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7502 - val_loss: 0.5116 - val_accuracy: 0.7394\n",
      "Epoch 183/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7515 - val_loss: 0.5115 - val_accuracy: 0.7407\n",
      "Epoch 184/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7515 - val_loss: 0.5118 - val_accuracy: 0.7401\n",
      "Epoch 185/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7509 - val_loss: 0.5115 - val_accuracy: 0.7426\n",
      "Epoch 186/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7502 - val_loss: 0.5115 - val_accuracy: 0.7382\n",
      "Epoch 187/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7515 - val_loss: 0.5115 - val_accuracy: 0.7401\n",
      "Epoch 188/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7521 - val_loss: 0.5114 - val_accuracy: 0.7407\n",
      "Epoch 189/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7512 - val_loss: 0.5119 - val_accuracy: 0.7363\n",
      "Epoch 190/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7512 - val_loss: 0.5114 - val_accuracy: 0.7394\n",
      "Epoch 191/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7515 - val_loss: 0.5117 - val_accuracy: 0.7363\n",
      "Epoch 192/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7521 - val_loss: 0.5115 - val_accuracy: 0.7356\n",
      "Epoch 193/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7505 - val_loss: 0.5118 - val_accuracy: 0.7382\n",
      "Epoch 194/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7540 - val_loss: 0.5116 - val_accuracy: 0.7407\n",
      "Epoch 195/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7537 - val_loss: 0.5115 - val_accuracy: 0.7401\n",
      "Epoch 196/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7533 - val_loss: 0.5118 - val_accuracy: 0.7375\n",
      "Epoch 197/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7509 - val_loss: 0.5118 - val_accuracy: 0.7382\n",
      "Epoch 198/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7512 - val_loss: 0.5118 - val_accuracy: 0.7382\n",
      "Epoch 199/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7533 - val_loss: 0.5115 - val_accuracy: 0.7394\n",
      "Epoch 200/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7515 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
      "Epoch 201/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7527 - val_loss: 0.5118 - val_accuracy: 0.7407\n",
      "Epoch 202/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7518 - val_loss: 0.5131 - val_accuracy: 0.7344\n",
      "Epoch 203/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7512 - val_loss: 0.5116 - val_accuracy: 0.7407\n",
      "Epoch 204/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7502 - val_loss: 0.5119 - val_accuracy: 0.7388\n",
      "Epoch 205/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7515 - val_loss: 0.5117 - val_accuracy: 0.7407\n",
      "Epoch 206/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7524 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
      "Epoch 207/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7524 - val_loss: 0.5119 - val_accuracy: 0.7401\n",
      "Epoch 208/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7527 - val_loss: 0.5118 - val_accuracy: 0.7388\n",
      "Epoch 209/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7521 - val_loss: 0.5120 - val_accuracy: 0.7388\n",
      "Epoch 210/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7509 - val_loss: 0.5118 - val_accuracy: 0.7338\n",
      "Epoch 211/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7530 - val_loss: 0.5117 - val_accuracy: 0.7407\n",
      "Epoch 212/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7527 - val_loss: 0.5117 - val_accuracy: 0.7394\n",
      "Epoch 213/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7524 - val_loss: 0.5121 - val_accuracy: 0.7394\n",
      "Epoch 214/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7518 - val_loss: 0.5120 - val_accuracy: 0.7375\n",
      "Epoch 215/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7527 - val_loss: 0.5120 - val_accuracy: 0.7356\n",
      "Epoch 216/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7537 - val_loss: 0.5120 - val_accuracy: 0.7382\n",
      "Epoch 217/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7543 - val_loss: 0.5118 - val_accuracy: 0.7363\n",
      "Epoch 218/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7527 - val_loss: 0.5123 - val_accuracy: 0.7407\n",
      "Epoch 219/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7509 - val_loss: 0.5120 - val_accuracy: 0.7394\n",
      "Epoch 220/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7546 - val_loss: 0.5120 - val_accuracy: 0.7350\n",
      "Epoch 221/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7546 - val_loss: 0.5117 - val_accuracy: 0.7356\n",
      "Epoch 222/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7515 - val_loss: 0.5121 - val_accuracy: 0.7401\n",
      "Epoch 223/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7524 - val_loss: 0.5122 - val_accuracy: 0.7369\n",
      "Epoch 224/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7515 - val_loss: 0.5121 - val_accuracy: 0.7369\n",
      "Epoch 225/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7518 - val_loss: 0.5121 - val_accuracy: 0.7369\n",
      "Epoch 226/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7530 - val_loss: 0.5120 - val_accuracy: 0.7363\n",
      "Epoch 227/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7518 - val_loss: 0.5119 - val_accuracy: 0.7375\n",
      "Epoch 228/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7533 - val_loss: 0.5120 - val_accuracy: 0.7394\n",
      "Epoch 229/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7509 - val_loss: 0.5125 - val_accuracy: 0.7338\n",
      "Epoch 230/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7518 - val_loss: 0.5119 - val_accuracy: 0.7382\n",
      "Epoch 231/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7524 - val_loss: 0.5121 - val_accuracy: 0.7401\n",
      "Epoch 232/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7527 - val_loss: 0.5123 - val_accuracy: 0.7375\n",
      "Epoch 233/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7537 - val_loss: 0.5122 - val_accuracy: 0.7394\n",
      "Epoch 234/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7505 - val_loss: 0.5118 - val_accuracy: 0.7394\n",
      "Epoch 235/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7496 - val_loss: 0.5120 - val_accuracy: 0.7375\n",
      "Epoch 236/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7537 - val_loss: 0.5121 - val_accuracy: 0.7350\n",
      "Epoch 237/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7530 - val_loss: 0.5120 - val_accuracy: 0.7369\n",
      "Epoch 238/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7521 - val_loss: 0.5120 - val_accuracy: 0.7350\n",
      "Epoch 239/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7512 - val_loss: 0.5126 - val_accuracy: 0.7356\n",
      "Epoch 240/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7543 - val_loss: 0.5118 - val_accuracy: 0.7363\n",
      "Epoch 241/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7521 - val_loss: 0.5120 - val_accuracy: 0.7369\n",
      "Epoch 242/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7537 - val_loss: 0.5120 - val_accuracy: 0.7375\n",
      "Epoch 243/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7521 - val_loss: 0.5119 - val_accuracy: 0.7394\n",
      "Epoch 244/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7505 - val_loss: 0.5135 - val_accuracy: 0.7338\n",
      "Epoch 245/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7524 - val_loss: 0.5122 - val_accuracy: 0.7394\n",
      "Epoch 246/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7540 - val_loss: 0.5122 - val_accuracy: 0.7388\n",
      "Epoch 247/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7515 - val_loss: 0.5120 - val_accuracy: 0.7413\n",
      "Epoch 248/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7533 - val_loss: 0.5123 - val_accuracy: 0.7363\n",
      "Epoch 249/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7509 - val_loss: 0.5126 - val_accuracy: 0.7363\n",
      "Epoch 250/250\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7518 - val_loss: 0.5123 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19cf70282b0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn=Sequential()\n",
    "model_nn.add(Dense(4,  activation='relu'))\n",
    "model_nn.add(Dense(3,  activation='relu'))\n",
    "model_nn.add(Dense(3,  activation='relu'))\n",
    "model_nn.add(Dense(1, activation='sigmoid'))\n",
    "model_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_nn.fit(x_train, y_train, validation_split=0.33, epochs=250, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d9282a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn=np.round(model_nn.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "223b9302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7566666666666667\n",
      "0.7920792079207921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75       594\n",
      "           1       0.74      0.79      0.77       606\n",
      "\n",
      "    accuracy                           0.76      1200\n",
      "   macro avg       0.76      0.76      0.76      1200\n",
      "weighted avg       0.76      0.76      0.76      1200\n",
      "\n",
      "confusion matrix:\n",
      "\n",
      " [[428 166]\n",
      " [126 480]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,y_pred_nn))\n",
    "print(metrics.recall_score(y_test,y_pred_nn))\n",
    "print(metrics.classification_report(y_test,y_pred_nn))\n",
    "print('confusion matrix:\\n\\n',metrics.confusion_matrix(y_test,y_pred_nn))\n",
    "accuracy['nn']=metrics.accuracy_score(y_test,y_pred_nn)\n",
    "recall['nn']=metrics.recall_score(y_test,y_pred_nn)\n",
    "precision['nn']=metrics.precision_score(y_test,y_pred_nn)\n",
    "f1['nn']=metrics.f1_score(y_test,y_pred_nn)\n",
    "models['nn']=model_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a17d10",
   "metadata": {},
   "source": [
    "#### roc-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "38ddae0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 951us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc=metrics.roc_auc_score(y_test,y_pred_nn)\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,model_nn.predict(x_test).ravel())\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr,tpr,color=\"blue\",label=\"logit model(area= %0.2f)\"%auc)\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate (1-true negative rate)\",size=12)\n",
    "plt.ylabel(\"True Positive Rate\",size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ab624",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "24e9e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=pd.Series(['logistic regression','Decision Tree','KNN','Naive Bayes','SVM','adaboost','random forest','bagging','LGBM','NeuralNetwork'])\n",
    "acc=[accuracy['lr'],accuracy['dt'],accuracy['knn'],accuracy['nb'],accuracy['SVM'],accuracy['ada'],accuracy['rf'],accuracy['bagging'],accuracy['lgbm'],accuracy['nn']]\n",
    "rec=[recall['lr'],recall['dt'],recall['knn'],recall['nb'],recall['SVM'],recall['ada'],recall['rf'],recall['bagging'],recall['lgbm'],recall['nn']]\n",
    "pre=[precision['lr'],precision['dt'],precision['knn'],precision['nb'],precision['SVM'],precision['ada'],precision['rf'],precision['bagging'],precision['lgbm'],precision['nn']]\n",
    "f1score=[f1['lr'],f1['dt'],f1['knn'],f1['nb'],f1['SVM'],f1['ada'],f1['rf'],f1['bagging'],f1['lgbm'],f1['nn']]\n",
    "model_result=pd.DataFrame({'model name':model_name,'accuracy':acc,'recall':rec,'precision':pre,'f1-score':f1score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5d09cd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.760833</td>\n",
       "      <td>0.780528</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.767234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.793729</td>\n",
       "      <td>0.692086</td>\n",
       "      <td>0.739431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>0.793729</td>\n",
       "      <td>0.731003</td>\n",
       "      <td>0.761076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.744224</td>\n",
       "      <td>0.761824</td>\n",
       "      <td>0.752922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.810231</td>\n",
       "      <td>0.719941</td>\n",
       "      <td>0.762422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adaboost</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.738019</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.740833</td>\n",
       "      <td>0.826733</td>\n",
       "      <td>0.708628</td>\n",
       "      <td>0.763138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bagging</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.745223</td>\n",
       "      <td>0.758509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.806931</td>\n",
       "      <td>0.736446</td>\n",
       "      <td>0.770079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.743034</td>\n",
       "      <td>0.766773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model name  accuracy    recall  precision  f1-score\n",
       "0  logistic regression  0.760833  0.780528   0.754386  0.767234\n",
       "1        Decision Tree  0.717500  0.793729   0.692086  0.739431\n",
       "2                  KNN  0.748333  0.793729   0.731003  0.761076\n",
       "3          Naive Bayes  0.753333  0.744224   0.761824  0.752922\n",
       "4                  SVM  0.745000  0.810231   0.719941  0.762422\n",
       "5             adaboost  0.743333  0.762376   0.738019  0.750000\n",
       "6        random forest  0.740833  0.826733   0.708628  0.763138\n",
       "7              bagging  0.751667  0.772277   0.745223  0.758509\n",
       "8                 LGBM  0.756667  0.806931   0.736446  0.770079\n",
       "9        NeuralNetwork  0.756667  0.792079   0.743034  0.766773"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "491e73e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': LogisticRegression(),\n",
       " 'Decision Tree': DecisionTreeClassifier(max_depth=2),\n",
       " 'dt': DecisionTreeClassifier(max_depth=2),\n",
       " 'knn': KNeighborsClassifier(n_neighbors=34, weights='distance'),\n",
       " 'nb': GaussianNB(),\n",
       " 'SVM': SVC(C=0.01, gamma=0.01, probability=True),\n",
       " 'ada': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                    n_estimators=400, random_state=7),\n",
       " 'bagging': BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',\n",
       "                                                         max_depth=3),\n",
       "                   max_samples=0.2, n_estimators=17, random_state=7),\n",
       " 'rf': RandomForestClassifier(max_depth=2, max_features=4, n_estimators=108),\n",
       " 'lgbm': LGBMClassifier(learning_rate=0.09, max_depth=4, random_state=42),\n",
       " 'nn': <keras.engine.sequential.Sequential at 0x19cf7043070>}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f27052a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final=models['rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd1a22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
